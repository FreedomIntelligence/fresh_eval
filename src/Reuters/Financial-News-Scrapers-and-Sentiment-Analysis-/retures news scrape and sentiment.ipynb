{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import urllib.request\n",
    "from tqdm import tqdm \n",
    "import time \n",
    "import pandas as pd\n",
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "# from nltk.tokenize import word_tokenize\n",
    "lemma = WordNetLemmatizer()\n",
    "import re\n",
    "# from textblob import TextBlob\n",
    "\n",
    "# from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "# sid =SentimentIntensityAnalyzer()\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "#Function to scroll and get all the links to the articles\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_links_to_articles(scrollNumber,searchTerm):\n",
    "\n",
    "    driver = webdriver.Chrome('chromedriver',options=chrome_options)\n",
    "    wait = WebDriverWait(driver, 2)\n",
    "    driver.get(\"https://www.reuters.com/search/news?blob=\"+searchTerm)\n",
    "    driver.find_element_by_xpath('//*[@id=\"content\"]/section[2]/div/div[1]/div[4]/div/div[1]/div/div[1]/select/option[2]').click()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for i in tqdm (range (scrollNumber),  \n",
    "               desc=\"Scrolling..\",  \n",
    "               ascii=False):\n",
    "        try:\n",
    "            if driver.find_element_by_xpath('//*[@id=\"content\"]/section[2]/div/div[1]/div[4]/div/div[4]/div[1]'):\n",
    "                        wait.until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"content\"]/section[2]/div/div[1]/div[4]/div/div[4]/div[1]')))\n",
    "                        n = driver.find_element_by_xpath('//*[@id=\"content\"]/section[2]/div/div[1]/div[4]/div/div[4]/div[1]')\n",
    "                        driver.execute_script(\"arguments[0].click();\", n)\n",
    "\n",
    "\n",
    "            else:\n",
    "                print('Not found')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    soup_a = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    html = driver.page_source\n",
    "    driver.close()\n",
    "    soup_a = BeautifulSoup(html, 'lxml')\n",
    "    # Them we close the driver as soup_a is storing the page source\n",
    "\n",
    "    # Empty array to store the links\n",
    "    links = []\n",
    "    article_urls = soup_a.findAll(\"h3\",{\"class\":\"search-result-title\"})\n",
    "\n",
    "\n",
    "    # Looping through all the a elements in the page source\n",
    "    for link in article_urls:\n",
    "        all_li = link.find_all('a')\n",
    "        for li in all_li:\n",
    "            links.append(li.get('href'))\n",
    "            \n",
    "    return links\n",
    "\n",
    "         \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article(url):\n",
    "    user_agent = 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7'\n",
    "    headers={'User-Agent':user_agent,} \n",
    "    request=urllib.request.Request(url,None,headers)\n",
    "\n",
    "    driver = webdriver.Chrome('chromedriver',options=chrome_options)\n",
    "    wait = WebDriverWait(driver, 2)\n",
    "    driver.get(url)\n",
    "\n",
    "    article = driver.find_element_by_xpath('//*[@id=\"__next\"]/div/div[4]/div[1]/article/div[1]').text\n",
    "    \n",
    "\n",
    "    t = driver.find_elements_by_css_selector('time')\n",
    "    \n",
    "    time = []\n",
    "\n",
    "    for i in t:\n",
    "        time.append(i.text)\n",
    "\n",
    "    driver.close()\n",
    "\n",
    "\n",
    "\n",
    "    return time,article\n",
    "\n",
    "    \n",
    "def get_all_articles(list_urls):\n",
    "    print(\"\\n Getting all articles from links\")\n",
    "    print(\" *This will take some time please be patient*\")\n",
    "    articles = []\n",
    "    time = []\n",
    "    base = 'https://www.reuters.com'\n",
    "    \n",
    "\n",
    "    for link in tqdm(list_urls):\n",
    "        u = base+link\n",
    "        t,a = get_article(u)\n",
    "        time.append(t)\n",
    "        articles.append(a)\n",
    "\n",
    "       \n",
    "        \n",
    "      \n",
    "    return time,articles \n",
    "\n",
    "\n",
    "\n",
    "def prepare_dt(t):  \n",
    "  l =[]\n",
    "  for i in t:\n",
    "    try:\n",
    "      i.remove(i[2])\n",
    "      l.append(i)\n",
    "    except:\n",
    "      l.append(i)\n",
    "  tii = []\n",
    "  for i in l:\n",
    "      separator = ', '\n",
    "      tii.append(separator.join(i))\n",
    "  return tii\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_df(time,articles):\n",
    "    time = prepare_dt(time)\n",
    "    df = pd.DataFrame({'Datetime':time,'Article':articles})\n",
    "    return df\n",
    "\n",
    "def clean_text(text):\n",
    "     totalStopwords = set([word.replace(\"'\",'') for word in stopwords.words('english')])\n",
    "     text = text.lower()\n",
    "     text = text.replace(\"'\",'')\n",
    "     text = re.sub('[^a-zA-Z]',' ',text)\n",
    "     words = text.split()\n",
    "     words = [lemma.lemmatize(word) for word in words if (word not in totalStopwords) and (len(word)>1)] # Remove stop words\n",
    "     text = \" \".join(words)\n",
    "\n",
    "     return text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cleaning_sentiment_scoring(df):\n",
    "    print(\"\\n Cleaning Text\")\n",
    "    df['Article'] = df['Article'].apply(lambda x:clean_text(x))\n",
    "    df['Datetime'] = pd.to_datetime(df.Datetime)\n",
    "    print(\"\\n Analyzing Sentiment\")\n",
    "    \n",
    "    new_words = {\n",
    "        'fall':-2.0,\n",
    "        'edge':1,\n",
    "        'rise':2.0,\n",
    "        'slip':-2.0,\n",
    "        'drop':-2.0,\n",
    "        'gain':2.0,\n",
    "        'jump':2.0,\n",
    "        'climb':2.0,\n",
    "        'rally':2.0,\n",
    "        'hit':-1,\n",
    "        'end':0.4\n",
    "        \n",
    "    }\n",
    "\n",
    "\n",
    "    sid.lexicon.update(new_words)\n",
    "    \n",
    "    desc_blob = [TextBlob(desc) for desc in df['Article']]\n",
    "    #add the sentiment metrics to the dataframe\n",
    "    df['Polarity'] = [b.sentiment.polarity for b in desc_blob]\n",
    "    df['Subjectivity'] = [b.sentiment.subjectivity for b in desc_blob]\n",
    "    #load VADER\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    #Add VADER metrics to dataframe\n",
    "    df['compound'] = [sid.polarity_scores(v)['compound'] for v in df['Article']]\n",
    "    df['neg'] = [sid.polarity_scores(v)['neg'] for v in df['Article']]\n",
    "    df['neu'] = [sid.polarity_scores(v)['neu'] for v in df['Article']]\n",
    "    df['pos'] = [sid.polarity_scores(v)['pos'] for v in df['Article']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sentiment_by_hr(df):\n",
    "    ndf = df.set_index('Datetime').resample('H')['compound'].mean().dropna().plot(color='r', label='Sentiment')\n",
    "    ndf.legend(loc=\"upper right\")\n",
    "    ndf.set_xlabel('Datetime')\n",
    "    ndf.set_ylabel('Sentiment')\n",
    "    ndf.yaxis.label.set_color('blue')\n",
    "    ndf.xaxis.label.set_color('blue')\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def show_sentiment_by_day(df):    \n",
    "    ndf = df.set_index('Datetime').resample('D')['compound'].mean().fillna(df['compound'].mean()).plot(color='r', label='Sentiment')\n",
    "    ndf.legend(loc=\"upper right\")\n",
    "    ndf.set_xlabel('Datetime')\n",
    "    ndf.set_ylabel('Sentiment')\n",
    "    ndf.yaxis.label.set_color('blue')\n",
    "    ndf.xaxis.label.set_color('blue')\n",
    "\n",
    "\n",
    "    \n",
    "def show_sentiment_by_week(df):    \n",
    "    ndf = df.set_index('Datetime').resample('W')['compound'].mean().fillna(df['compound'].mean()).plot(color='r', label='Sentiment')\n",
    "    ndf.legend(loc=\"upper right\")\n",
    "    ndf.set_xlabel('Datetime')\n",
    "    ndf.set_ylabel('Sentiment')\n",
    "    ndf.yaxis.label.set_color('blue')\n",
    "    ndf.xaxis.label.set_color('blue')\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def save_to_excel(df,name):\n",
    "    df.to_excel('reutersnews/'+name+'NewsSentiment.xlsx')\n",
    "    print('File saved as: ', name+'NewsSentiment.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search():\n",
    "    link = input('Please enter name for example: Apple:aaple :') or 'Apple'\n",
    "    scroll = int(input('Please enter pages to scroll :') or '2')\n",
    "    l =get_links_to_articles(scroll,link)\n",
    "    t,a  =get_all_articles(l)\n",
    "    df = make_df(t,a)\n",
    "    # df = cleaning_sentiment_scoring(df)\n",
    "\n",
    "    save_to_excel(df,link)\n",
    "    print('\\n **Done**')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got multiple values for argument 'options'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16712\\211750583.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16712\\4154786279.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mlink\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Please enter name for example: Apple:aaple :'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m'Apple'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mscroll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Please enter pages to scroll :'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m'2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mget_links_to_articles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscroll\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m  \u001b[1;33m=\u001b[0m\u001b[0mget_all_articles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16712\\3221071620.py\u001b[0m in \u001b[0;36mget_links_to_articles\u001b[1;34m(scrollNumber, searchTerm)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_links_to_articles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscrollNumber\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msearchTerm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mdriver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'chromedriver'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchrome_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[0mwait\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWebDriverWait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://www.reuters.com/search/news?blob=\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0msearchTerm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got multiple values for argument 'options'"
     ]
    }
   ],
   "source": [
    "df = search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'show_sentiment_by_hr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16712\\1768499617.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Horly sentiment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mshow_sentiment_by_hr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'show_sentiment_by_hr' is not defined"
     ]
    }
   ],
   "source": [
    "#Horly sentiment\n",
    "show_sentiment_by_hr(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'show_sentiment_by_day' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16712\\3728796250.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Daily sentiment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mshow_sentiment_by_day\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'show_sentiment_by_day' is not defined"
     ]
    }
   ],
   "source": [
    "#Daily sentiment\n",
    "show_sentiment_by_day(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'show_sentiment_by_week' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16712\\4237509205.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#weekly sentiment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mshow_sentiment_by_week\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'show_sentiment_by_week' is not defined"
     ]
    }
   ],
   "source": [
    "#weekly sentiment\n",
    "show_sentiment_by_week(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
