{"date": "2024-01-04-22-29", "error": false, "url": "PDF", "text_blocks": "AVRA: Automatic Visual Ratings of Atrophy from MRI images\nusing Recurrent Convolutional Neural Networks.\nGustav M\u0017 artenssona,\u0003, Daniel Ferreiraa, Lena Cavallinb,c, J-Sebastian Muehlboecka, Lars-Olof\nWahlunda, Chunliang Wangd, Eric Westmana,e, for the Alzheimer's Disease Neuroimaging\nInitiativeI\naDivision of Clinical Geriatrics, Department of Neurobiology, Care Sciences and Society, Karolinska Institutet,\nStockholm, Sweden.\nbDepartment of Clinical Neuroscience, Karolinska Institutet, Stockholm, Sweden.\ncDepartment of Radiology, Karolinska University Hospital, Stockholm, Sweden.\ndSchool of Technology and Health, KTH Royal Institute of Technology, Stockholm, Sweden.\neDepartment of Neuroimaging, Centre for Neuroimaging Sciences, Institute of Psychiatry, Psychology and\nNeuroscience, King's College London, London, UK.\nAbstract\nQuantifying the degree of atrophy is done clinically by neuroradiologists following established\nvisual rating scales. For these assessments to be reliable the rater requires substantial training\nand experience, and even then the rating agreement between two radiologists is not perfect. We\nhave developed a model we call AVRA (Automatic Visual Ratings of Atrophy) based on machine\nlearning methods and trained on 2350 visual ratings made by an experienced neuroradiologist.\nIt provides fast and automatic ratings for Scheltens' scale of medial temporal atrophy (MTA),\nthe frontal subscale of Pasquier's Global Cortical Atrophy (GCA-F) scale, and Koedam's scale\nof Posterior Atrophy (PA). We demonstrate substantial inter-rater agreement between AVRA's\nand a neuroradiologist ratings with Cohen's weighted kappa values of \u0014w= 0.74/0.72 (MTA\nleft/right), \u0014w= 0.62 (GCA-F) and \u0014w= 0.74 (PA), with an inherent intra-rater agreement of\n\u0014w= 1. We conclude that automatic visual ratings of atrophy can potentially have great clinical\nand scienti\fc value, and aim to present AVRA as a freely available toolbox.\n1. Introduction\nThe assessment of structural changes in the brain is made clinically by visual ratings of brain\natrophy according to established visual rating scales. They o\u000ber an e\u000ecient and inexpensive\nmethod of quantifying the degree of atrophy and can help to improve the speci\fcity and sensi-\ntivity of dementia diagnoses [1, 2]. However, there are limitations associated with visual ratings\nof atrophy, which may explain why they are still not widely used in the clinical routine. First,\nthe ratings are inherently subjective which means that the agreement between two radiologist\nmight be low if they have not had su\u000ecient training [1]. Second, in order to achieve adequate\nreliability the radiologist needs to be experienced and regularly perform ratings for the repro-\nducibility not to drop [3]. Third, the ratings are relatively time consuming and tedious. It takes\na few minutes per image [4], depending on rating scale and level of rating experience. While\nthis amount of time may be feasible in most clinical settings, it does not easily allow studying\nlarge imaging cohorts of potentially thousands of images. An automatic method would remove\nthe inter- and intra-rater variability and eliminate the time-consuming process of rating.\n1.1. Visual rating scales\nAmongst the most commonly used rating scales|both in research and in clinical routine|are\nScheltens' Medial Temporal Atrophy (MTA) scale [5], Koedam's scale for Posterior Atrophy (PA)\nIData used in preparation of this article were obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database\n(adni.loni.usc.edu). As such, the investigators within the ADNI contributed to the design and implementation of ADNI and/or pro-\nvided data but did not participate in analysis or writing of this report. A complete listing of ADNI investigators can be found at:\nhttp://adni.loni.usc.edu/wp-content/uploads/how_to_apply/ADNI_Acknowledgement_List.pdf .\n\u0003Corresponding author\nEmail address: gustav.martensson@ki.se (Gustav M\u0017 artensson)\n1arXiv:1901.00418v1  [physics.med-ph]  23 Dec 20181.1 Visual rating scales 1 INTRODUCTION\nMTA 0 1 2 3 4\nGCA-F 0 1 2 3\nPA 0 1 2 3\nFigure 1: Examples of Scheltens' MTA scale [5], Pasquier's frontal subscale of GCA [8], and Koedam's PA scale\n[6]. The MTA ratings are done in the coronal plane, GCA-f in the axial plane, and PA ratings are based on\nassessments of all three planes. The area between the dashed lines in the left images indicates the slices assessed\nby a radiologist for the GCA-F and PA scales, while it shows the single slice assessed for MTA. The red boxes\nshow the regions assessed for each rating scale.\n[6] and Pasquier's scale for Global Cortical Atrophy (GCA) [7, 8] (see Fig. 1 for examples). These\nscales have previously been validated by quantitative neuroimaging techniques [9, 10, 11, 12].\nThe MTA scale was developed by Scheltens et al. (1992) [5]. A rating is given for each\nhemisphere ranging from 0 (no atrophy) to 4 (severe atrophy) and focuses on three structures: the\nwidth of the choroid \fssure, the width of the temporal horn and the height of the hippocampus.\nThe assessment is made in a single or few coronal slices on a high quality CT or ideally a T 1-\nweighted MRI. Di\u000berent cut-o\u000bs have been suggested where the most common is that an average\nMTA score\u00152 is considered pathological if the patient is younger than 75 years old, and an\naverage MTA\u00153 for patients older than 75 years [5, 13, 14].\nThe PA scale assesses atrophy of the parietal lobe of the brain and was proposed by Koedam\net al. (2011) [6]. A rating from 0 (no atrophy) to 3 (severe atrophy) is given that speci\fcally\nassesses the degree of atrophy of the precuneus, the posterior cingulate sulcus, the parieto-\noccipital sulcus and the parietal cortex.\nPasquier et al. (1996) developed a visual rating system of cerebral atrophy in 13 di\u000berent\nbrain regions that assesses the level of dilatation of sulci and the ventricles [8]. For each of these\nregions a score ranging from 0 (no atrophy) to 3 (severe atrophy) is given by the radiologist.\n21.2 Related work 2 MATERIAL AND METHODS\nThese measures have been simpli\fed into a global assessment of cortical atrophy rated from 0 to 3\ncalled the GCA scale. The original paper by Pasquier and colleagues used T 2-weighed images[8]\nbut several studies have also assessed GCA in T 1-weighted images [13, 12, 15, 7]. A frontal\nsubscale of GCA (GCA-F) is of particular interest since frontal atrophy has been shown to be\nassociated with executive dysfunction [16] and can o\u000ber improved diagnosis of frontotemporal\ndementia (FTD) [12].\n1.2. Related work\nA few automatic (or semi-automatic) methods to quantify medial temporal atrophy|besides\nvolumetrics|have previously been proposed. Two of them involve planimetrics based on manual\ndelineation of hippocampus and surrounding structures that are combined into a single score of\nmedial temporal atrophy [17, 18]. While these methods assess almost the same structures as\nScheltens' MTA scale, the di\u000berent scales are not interchangeable and do not necessarily re\rect\nthe same atrophy patterns. Another study recently reported an automatic method that is trained\non radiologist ratings which predicts MTA scores based on volumetric measures extracted from\nthe MRI image [19]. Volumetric measures of brain regions can not be extracted from most CT\nimages nor do they retain any information regarding the shape of the structures. It is reasonable\nto assume that the shapes are important since the visual MTA rating is done on a single slice,\nfrom which it is not possible to estimate the hippocampal volume.\nDeep learning|a branch of machine learning|has recently generated impressive results in\nseveral \felds, such as speech recognition, text semantics, image recognition and genomics [20].\nConvolutional neural networks (CNN's) have already been substantially applied in medical image\nanalysis (for recent reviews, see [21, 22]). For instance, studies using CNN's have achieved\nsimilar levels of accuracy as medical experts in classifying skin cancer [23], mammographic\nskin lesion detection [24], and diabetic retinopathy diagnosis [25]. Focusing on applications in\nneuroimaging, deep neural networks have been used successfully for automatic methods of skull\nstripping [26, 27], brain age prediction [28], brain segmentation [29], PET image enhancement\n[30] and brain tumor segmentation [31, 32] to name a few. In dementia research, several studies\nhave investigated brains of patients with Alzheimer's disease (AD) using deep learning and shown\nimpressive diagnostic abilities [33, 34, 35, 36]. A Recurrent Neural Network (RNN) is an arti\fcial\nneural network that has an internal state (or \"memory\") and is useful when processing sequential\ndata, such as words in a sentence or frames in a video[20, 37]. RNN's have successfully been\ncombined with CNN's to segment MRI images, where the addition of an RNN module helped to\nleverage adjacent slice dependencies [38, 39].\n1.3. Our approach\nIn this study, we aimed to develop an automatic algorithm based on convolutional and re-\ncurrent neural networks that provides fast, reliable, and systematic predictions of established\nvisual ratings scales of atrophy of brain regions often a\u000bected in dementia: the MTA, GCA-F\nand PA scales. The models are trained on a large set of MRI images that have been rated by\nan experienced neuroradiologist. This method is atlas-free and requires minimum amount of\nsetup and third-party software. We plan to present the proposed algorithm as a freely available\nsoftware targeted towards neuroimaging researchers.\n2. Material and methods\n2.1. MRI data and protocols\nTwo di\u000berent dementia cohorts of MRI images were included in this project: Alzheimer's\nDisease Neuroimaging Initiative (ADNI) and a clinical cohort with images from the memory\nclinic at Karolinska University Hospital (referred to as MemClin from here on). Informed consent\nwas obtained for all participants, or by an authorized representative of theirs.\nIndividuals in the MemClin cohort mainly consisted of patients clinically diagnosed with\ndementia according to the ICD-10 criteria between 2003 and 2011. All participants underwent\na T 1-weighted MRI scan at the Radiology Department of Karolinska University Hospital in\nStockholm, Sweden. Exclusion criteria were if the patient had other types of dementia, history\nof traumatic brain injury, or insu\u000ecient quality of the MRI scan [40, 41].\n32.2 Human ratings 2 MATERIAL AND METHODS\nTable 1: The rating distribution of the images used in the study. The \"Images\" column refers to how many\nunique images that were rated by the radiologist at least once. Both the left and right MTA ratings are presented\nin the \"MTA\" column in the Table.\nCohort ImagesMTA GCA-F PA\n0 1 2 3 4 0 1 2 3 0 1 2 3\nADNI 1966 425 1581 1147 555 224 1449 468 49 0 1188 611 157 10\nMemClin 384 23 265 296 139 45 279 89 14 2 210 127 43 4\nTotal 2350 448 1846 1443 694 269 1728 557 63 2 1398 738 200 14\nData used in the preparation of this article were obtained from the Alzheimer's Disease Neu-\nroimaging Initiative (ADNI) database ( adni.loni.usc.edu ). The ADNI was launched in 2003\nas a public-private partnership, led by Principal Investigator Michael W. Weiner, MD. The pri-\nmary goal of ADNI has been to test whether serial magnetic resonance imaging (MRI), positron\nemission tomography (PET), other biological markers, and clinical and neuropsychological as-\nsessment can be combined to measure the progression of mild cognitive impairment (MCI) and\nearly Alzheimer's disease (AD). For up-to-date information, see www.adni-info.org . A major-\nity of the participants in the ADNI cohort were scanned multiple times within a few weeks|often\nin the same day. A subset of participants were scanned both in 1.5T and 3T machines.\nAll available images with an associated visual atrophy rating performed by a neuroradiologist\nwere used in this study. Images that did not pass the initial automatic AC/PC-alignment (the\nanterior and posterior commissures) were excluded from the training and evaluation process (144\nout of 5355 images in total).\nThe algorithm was developed using theHiveDB database system[42] and will become part of\nits automated activity system.\n2.2. Human ratings\nAn experienced neuroradiologist, Lena Cavallin (L.C.), visually rated 2350 T 1-weighted MRI\nimages over the course of 16 months with no prior knowledge of age, sex, or diagnosis. For\nADNI subjects scanned more than once, only one of the images was rated by the radiologist and\nthe additional image(s) were labeled with the same rating. The distribution of L.C.'s MTA, PA\nand GCA-F ratings are shown in Table 1. Many of the ADNI ratings have been analyzed and\nreported in previous studies [40, 13, 12, 15, 14]. All visual ratings of MTA, PA and GCA-F were\nbased on T 1-weighted MRI images, and illustrative examples of the ratings can be seen in Fig.\n1. The images were aligned with AC/PC by the radiologist if the protocol allowed for it [3].\nThe MTA ratings were made in a single coronal slice, just behind the amygdala and mammillary\nbodies. The GCA-F ratings were based on multiple sagittal slices, whereas the PA score was\nbased on slices in all three planes.\n2.3. Computer ratings\nThe motivation behind the proposed model architecture was to mimic how a neuroradiol-\nogist would process an MRI image: to scroll through the brain volume slice-by-slice looking\nfor the \"correct\" slice(s) to base the rating on. A human rater assesses images acquired using\ndi\u000berent scanners, vendors and protocols without any need for substantial preprocessing such\nas segmentation, intensity normalization, non-linear registrations or skull-stripping. To better\nmimic the clinical situation (and to keep the number of time consuming preprocessing steps that\ncan potentially fail to a minimum) we trained AVRA to rate images with as little preprocessing\nas possible. The main di\u000berence between AVRA's and a human rater is that AVRA's ratings\nare continuous instead of discrete.\nAll code in this project was developed in Python 3.4.3 using the deep learning framework\nPyTorch 1.0 [43].\nPreprocessing\nThe only preprocessing included in our method is the registration of all brains to the MNI\nstandard brain using FSL FLIRT 6.0 (FMRIB's Linear Image Registration Tool) [44, 45, 46].\nThis rigid transform is computed with 6 degrees of freedom (i.e. rotation and translation only)\nand is used to automatically AC-PC align each brain and conform all images to the same voxel\n42.3 Computer ratings 2 MATERIAL AND METHODS\nLSTM 2 LSTM 2...LSTM 2\nFC GCA-Fh(2)\n0 h(2)\n1 h(2)\n2 h(2)\nn−1h(2)\nn\nLSTM 1 LSTM 1...LSTM 1h(1)\n0 h(1)\n1 h(1)\n2 h(1)\nn−1h(1)\nnAttention Netx0\nSlice 0x1\nSlice 1xn−1\nSlicen−1...\nSlicen−1\n::\nSlice 0\nFigure 2: A sketch of the architecture of AVRA, with the example of a GCA-F prediction. The MTA and PA\nmodels followed the same structure.\nsize (1x1x1mm3) and input dimension (182x218x182). The AC-PC aligned images are cropped\nto remove excess space outside the brain and redundant slices not part of the ratings scale (as\nindicated in Figs. 1 and 2). The center-voxel of the cropped images depended on the rating\nscale. For the MTA ratings, 22 coronal slices of the dimension 128mm x 128mm are input to the\nmodel|enough to ensure that the \"correct\" rating slice is included. The GCA-F ratings are done\non multiple axial slices so each volume is cropped to 160mm x 192mm x 40 slices, with 2mm slice\nthickness. The PA model requires slices from all three anatomical planes. From each MRI image\na smaller volume of 128mm x 128mm x 128mm was extracted from the parietal lobe, su\u000eciently\nlarge to include all relevant structures in the parietal cortex. From this cropped volume 37 axial,\n28 coronal and 34 sagittal slices with 2mm slice thickness (i.e. 99 slices in total) were used as\ninput to the model. Since the distribution of raw voxel values was very di\u000berent|particularly\nbetween 1.5T and 3T images|all cropped volumetric images were normalized to have a zero\nvariance and mean.\nModel architectures\nThe overall structure of the models can be seen in Fig. 2 and can be split into three parts.\nFirst, relevant features from a single slice are extracted using a Residual Attention Network [47],\ndetailed in Fig. 3. It combines the abilities from residual learning [48], which can allow for even\ndeeper models, and attention models that can \"focus\" spatially on images|particularly useful\nfor visual ratings since they are based on regional atrophy [49, 50]. Our implementation is a\nslimmed version of the original, with the same depth but a smaller number of \flters in each\nlayer to reduce memory usage and computation time. Initial experiments showed no noticeable\nperformance reduction on the validation set compared to using a larger network. Second, the\nfeatures are reshaped to a 1D vector and fed to an RNN, which consists of a two-layer Long-\nShort Term Memory (LSTM) network with 256 hidden nodes [51, 52]. The LSTM modules are\nexpected to \"remember\" relevant features seen in previous slices and update its state (\"memory\")\nwhen it is exposed to a slice containing useful information for the rating. Finally, when slice 0, 1,\n..., (n\u00001) have been propagated through the network, the \fnal output from the second LSTM\nmoduleh(2)\nnis used to make a linear prediction of the visual rating. All three models share the\nsame network architecture except for the size of the input vector fed to the LSTM network, as\n52.4 Analyses metrics 3 RESULTS\nSlice i\nx+ x+ x+ xi\nDownsample\nUpsampleConvolution\nPooling\nResidual block\nFigure 3: A sketch of the residual attention net used to extract features from individual MRI slices, where the\n\rattened output is fed to the RNN. The downsampling block consists of stacking maxpooling operations followed\nby a residual block. The upsamling is performed with bilinear interpolations of the output of a residual block.\nThe \"+\", \"x\", and \"S-shaped\" symbols denote element-wise summation, multiplication and the sigmoid function,\nrespectively. The \row chart is adapted from [47].\nthat is dependent on the input size of the MRI slices.\nFor comparison, we train a VGG16 network [53] without the RNN part, where the 3D volumes\nare treated as multi-channel 2D images. That is, for the MTA model we input one \"22-channel\"\nimage to the CNN once instead of 22 single-slice images.\nTraining\nFor training and evaluation, the dataset was randomly split into a training and a hold-out\ntest set, where 20% of all subjects where assigned to the test set. On the remaining images in\nthe training set we applied 5-fold cross validation for hyper-parameter tuning for each rating\nscale. The \fve trained models were used together as an ensemble classi\fer evaluated on the test\nset, where the average prediction was considered the \fnal rating.\nThe models were trained for 200 epochs using backpropagation and optimized through\nstochastic gradient descent (SGD) with cyclic learning rate to maximize the probability of pre-\ndicting the radiologist's rating [54, 55]. The training set was randomly split into minibatches,\neach containing 20 MRI images, and the weights were updated to minimize the mean-squared\nerror between the automatic and the integer ratings by L.C. We employed data augmentation\nin the training process of the network to reduce the risk of over\ftting to the training set. This\nincluded random cropping (within \u000610mm o\u000b the center voxel), scaling, left/right mirroring, and\nrandomly selecting N4ITK inhomogeniety corrected images instead of the original \fle [56]. Due\nto the imbalance of ratings in the dataset we employed random oversampling of images with less\nfrequent ratings, which has been shown to improve the prediction performance of CNN's [57].\nFor ADNI subjects that had multiple scans for a single timepoint, a scan was selected randomly\nfor each minibatch.\n2.4. Analyses metrics\nThe visual rating scales are subjective measures by de\fnition. Consequently, there are no\nobjective ground truth ratings available. In most studies, the performance of a rater is reported\nin kappa statistics|a group of measures that can quantify the level of agreement between two\nsets of discrete ratings|but there is no single metric always reported. To make our results\ncomparable to previous \fndings, we present our results with Cohen's weighted kappa ( \u0014w), which\nhas been used in several previous rating studies [6, 14, 3, 58, 12, 15, 59], as well as accuracy and\nthe Pearson correlation coe\u000ecient ( \u001a). The agreement between two sets of ratings is referred to\ninter -rater agreement if the sets were assessed by di\u000berent raters, and intra -rater agreement if\na single radiologist rated the set twice.\n3. Results\n3.1. Intra-rater agreements\nTo have an idea of the variability in the human ratings used for training in this project, we\nstudied the intra-rater agreement in a subset of 244 images that had been rated 2-4 times with\nat most 16 months from the \frst to the last rating session. To be consistent with the computer\ntraining and evaluation procedure, we compared the latest rating to a previous one. If there were\nmore than two ratings, the previous rating was chosen randomly. This yielded \u0014wagreements\n63.2 Inter-rater agreements 4 DISCUSSION\nTable 2: Previously reported intra- and inter-rater agreements together with the test set agreement between\nL.C. and AVRA, and L.C and VGG16 as a reference. The interval given refers to the minimum and maximum\nweighted kappa ( \u0014w) value reported in the referenced study.\nStudy Scale NIntra-rater\nagreement ( \u0014w)Inter-rater\nagreement ( \u0014w)\nCavallin et al. (2012) [3] MTA 100 0.83-0.94 0.72 - 0.84\nCavallin et al. (2012b) [58] MTA 100 0.84-0.85 |\nWestman et al. (2011) [14] MTA 100 0.93 |\nVelickaite et al. (2017) [59] MTA 390 0.79-0.84 0.6-0.65\nFerreira et al. (2017) [15] MTA 120 0.89-0.94 0.70-0.71\nKoedam et al. (2016) [6] MTA 29-118 0.91-0.95 0.82-0.90\nVGG16 MTA 464 1 0.58 - 0.59\nAVRA MTA 464 1 0.72 - 0.74\nKoedam et al. (2016) [6] PA 29-118 0.93-0.95 0.65-0.84\nFerreira et al. (2017) [15] PA 120 0.88 0.88\nVGG16 PA 464 1 0.63\nAVRA PA 464 1 0.74\nFerreira et al. (2016) [12] GCA-F 100 0.70 0.59\nFerreira et al. (2017) [15] GCA-F 120 0.83 0.79\nVGG16 GCA-F 464 1 0.56\nAVRA GCA-f 464 1 0.62\nand accuracies for MTA (left): \u0014w= 0.83, acc = 76%; MTA (right): \u0014w= 0.79, acc = 70%;\nGCA-F:\u0014w= 0.46, acc = 71%; PA \u0014w= 0.65, acc = 72%. Ratings made only 1 week apart\nshowed substantially better intra-rater agreement (see Ferreira et al. (2017) entry in Table 2).\nThese results provide an estimate of the \"human-level agreement\"|i.e. approximate levels of\nagreement our models should be able to achieve by training on the available cohort due to rating\ninconsistencies over 16 months.\nSince there are no random elements in the evaluation process of a brain image, the \"intra-\nrater\" agreement of AVRA is inherently \u0014w= 1.\n3.2. Inter-rater agreements\nOur models predicted continuous rating scores of an image, based on training from discrete\nratings by L.C. We rounded AVRA's ratings to the nearest integer to be able to compare the\nrating consensus in terms of accuracy and kappa statistics. The agreements between the ra-\ndiologist's and AVRA's (as well as the VGG networks') ratings on the hold-out test set are\nsummarized in Table 2 together with previously reported \u0014wvalues of inter- and intra-rater\nagreements. The inter-rater agreement kw, Pearson correlation \u001a, and accuracy on the test set\nfor MTA (left): \u0014w= 0.74, acc = 70 %; MTA (right): \u0014w= 0.72,\u001a= 0.88, acc = 70 %; GCA-F:\n\u0014w= 0.62,\u001a= 0.71, acc = 84 %; PA: \u0014w= 0.74,\u001a= 0.85, acc = 83%. These agreement levels\nwere similar to previously reported in studies, see Table 2. The naive VGG16 implementations\nshowed lower inter-rater agreements with the radiologist compared to AVRA.\nTo increase interpretability and understanding of the models, we computed gradient-based\nsensitivity maps of images in the test set based on the SmoothGrad method [60]. These indicated\nhow in\ruential individual voxels were in the rating prediction, which we can apply to verify that\nthe network identi\fed the correct features. Examples of AVRA's rating predictions for each scale\nare shown in Fig. 4. As can be observed, the MTA sensitivity maps were generally focused only\naround the area of the hippocampus and the inferior lateral ventricle in \u0018\u0006 3 slices from the\n\"correct\" rating slice. The sensitivity maps in other more posterior and anterior slices were close\nto zero. The GCA-F maps were more di\u000bused, but the greatest magnitudes were primarily seen\nin the sulci of the frontal lobe. The PA maps were mainly visible in the parietal lobe and in the\nsagittal plane, with the greatest magnitudes appearing in parieto-occiptal sulcus and precuneus.\n4. Discussion\nWe have developed a tool for automatic visual ratings of atrophy (AVRA) that is fast, sys-\ntematic and robust. AVRA is trained on a large set of images rated by an expert neuroradiologist\nusing the established clinical assessment measures of Scheltens' MTA scale, Pasquier's GCA-F\n74.1 Agreement levels 4 DISCUSSION\nMTA GCA-F PA\nFigure 4: Examples of sensitivity maps for the MTA, GCA-F and PA scale, respectively. These maps indicate the\nin\ruence each voxel had in AVRA's rating. The particular slices displayed were chosen manually as representative\nimages for each rating scale.\nscale and Koedam's PA scale with agreement levels similar to that between two experienced\nradiologists. This tool runs in under 1 minute on a regular laptop, which enables automatically\nrating thousands of images in a couple of hours. Rating an MRI image of the brain requires\nminimum amount of preprocessing and the models were built to potentially work in a clinical\nsetting. The main advantage of an automatic model is the absence of randomness, which can\nensure rating consistency between di\u000berent clinics, research groups and cohorts. Thus, AVRA\nhas potential to function as a clinical aid, and to increase the use of visual ratings in research.\n4.1. Agreement levels\nThe rating agreements between AVRA's and the radiologist's ratings were considered sub-\nstantial (i.e. between 0.6-0.8) according to the often cited paper by Landis and Koch (1977) [61].\nThe agreements were close to the \"human-level agreements\" in this study (i.e. the agreement\nbetween the multiple L.C. ratings of the same image). This was reasonable since a model trained\non imperfect labels due to rating inconsistency can never achieve perfect agreement. A previous\nstudy has investigated the overtime reliability of MTA ratings, where their results showed that\nthe intra-rater agreement is typically higher when a set is rated twice closer in time{especially\nwhen the radiologist do not rate images on a daily basis [3]. The time between ratings is often not\nreported, but in Pasquier's introduction of the GCA scale the second rating was performed 24 h\nafter the \frst [8]. Thus it is reasonable that if all images in a study were rated twice 16 months\napart, the intra-rater agreement would generally be lower than the actual reported values. Our\nanalysis of the subset of images rated more than once suggests this to be the case. Those values\nmay not necessarily re\rect the \"true\" rating consistency either since the multiple-rating subset\ndoes not follow the same distribution as the whole cohort. Limiting the time span between the\n\frst and last set of ratings meant having to discard a large part of the images in the training\nset, and initial investigations of this showed decreasing agreement in our study. This suggested\nthat a large number of images for training was more important than the potential inclusion of\nnoisy labels.\nAVRA's ratings agreed more with the radiologist ratings than the VGG16 models' did. A\nrecurrent CNN architecture might thus be particularly suitable for visual rating predictions, but\nwe can not say from these results if it were the residual modules, the attention components,\nor the LSTM cells|all used in AVRA but not in the VGG16 models|that had the greatest\npositive impact on the performance. Another contributing factor may be the wide di\u000berence\nin the number of trainable parameters between AVRA (1.5M) and VGG16 (65M) that makes\nAVRA less prone to over\ft on the training data. However, it should be noted that we spent more\ntime to tune and optimize AVRA compared to the VGG16 networks, which biases the results in\nfavor of AVRA.\nThe automatic model presented by L otj onen and colleagues (2017) is, to our knowledge, the\nonly software that also attempts to predict scores based on clinical visual rating scales [19]. It is\nbased on volume measures of hippocampus and surrounding structures, whereas AVRA predicts\nthe ratings directly from the voxel intensity values. This makes our proposed method promising\nto also work on MRI images with large slice thickness and CT images, from which volumes\ngenerally cannot be computed. The fact that CT is a cheaper and more commonly used imaging\n84.2 Reliability of AVRA 4 DISCUSSION\n[2.0, 1.9974875]\n [2.0, 2.1983776]\n [2.0, 2.3995764]\n [2.0, 2.5955575]\n [2.0, 2.8299313]\n [2.0, 2.9997928]\n[3.0, 2.045701]\n [3.0, 2.2057319]\n [3.0, 2.3869739]\n [3.0, 2.5828061]\n [3.0, 2.7978511]\n [3.0, 3.0002832]2\n3AVRARadiologist2.0 2.2 2.4 2.6 2.8 3.0\nFigure 5: Comparison between AVRA's continuous ratings and the neuroradiologist's discrete ratings of the\nsame images. Rows : MRI slices with MTA on the right side of the image (side indicated by the red squares)\nrating of 2 (top) and 3 (bottom) given by neuroradiologist. Columns : corresponding continuous AVRA ratings.\nE.g., the second image from the left in the bottom row was given assessed to have a left MTA score of 3 by the\nneuroradiologist and 2.2 by AVRA. When the radiologist re-examined these cases the same ratings were given\nfor all images, except for the three images on the right in the top row (Radiologist: 2, AVRA: 2.6, 2.8 and 3.0),\nwhich were instead given MTA scores of 3. The image rated 2 by L.C. and 2.4 by AVRA was described as a\nsubject between 2 and 3.\nmodality than MRI in the clinics speaks in favor of using convolutional neural networks over\nvolumetrics for automatic ratings of atrophy [62]. No \u0014wvalues are reported in [19], but they\nprovided correlation coe\u000ecients between radiologist and computer ratings for the MTA scale as\n0.86 (left) and 0.85 (right). AVRA showed a similar magnitude of correlation for the MTA scale\non the hold-out test set: \u001a= 0:88.\n4.2. Reliability of AVRA\nOne of the main motivations of having a computer rate brain atrophy instead of humans\nis its inherent perfect intra-rater agreement|the same image will be rated exactly the same\nregardless of when (and where) it is rated. A relevant question to ask is: why not let a computer\nsegment and calculate e.g. hippocampal volumes instead of an MTA rating? We see three main\nmotivations for this: 1) CT, and some MRI protocols, have too large slice thickness that do not\nallow for extracting reliable volumetric information from the images. 2) Segmentaion methods\nwill|just as AVRA|fail in processing some cases, and for clinician to manually intervene and\ndelineate structures would neither be feasible nor practical. If an automatic visual rating would\nfail the radiologist would be able to quickly perform their own visual rating, as is done today.\n3) There is a lack of how to clinically interpret volumetric data, e.g. the hippocampal volumes.\nHowever, extensive research has been done on cut-o\u000bs for visual rating scales, even considering\nmodulating factors such as age [13].\nThe sensitivity maps shown in Fig. 4 suggested that the models were able to correctly\nidentify relevant structures to base their ratings on. Particularly the sensitivity maps of the\nMTA model were typically not visible \u00063mm from the \"correct\" rating slice, indicating that\nthe employed recurrent CNN architecture used was able to correctly identify relevant slices\nand disregard redundant ones. The di\u000bused sensitivity maps seen for the GCA-F scale was also\nobserved in the quantitative validation study done by Ferreira et al. (2015), showing that frontal\natrophy is also associated with temporal and posterior atrophy|at least in the ADNI cohort\n[12]. M oller and colleagues (2014) found, using VBM analysis, signi\fcant di\u000berences between PA\nratings not only in the parietal lobe, but also in parts of the cerebellum, temporal lobe and the\noccipital lobe [11]. Their study was also performed on a cohort with individuals with probable\nAD and subjective memory complaints, concluding that atrophy solely in the posterior cortex\nis an exception. The sensitivity maps from our PA model indicate that AVRA based the PA\nratings on mainly the same regions. AVRA learns to how to predict a GCA-F or a PA score from\nan MRI image only based on previous human ratings. Thus, if e.g. frontal atrophy is strongly\nassociated with atrophy in the temporal lobe, the model is likely to \fnd it di\u000ecult to learn to\nonly assess the frontal lobe in the GCA-F scale. Since the sensitivity maps are based on the\nabsolute values of the calculated gradients in the backward propagation, the magnitude of these\n94.2 Reliability of AVRA 4 DISCUSSION\n0 1 2 3 4\nRadiologist rating-2.0-1.5-1.0-0.50.00.51.01.52.0(AVRA - Radiologist)MTA\nPA\nGCA-F\nFigure 6: Box plots of the di\u000berence between AVRA's continuous and the radiologist's discrete ratings of the\nsame image (strati\fed by radiologist score) for the MTA (red), GCA-F (green), and the PA scale (blue). There\nwere no images assigned a rating of GCA-F=3 by the radiologist and only 1 image with PA=3 in the test set,\nwhich explains the absence of boxes for these ratings.\ndecrease every time it propagates through the LSTM cell due to the point-wise multiplication in\nthe forget gate [52]. The PA model inputs 99 slices. As the sagittal slices are the last to be fed\nto the model it is reasonable to assume that they dominate the sensitivity maps as opposed to\nearly axial slices, which have propagated through the LSTM cell almost 100 times.\nThe performance of AVRA was validated in a test set that was randomly sampled from the\nsame cohorts as the training data set. This means that the data distribution in the test set was\nsimilar to the image samples that the models were trained on. This is a simpler test set than if\nthe test set was from a di\u000berent cohort with images acquired using other scanning parameters.\nWe are currently in the process of validating how the models would handle data from a di\u000berent\nimage distribution (cohort), and the e\u000bect it would have on the rating agreement.\nFrequently, it is di\u000ecult for a radiologist to decide between two scores, and in a clinical\nsituation the level of atrophy is often described as \"the left MTA is between 2 and 3\" for\ninstance. This nuance might be important information for the physician diagnosing dementia,\nbut in research single integer scores have typically been used following the original de\fnitions\nof the rating scales. Previous attempts of (semi-)automatic atrophy measures have output a\ncontinuous measure [17, 18, 63, 19]. The main advantages of using a continuous measure of\natrophy are 1) atrophy evolves continuously and thus it is reasonable to describe its degree\nthrough a continuous measure, and 2) it provides more detailed information about the severity\nof the atrophy. The latter point is for instance particularly useful to track disease progression\nand could allow us to establish more sensitive cut-o\u000b values for di\u000berent diagnoses. It is also\neasy to convert the continuous measures of the rating scales to their discrete, original versions\nby rounding to nearest integer.\nIn Fig. 5 we show some examples between AVRA's continuous and the radiologist discrete\nratings in the important diagnostic interval between MTA=2 and MTA=3. When studying\nthese images again post AVRA's ratings, the radiologist only assessed that the images originally\nrated MTA=2 with associated AVRA scores of 2.6-3.0 to be wrongly rated. They would be\nre-rated as MTA=3, i.e. closer to AVRA's score. The image scored MTA=2 (radiologist) and\nMTA=2.4 (AVRA) was described as a case between 2 and 3, which may illustrate the usefulness\nof continuous ratings. However, we noticed that in two of the most disagreeing ratings (L.C.:\nMTA=3, Avra: MTA= f2.0, 2.2g) the individuals had an adhesion between the hippocampus\nand the cerebral white matter. These cases are not frequent, and the rating disagreements in Fig.\n5 indicate that AVRA did not learn to correctly adjust the score for the presence of adhesions.\nWe aimed to design AVRA to function on images with the least amount of preprocessing\npossible to demonstrate that it could work in a clinical setting. A few concessions were made to\nfacilitate the training process|mainly the AC-PC alignment performed through rigid registra-\n104.3 Limitations 5 CONCLUSION\ntion to the MNI brain using FSL FLIRT. This helped centering all images to allow for tighter\ncropping around the structures of interest. However, this automatic preprocessing step failed in\naround 2.5% of all images, which were discarded for future training and evaluation although the\nquality of most of the images was good enough for a radiologist to visually rate it. Since the\nMRI image input to CNN has not been intensity normalized, skull stripped or motion corrected,\nit is possible to perform a manual AC-PC alignment for the failed cases and then input them\nto the model. More extensive data augmentation and training, or using reinforcement learning\nto \fnd the correct slice, could potentially be used to avoid the AC-PC alignment step and just\ninput the raw MRI image. This was, however, not explored in the current study.\n4.3. Limitations\nThere are some limitations of the proposed algorithm. First, the models are solely based on\nthe ratings by a single radiologist and thus assume that the ratings we trained the model on are\n\"ground truth\" labels. A model trained on these labels can therefore never be \"better\" than the\nrater. If the ratings have systematic errors the model will incorporate these. For instance, a rater\nmight systematically look at the left medial temporal lobe when rating the MTA of the right\nhemisphere, which could in\ruence (bias) the right hemisphere MTA score. If we train a model\non these ratings, this bias would be learned by the model as well. Another approach would be to\nhave multiple expert radiologists rate a set of images together or separately and use these labels\nas ground truth. However, it is not feasible to have multiple radiologist visually assess the large\nnumber of images necessary for training a deep neural network. It also does not automatically\nmean that these ratings would necessarily be \"closer\" to the ground truth. If future studies want\nto use a neural network based on their own set of ratings, it should be possible to start from the\npre-trained networks of AVRA and \fne-tune the \fnal classi\fcation layer(s) on the new ratings.\nThis would require substantially fewer ratings, since the convolutional part would already have\nlearned to extract relevant features from the images.\nThe second limitation of the study are the small numbers of the highest GCA-F and PA\nratings, which may increase the risk of \"true\" 3 score to be misclassi\fed. Based on the results\nin Fig. 6 this seems to be the case. As the diagnostic cut-o\u000b values for these ratings scales in\nAD diagnosis have been suggested as PA \u00151 and GCA-F\u00151 [13], the clinical implications of this\nmay be minor even in the cases where the atrophy is rated as a 2 instead of a 3. These severe\nratings are rare also in previous studies on dementia cohorts [13, 64], so this will likely be an\nissue for any computerized method trained on radiologist ratings.\n5. Conclusion\nIn this study, we have proposed an automatic method (AVRA) to provide visual ratings of\natrophy according to Scheltens' MTA scale, Koedam's PA scale, and Pasquier's frontal GCA\nscale. AVRA mimics the neuroradiologist's rating procedure and achieves similar levels of agree-\nment to that between two experienced neuroradiologists|without any prior preprocessing of the\nMRI images. We plan to make AVRA freely available as a user-friendly software aimed towards\nneuroscientists and neuroradiologists.\nAcknowledgements\nWe would like to thank the Swedish Foundation for Strategic Research (SSF), The Swedish\nResearch Council (VR), the Strategic Research Programme in Neuroscience at Karolinska Insti-\ntutet (StratNeuro), Swedish Brain Power, the regional agreement on medical training and clini-\ncal research (ALF) between Stockholm County Council and Karolinska Institutet, Hj arnfonden,\nAlzheimerfonden, the \u0017Ake Wiberg Foundation and Birgitta och Sten Westerberg for additional\n\fnancial support.\nData collection and sharing for this project was funded by the Alzheimer's Disease Neu-\nroimaging Initiative (ADNI) (National Institutes of Health Grant U01 AG024904) and DOD\nADNI (Department of Defense award number W81XWH-12-2-0012). ADNI is funded by the\nNational Institute on Aging, the National Institute of Biomedical Imaging and Bioengineer-\ning, and through generous contributions from the following: AbbVie, Alzheimer's Association;\n11References REFERENCES\nAlzheimer's Drug Discovery Foundation; Araclon Biotech; BioClinica, Inc.; Biogen; Bristol-\nMyers Squibb Company; CereSpir, Inc.; Cogstate; Eisai Inc.; Elan Pharmaceuticals, Inc.; Eli\nLilly and Company; EuroImmun; F. Ho\u000bmann-La Roche Ltd and its a\u000eliated company Genen-\ntech, Inc.; Fujirebio; GE Healthcare; IXICO Ltd.; Janssen Alzheimer Immunotherapy Research\n& Development, LLC.; Johnson & Johnson Pharmaceutical Research & Development LLC.;\nLumosity; Lundbeck; Merck & Co., Inc.; Meso Scale Diagnostics, LLC.; NeuroRx Research;\nNeurotrack Technologies; Novartis Pharmaceuticals Corporation; P\fzer Inc.; Piramal Imag-\ning; Servier; Takeda Pharmaceutical Company; and Transition Therapeutics. The Canadian\nInstitutes of Health Research is providing funds to support ADNI clinical sites in Canada. Pri-\nvate sector contributions are facilitated by the Foundation for the National Institutes of Health\n(www.fnih.org ). The grantee organization is the Northern California Institute for Research and\nEducation, and the study is coordinated by the Alzheimer's Therapeutic Research Institute at\nthe University of Southern California. ADNI data are disseminated by the Laboratory for Neuro\nImaging at the University of Southern California.\nReferences\n[1] Lorna Harper, Frederik Barkhof, Nick C. Fox, and Jonathan M. Schott. Using visual rating to\ndiagnose dementia: A critical evaluation of MRI atrophy scales. Journal of Neurology, Neurosurgery\nand Psychiatry , 86(11):1225{1233, 2015.\n[2] Lars Olof Wahlund, Eric Westman, Danielle van Westen, Anders Wallin, Sara Shams, Lena Cavallin,\nand Elna Marie Larsson. Imaging biomarkers of dementia: recommended visual rating scales with\nteaching cases. Insights into Imaging , 8(1):79{90, 2017.\n[3] Lena Cavallin, Kirsti L\u001cken, Knut Engedal, Anne Rita \u001fkseng\u0017 ard, Lars Olof Wahlund, Lena\nBronge, and Rimma Axelsson. Overtime reliability of medial temporal lobe atrophy rating in a\nclinical setting. Acta Radiologica , 53(3):318{323, 2012.\n[4] Lars-Olof Wahlund, Per Julin, Johan Lindqvist, and Philip Scheltens. Visual assessment of me-\ndial temporal lobe atrophy in demented and healthy control subjects: correlation with volumetry.\nPsychiatry Research: Neuroimaging , 90(3):193{199, 1999.\n[5] Philip Scheltens, D Leys, F Barkhof, D Huglo, H C Weinstein, P Vermersch, M Kuiper, M Steinling,\nE Ch Wolters, and J Valk. Atrophy of medial temporal lobes on MRI in \"probable\" Alzheimer's\ndisease and normal ageing: diagnostic value and neuropsychological correlates. Journal of Neurology\nNeurosurgery, and Psychiatry , 55:967{972, 1992.\n[6] Esther L.G.E. Koedam, Manja Lehmann, Wiesje M. Van Der Flier, Philip Scheltens, Yolande A.L.\nPijnenburg, Nick Fox, Frederik Barkhof, and Mike P. Wattjes. Visual assessment of posterior\natrophy development of a MRI rating scale. European Radiology , 21(12):2618{2625, 2011.\n[7] Philip Scheltens, Florence Pasquier, Jan G.E. Weerts, Frederik Barkhof, and Didier Leys. Qualita-\ntive assessment of cerebral atrophy on MRI: inter- and intra- observer reproducibility in dementia\nand normal aging. European Neurology , 37(2):95{99, 1997.\n[8] Florence Pasquier, Didier Leys, Jan G.E. Weerts, Francois Mounier-Vehier, Frederik Barkhof, and\nPhilip Scheltens. Inter-and intraobserver reproducibility of cerebral atrophy assessment on mri\nscans with hemispheric infarcts. European Neurology , 36(5):268{272, 1996.\n[9] Lorena Bresciani, Roberta Rossi, Cristina Testa, Cristina Geroldi, Samantha Galluzi, Mikko P.\nLaakso, Alberto Beltramello, Hilkka Soininen, and Giovanni B. Frisoni. Visual assessment of medial\ntemporal atrophy on MR \flms in Alzheimer's disease: Comparison with volumetry. Aging clinical\nand experimental research , 17(May 2014):8{13, 2005.\n[10] Wouter J.P. Henneman, Jasper D. Sluimer, Charlotte Cordonnier, Merel M.E. Baak, Philip Schel-\ntens, Frederik Barkhof, and Wiesje M. Van Der Flier. MRI biomarkers of vascular damage and\natrophy predicting mortality in a memory clinic population. Stroke , 40(2):492{498, 2009.\n[11] Christiane M oller, Wiesje M. Van Der Flier, Adriaan Versteeg, Marije R. Benedictus, Mike P. Wat-\ntjes, Esther L G M Koedam, Philip Scheltens, Frederik Barkhof, and Hugo Vrenken. Quantitative\nregional validation of the visual rating scale for posterior cortical atrophy. European Radiology ,\n24(2):397{404, 2014.\n12REFERENCES REFERENCES\n[12] Daniel Ferreira, Lena Cavallin, Tobias Granberg, Olof Lindberg, Carlos Aguilar, Patrizia Mecocci,\nBruno Vellas, Magda Tsolaki, Iwona K loszewska, Hilkka Soininen, Simon Lovestone, Andrew Sim-\nmons, Lars Olof Wahlund, and Eric Westman. Quantitative validation of a visual rating scale\nfor frontal atrophy: associations with clinical status, APOE e4, CSF biomarkers and cognition.\nEuropean Radiology , 26(8):2597{2610, 2016.\n[13] Daniel Ferreira, Lena Cavallin, Elna-Marie Larsson, J-Sebastian. Muehlboeck, Patrizia Mecocci,\nBruno Vellas, Magda Tsolaki, Iwona K loszewska, Hilkka Soininen, Simon Lovestone, Andrew Sim-\nmons, Lars-Olof Wahlund, and Eric Westman. Practical cut-o\u000bs for visual rating scales of medial\ntemporal, frontal and posterior atrophy in Alzheimer's disease and mild cognitive impairment.\nJournal of Internal Medicine , 278(3):277{290, 2015.\n[14] Eric Westman, Lena Cavallin, J. Sebastian Muehlboeck, Yi Zhang, Patrizia Mecocci, Bruno Vellas,\nMagda Tsolaki, Iwona K loszewska, Hilkka Soininen, Christian Spenger, Simon Lovestone, Andrew\nSimmons, and Lars Olof Wahlund. Sensitivity and speci\fcity of medial temporal lobe visual ratings\nand multivariate regional MRI classi\fcation in Alzheimer's disease. PLoS ONE , 6(7), 2011.\n[15] Daniel Ferreira, Chlo e Verhagen, Juan Andr\u0013 es Hern\u0013 andez-Cabrera, Lena Cavallin, Chun Jie Guo,\nUrban Ekman, J. Sebastian Muehlboeck, Andrew Simmons, Jos\u0013 e Barroso, Lars Olof Wahlund,\nand Eric Westman. Distinct subtypes of Alzheimer's disease based on patterns of brain atrophy:\nLongitudinal trajectories and clinical applications. Scienti\fc Reports , 7(April):1{13, 2017.\n[16] Rebecca Elliott. Executive functions and their disorders. Imaging neuroscience: clinical frontiers\nfor diagnosis and management , 65(March):49{59, 2003.\n[17] Anna Zimny, Joanna Bladowska, Ma lgorzata Neska, Kamila Petryszyn, Maciej Guzi\u0013 nski, Pawe l\nSzewczyk, Jerzy Leszek, and Marek S\u0018 asiadek. Quantitative MR evaluation of atrophy, as well as\nperfusion and di\u000busion alterations within hippocampi in patients with Alzheimer's disease and mild\ncognitive impairment. Medical science monitor : international medical journal of experimental and\nclinical research , 19:86{94, 2013.\n[18] Manuel Men\u0013 endez-Gonz\u0013 alez, Alfonso L\u0013 opez-Mu~ niz, Jos\u0013 e A. Vega, Jos\u0013 e M. Salas-Pacheco, and Oscar\nArias-Carri\u0013 on. MTA index: A simple 2D-method for assessing atrophy of the medial temporal lobe\nusing clinically available neuroimaging. Frontiers in Aging Neuroscience , 6(MAR):1{6, 2014.\n[19] Jyrki Lotjonen, Juha Koikkalainen, Hanneke F M Rhodius Meester, Wiesje M Van Der Flier, Philip\nScheltens, Frederik Barkhof, and Timo Erkinjuntti. Computed rating scales for cognitive disorders\nfrom MRI. Alzheimer's & Dementia: The Journal of the Alzheimer's Association , 13(7):P1108,\n2017.\n[20] Yann Lecun, Yoshua Bengio, and Geo\u000brey Hinton. Deep learning. Nature , 521(7553):436{444, 2015.\n[21] Dinggang Shen, Guorong Wu, Heung-il Suk, and Cognitive Engineering. Deep Learning in Medical\nImage Analysis. Annual Review of Biomedical Engineering , 19(1):221{248, 2017.\n[22] Geert Litjens, Thijs Kooi, Babak Ehteshami Bejnordi, Arnaud Arindra Adiyoso Setio, Francesco\nCiompi, Mohsen Ghafoorian, Jeroen A.W.M. van der Laak, Bram van Ginneken, and Clara I.\nS\u0013 anchez. A survey on deep learning in medical image analysis. Medical Image Analysis , 42(December\n2012):60{88, 2017.\n[23] Andre Esteva, Brett Kuprel, Roberto A. Novoa, Justin Ko, Susan M. Swetter, Helen M. Blau,\nand Sebastian Thrun. Dermatologist-level classi\fcation of skin cancer with deep neural networks.\nNature , 542(7639):115{118, 2017.\n[24] Thijs Kooi, Geert Litjens, Bram van Ginneken, Albert Gubern-M\u0013 erida, Clara I. S\u0013 anchez, Ritse\nMann, Ard den Heeten, and Nico Karssemeijer. Large scale deep learning for computer aided\ndetection of mammographic lesions. Medical Image Analysis , 35:303{312, 2017.\n[25] Varun Gulshan, Lily Peng, Marc Coram, Martin C. Stumpe, Derek Wu, Arunachalam\nNarayanaswamy, Subhashini Venugopalan, Kasumi Widner, Tom Madams, Jorge Cuadros, Ra-\nmasamy Kim, Rajiv Raman, Philip C. Nelson, Jessica L. Mega, and Dale R. Webster. Development\nand validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus\nphotographs. JAMA - Journal of the American Medical Association , 316(22):2402{2410, 2016.\n[26] Snehashis Roy, John A. Butman, and Dzung L. Pham. Robust skull stripping using multiple MR\nimage contrasts insensitive to pathology. NeuroImage , 146(November 2016):132{147, 2017.\n13REFERENCE"}
{"date": "2024-01-04-22-29", "error": false, "url": "PDF", "text_blocks": "PrideMM:\nA Solver for Relaxed Memory Models\nSimon Cooksey1, Sarah Harris1, Mark Batty1, Radu Grigore1, and\nMikol\u0013 a\u0014 s Janota2\n1University of Kent,\n2IST/INESC-ID, University of Lisbon\nAbstract Relaxed memory models are notoriously delicate. To ease\ntheir study, several ad hoc simulators have been developed for axiomatic\nmemory models. We show how axiomatic memory models can be simulated\nusing a solver for 9SO. Further, we show how memory models based on\nevent structures can be simulated using a solver for MSO. Finally, we\npresent a solver for SO, built on top of QBF solvers.\n1 Introduction\nUnderstanding processor and language concurrency is an essential step in building\nreliable systems. Formal modelling and simulation have exposed \raws [4,39,51,52]\nand led to re\fnements [1, 10] in the o\u000ecial descriptions of concurrency in key\nlanguages and processors. Current simulators rely on ad hoc algorithms [5,10,19]\nor SAT solvers [53]. However, \raws in existing language concurrency models [9] {\nwhere one must account for behaviour introduced through aggressive optimisation\n{ have led to a new class of models [27,29] that cannot be simulated with previous\nad hoc methods and \ft awkwardly in the limited language of SAT, making\nsimulation unworkable.\nThis paper presents PrideMM, a tool that both simulates the more intricate\nmodels of aggressively optimised concurrent languages and replicates the function-\nality of previous tools. PrideMM identi\fes second order (SO) logic as expressive\nenough to capture the wider set of concurrency models, while restrictive enough\nto enable automatic solving. PrideMM uses a new checker, built above rapidly\nimproving quanti\fed boolean formula (QBF) solvers, that solves SO logic formulas\ndirectly.\nThe following contributions underpin PrideMM:\n1. we demonstrate simulation of existing models using a solver for 9SO,\n2. we present a model checker for SO, built on top of QBF solvers, and\n3.we simulate the Je\u000brey and Riely model { one of a new class of concurrency\nmodels for optimised concurrent languages { using a solver for SO.\n1.1 Modelling Relaxed Memory Models\nProcessor speculation, memory-subsystem reordering and compiler optimisations\nlead mainstream languages and processors to violate sequential consistency , aarXiv:1901.00428v1  [cs.LO]  8 Dec 2018a: Rx1\nb: W y1c: Ry1\nd: W x1rf\nrfpo poinitially x = 0, y = 0\nr1 = x r2 = y\nif (r1 == 1) if (r2 == 1)\nfy = 1g fx = 1g\nr1 == 1, r2 == 1 allowed?acyclic( po[rf)\nFigure 1: LB+ctrl, an axiomatic execution of it, and an axiom that forbids it.\nmodel of memory where accesses are simply interleaved [33]. We say such systems\nexhibit relaxed concurrency . Relaxed concurrency is commonly described in\nanaxiomatic model, where each program behaviour is represented as graph of\nmemory accesses, and a set of axioms \flters forbidden execution graphs.\nHerd is a simulator of axiomatic models that has been used extensively\nto model processor, GPU, and language concurrency [5]. In Herd, the model\nis expressed as a predicate on execution graphs, written in the propositional\nrelation calculus, and recorded in a .cat \fle. Figure 1 presents load bu\u000bering with\ncontrol dependencies (LB+ctrl), a small program called a litmus test constructed\nto probe for a single relaxed behaviour, together with an execution graph and an\naxiom as it would appear in a .cat \fle. LB+ctrl consists of two parallel threads\nthat read x(ory) and then conditionally write y(orx), with xandyinitialised\nto 0. The outcome 1/1 represents a relaxed behaviour, and is allowed in particular\nby the current C++ standard, but forbidden under the SC, x86, Power and ARM\nmodels. The graph of Figure 1 presents the execution in question, with memory\nreads and writes as vertices (eliding the initialisation) and edges representing\nprogram order ( po) and the writes that each read reads from ( rf). The axiom\nof Figure 1 forbids the outcome 1/1 as the corresponding execution contains a\ncycle in po[rf. The SC, x86, Power and ARM models each include a variant of\nthis axiom, all forbidding 1/1.\nHerd uses an ad hoc algorithm for judging whether an execution is allowed.\nIts performance is surpassed by the Memalloy [53] tool built above SAT-based\nAlloy, so it is clear that the judgement of axiomatic models can be expressed as a\nSAT problem. Unfortunately, not all memory models \ft the axiomatic paradigm.\nAxiomatic models do not \ft optimised languages. Languages like C++ and\nJava perform dependency-removing optimisations that complicate their memory\nmodels. For example, the second thread of the LB+false-dep test in Figure 2\ncan be optimised using common subexpression elimination to r2=y; x=1; . On\nARM and Power, this optimised code may be reordered, permitting the relaxed\noutcome 1/1, whereas the syntactic dependency of the original would make\n1/1 forbidden. It is common practice to use syntactic dependencies to enforce\nordering on hardware, but at the language level the optimiser removes these fake\ndependencies.\nThe C++ standard is \rawed because it describes an axiomatic language\nmodel that cannot draw a distinction between the executions leading to outcome\n2initially x = 0, y = 0\nr1 = x r2 = y\nif (r1 == 1) if (r2 == 1)\nfy = 1g fx = 1g\nelse\nfx = 1g\nr1 == 1, r2 == 1 allowed?Init\na: Rx0 b: Rx1\nc: W y1d: Ry0\ne: W x1f: Ry1\ng: W x1ord\nord ordord\nord ord ordconf conf\nFigure 2: LB+false-ctrl and the corresponding event structure.\n1/1 in LB+dep and LB+false-dep: the details of other branches of control \row\nhave been stripped and they have precisely the same vertices and edges [9]\nEvent structures capture the necessary information. A new class of models\naims to \fx this by ordering only real dependencies [27,29,42]. With a notable\nexception [29], these models are based on event structures , where all paths of\ncontrol \row are represented in a single graph. Figure 2 presents the event structure\nfor LB+false-deps. Program order is captured by the ordrelation. Con\rict , the\nconf edge, links events where only one can occur in an execution (the same holds\nfor their ord-successors). For example, on the left-hand thread, the load of xcan\nresult in a read of value 0 (event a) or a read of value 1 (event b), but not both.\nConversely, two subgraphs unrelated by ordorconf, e.g.fa;b;cgandfd;e;f;gg,\nrepresent two threads in parallel execution.\nIt should be clear from the event structure in Figure 2 that regardless of\nthe value read from yin the right-hand thread, there is a write to xof value 1,\ni.e. the apparent dependency from the load of yis fake and could be optimised\naway. Memory models built above event structures can recognise this pattern\nand permit relaxed execution.\nThe Je\u000brey and Riely model. Je\u000brey and Riely proposed a concurrency model\n(henceforth referred to as J+R) built above event structures that correctly\nidenti\fes fake dependencies [27]. Conceptually, the model is related to the Java\nmemory model [36]: in both, one constructs an execution stepwise, adding only\nmemory events that can be justi\fed from the previous steps. The sequence\ncaptures a causal order and prevents cycles that could lead to thin-air values.\nWhile Java is too strong, the J+R model allows writes that have fake dependencies\non a read to be justi\fed before that read. To do this, the model recognises\ncon\ruence in the program structure: regardless of the execution path, the write\nwill always be made. This search across execution paths involves alternation\nof quanti\fcation that current ad hoc and SAT-based tools cannot e\u000eciently\nsimulate. The problem is amenable to the new breed of QBF solvers.\n31.2 Solvers\nThe late 90's brought about a surge of practical applications of SAT solvers [11,38].\nQBF provides a more expressive language and therefore less burden on the modeler\nbut it is also inherently harder. Indeed, QBF is PSPACE-complete, whereas SAT\nis \\only\" NP-complete. Initially QBF solving mainly focused on adapting SAT\ntechniques to quanti\fers [56]. In the last decade, however, there has been a\nproli\fc activity in the \feld leading to several independent paradigms. There\nhas been a remarkable progress in the area almost each year [7, 17, 18, 20, 25,\n26, 30, 35, 41, 45 {47, 49, 50]. This evolution has also been traced by the yearly\nQBF competitions [43], see also [37]. These improvements suggest that it may be\nbene\fcial to integrate modern QBF technology into formal veri\fcation tools.\nWe highlight the algorithm RAReQS [20,24] with its recent improvements [22].\nThe algorithm has exhibited highly competitive performance in formulas coming\nfrom practical applications and with small number of quanti\fer levels. Hence,\nRAReQS is a natural candidate for the problems targeted in this paper. Never-\ntheless, other solvers are also included in the evaluation (see section 6).\nFrom practical perspective, it is important to mention the input format\nto QBF solvers. Unlike in SAT, CNF input has been observed as extremely\nharmful to QBF solving [6,21,55]. This has been re\rected by recent e\u000borts to\npromote solvers that accept a circuit-like format QCIR [28]. Hence, QBF solvers\ncan be classi\fed according to which of the two inputs they support. During\nthe experimental evaluation we have observed that the circuit-based solvers\ndramatically outperform the CNF-based ones (see section 6).\nWe should mention that there are other tools dedicated to automated solving\nin higher-order logic. Namely higher order model \fnders [13] or automated higher\norder theorem provers [15]. Even though one could encode the problems considered\nin this paper into those tools, their ultimate focus are mainly mathematical\ntheorems. Hence, applying these tools to our problems would likely lead to poor\nperformance: a scenario of a using a sledgehammer to crack a nut.\n2 Overview\nFigure 3 shows the architecture of our memory-model simulator. The input is LISA\ncode, and the output is a yes/no answer. LISA is a programming language that\nhas been designed for studying memory models [2]. This language enables writing\nmulti-threaded programs and asking questions about whether certain behaviours\nare allowed. Using LISA as our input format enables a comparison with the\nstate-of-the-art memory-model simulator Herd [5]. The LISA frontend produces\nan event structure [54]. Any event structure is trivially representable as a SO\nlogic structure, so the conversion is simple. The MM generator (memory-model\ngenerator) produces a SO formula. We have a few interchangeable MM gen-\nerators (section 4). For some memory models (subsection 4.1, subsection 4.2,\nsubsection 4.3), which Herd can handle as well, the formula is in fact \fxed and\ndoes not depend at all on the event structure. For other memory models (such\n4as subsection 4.4), the MM generator might need to look at certain characteristics\nof the event structure (such as its size). Finally, both the second-order structure\nand the second-order formula are fed into a solver, which e\u000bectively simulates\nthe program under the memory-model, and gives a verdict.\nLISA codeLISA frontend event structure MM generator formula\nconverter SO structure SO solver\nFigure 3: From a LISA test case to a Y/N answer, given by the SO solver.\nWe build on prior work from two di\u000berent areas { relaxed memory models,\nand SAT/QBF solving: the LISA frontend comes from the Herd memory-model\nsimulator [5], the MM generators implement memory models that have been\npreviously proposed [27, 32], and the SO solver is based on a state-of-the-art\nQBF solver [22]. Our main contribution to the area of relaxed memory models\nis that we widen the class of memory models that can be e\u000eciently simulated.\nOur main contribution to SAT/QBF solving is that we widen the applicability of\nsuch tools.\nApplying SAT technology to simulate memory models has been tried be-\nfore [53]. But, although it did lead to performance improvements, it did not\nwiden the class of models that can be e\u000eciently simulated. We are able to do so\nbecause of a key insight: relational second-order logic represents a sweet-spot in\nthe design space. On the one hand, it is expressive enough such that encoding\nmemory models is natural. On the other hand, it is simple enough such that it\ncan be solved e\u000eciently, using emerging QBF technology.\nConsider for example the sequentially consistent memory model. It is often\ndescribed by saying that there exists a reads-from relation rfand a coherence\norder cosuch that the transitive closure of rf[co[(rf\u00001;co)[pois acyclic. Here,\npois the (\fxed) program-order relation, and it is understood that coandrfsatisfy\ncertain further axioms. In our setting, we describe the sequentially consistent\nmodel as follows. We represent rfand coby existentially-quanti\fed SO arity-2\nvariables Ycoand Yrf, respectively. For example, to say ( x;y)2co, we use the\nformula Yrf(x;y). The program order pois represented by an interpreted arity-2\nsymbol<. Then, the SO formula that represents rf[co[(rf\u00001;co)[pois\nR(y;z):=Yrf(y;z)_Yco(y;z)_9x\u0000\nYrf(x;z)^Yco(x;y)\u0001\n_(y<z ) (1)\nThe de\fnition from above should be interpreted as a macro expansion rule: the\nleft-hand side R(y;z) is a macro that expands to the formula on right-hand side.\nTo require that the transitive closure of Ris acyclic we require that there exists\na relation that includes R, is transitive, and irre\rexive:\n9Z\u0000\nsub2(R;Z)^trans(Z)^irre\r(Z)\u0001\n(2)\n5The macros sub2,trans,irre\r are de\fned as one would expect. For example,\nsub2(P;Q), which says that the arity-2 relation Pis included in the arity-2\nrelationQ, is8xy\u0000\nP(x;y)^Q(x;y)\u0001\n. In short, the translation from the usual\nformulation of memory-models into the SO logic encoding that we propose is\nnatural and almost automatic. In section 4, we describe this translation in detail\nfor 4 memory models. One of these models (subsection 4.4) illustrates that the\ntranslation is not entirely automatic: some care is required to skirt exponential\nblowup.\nTo represent programs and their behaviours uniformly for all memory models,\nwe use event structures. These have the ability to represent an overlay of potential\nexecutions. Some memory-models require reasoning about several executions at\nthe same time: this is a salient feature of the J+R memory model.\nOnce we have the program and its behaviour represented as a logic structure A\nand the memory model represented as a logic formula \u001e, we ask whether the\nstructure satis\fes the formula, written Aj=\u001e. In other words, we have to solve a\nmodel-checking problem for second-order logic, which reduces to QBF solving\nbecause the structure Ais \fnite. As a foretaste, consider the SO formula\n9X \n8xy\u0000\n(ord(x;y)^X(y))!X(x)\u0001\n^\n8xy\u0000\n(X(x)^X(y))!:conflict (x;y)\u0001!\n(3)\nwhich asks if there exists an execution Xthat is downward closed with respect\nto the order ordand does not contain con\ricting events. We wish to evaluate\nthis formula on a structure Ade\fned by\nA=f1;2;3g ordA:=f(1;2);(1;3)g conflictA:=f(2;3)g (4)\nThis structure contains three events that are partially ordered (with 1 coming\n\frst). Events 2 and 3 are con\ricting. The QBF question we ask is the following:\n8x1x2x3\u0000\n(x2!x1)^(x3!x1)^:(x2^x3)\u0001\n(5)\nTo represent the arity-1 second-order variable Xwe introduced 3 (Boolean) QBF\nvariables x1;x3;x3. In general, an arity- ksecond-order variable is encoded into\njAjkQBF variables. The \frst order quanti\fers ( 8xy) disappeared altogether,\nbecause they were expanded. The relation names ordand conflict do not\nappear anymore either, because, once we \fxed xandy, we could replace them\nby true/false constants that were simpli\fed away. For example, ord(2;3) was\nreplaced by `false', which was simpli\fed away; and ord(1;2) was replaced by\n`true', which was also simpli\fed away.\nObserve that (5)is in fact a SAT instance. This is because the formula (3)\ndoes not contain universal second-order variables. When such universal variables\nare present, they give rise naturally to universal QBF variables.\nIt is well known that SO \fnite model-checking can be reduced to QSAT.\nHowever, in practice it is important to know how the reduction is done. We give\nthe details of our reduction in section 5. We have implemented this reduction\ntwice, independently. One implementation is built-in the SO solver and optimised;\n6the other implementation is an optional backend for the MM generators. Having\ntwo implementations that agree increases our con\fdence that they are correct.\nFurther, the MM generator backend produces formulas in the QCIR format,\nwhich can be solved using multiple QBF solvers.\nWe illustrate the generality of our approach by implementing the MM gen-\nerator component for 4 memory models, including one that cannot be handled\nby existing simulators. These 4 MM generators are implemented on top of an\nOCaml API that provides combinators such as sub2,trans, and irre\r. Since this\nAPI has 4 users, we believe it is reusable.\nThree of the four memory models we described could be described in the CAT\nlanguage [3], but not J+R. As future work, we aim to extend the CAT language,\nand implement a generic MM generator that can handle this extended CAT.\n3 Preliminaries\nThe standard problem solved by simulators is to decide whether a given program\nbehaviour is allowed by a given memory model. The standard model checking\nproblem is to decide whether a given structure Asatis\fes a formula \u001e, written\nAj=\u001e. We will describe program behaviours by relational structures A, and\nmemory models by second-order formulas \u001e.\nWe now recall standard de\fnitions [34]. A (\fnite, relational) vocabulary\u001bis a\n\fnite collection of constant symbols (a,b, . . . ) together with a \fnite collection of\nrelation symbols (Q,R, . . . ). A (\fnite, relational) structure Aover vocabulary \u001b\nis a tuplehA;bA;cA;:::;QA;RA;:::iwhereAis a \fnite set called universe with\nseveral distinguished elements aA;bA;:::and relations QA;RA;:::To simplify\nthe presentation, we will assume that the universe AisfaA\n1;:::;aA\nng, and that the\nconstant symbols include a1;:::;an, which denote the elements of the universe.\nFor each distinguished relation such as QA, there is a ksuch thatQA\u0012Ak; we\nsay thatkis the arity ofQA. We assume a countable set of \frst-order variables\n(x,y, . . . ); for each arity k > 0, we assume a countable set of second-order\nvariables (Xk,Yk, . . . ). In particular, we think of the arity as being part of\nthe variable name, and we single it out only when necessary. A variable\u000bis a\n\frst-order variable or a second-order variable; a termtis a \frst-order variable\nor a constant symbol; a predicatePkis a second-order variable or a relation\nsymbol. A (second-order) formula\u001eis de\fned inductively: (a) if Pkis a predicate\nandt1;:::;tkare terms, then Pk(t1;:::;tk) is a formula; (b) if \u001e1and\u001e2are\nformulas, then \u001e1Z\u001e2is a formula; (c) if \u000bis a variable and \u001eis a formula, then\n8\u000b\u001eand9\u000b\u001eare formulas. Other boolean connectives can be desugared into\nlogical-not-and Z.\nAssume a structure Aover universe A, a formula \u001e, an environment \rthat\nbinds the free \frst-order variables of \u001eto elements of A, and an environment \u0000\nthat binds the free SO variables of \u001eto subsets of Ak, wherekis the arity. We\nuse the notation \r[x7!aA] and\u0000[x7!RA] to extend environments, which we\nde\fne as\r[x7!aA](y):=aAwheny=xand\r(y) otherwise. Similar for \u0000.\n7subk(Pk; Qk):=8~ x\u0000\nPk(~ x)!Qk(~ x)\u0001\nid(x; y):= (x=y)\neqk(Pk; Qk):=8~ x\u0000\nPk(~ x)$Qk(~ x)\u0001\ninj(P):=sub2\u0000\nseq(P;inv(P));id\u0001\nirre\r(P):=8x:P(x; x) seq(P; Q)(x; z):=9y\u0000\nP(x; y)^Q(y; z)\u0001\ninv(P)(x; y):=P(y; x) trans(P):=sub2\u0000\nseq(P; P); P\u0001\nacyclic (P):=9X\u0000\nsub2(P; X)^trans(X)^irre\r(X)\u0001\nTC0(R):=eq1\nTCn+1(R)(P1; Q1):=eq1(P1; Q1)_ 9X1\u0000\nR(P1; X1)^TCn(R)(X1; Q1)\u0001\nFigure 4: Combinators used to build SO formulas. By convention, all quanti\fers\nthat occur on the right-hand side of the de\fnitions above are over fresh variables.\nAbove,PandQare arity-2 predicates, PkandQkare arity-kpredicates,xandy\nare \frst-order variables, and Ris a combinator.\nWe let the \frst-order empty environment \u000fmap constant symbols to their\nrespective constants \u000f(a):=aA, and we let the second-order empty environment E\nmap relation symbols to their respective relations E(R):=RA. With these\nconventions, we interpret formulas over structures by de\fning the judgement\nAj=\u001e[\r;\u0000] as follows:\nAj=P(t1;:::;tk)[\r;\u0000] i\u000b\u0000\n\r(t1);:::;\r (tk)\u0001\n2\u0000(P)\nAj= (\u001e1Z\u001e2)[\r;\u0000] i\u000b not both Aj=\u001e1[\r;\u0000] andAj=\u001e2[\r;\u0000]\nAj= (8x\u001e)[\r;\u0000] i\u000b Aj=\u001e\u0002\n\r[x7!aA];\u0000\u0003\nfor allaA2A\nAj= (9x\u001e)[\r;\u0000] i\u000b Aj=\u001e\u0002\n\r[x7!aA];\u0000\u0003\nfor someaA2A\nAj= (8Xk\u001e)[\r;\u0000] i\u000b Aj=\u001e\u0002\n\r;\u0000[Xk7!RA]\u0003\nfor allRA\u0012Ak\nAj= (9Xk\u001e)[\r;\u0000] i\u000b Aj=\u001e\u0002\n\r;\u0000[Xk7!RA]\u0003\nfor someRA\u0012Ak\nThe notation Aj=\u001eis a shorthand for Aj=\u001e[\u000f;E]. A formula with no free\nvariables is called a sentence . For a formula \u001ewhose free variables are ~ \u000b, both\n9~ \u000b\u001eand8~ \u000b\u001eare sentences. We say that \u001eissatis\fable when there exists a\nstructure Asuch that Aj=9~ \u000b\u001e; we say that \u001eisvalid when for all structures A\nwe have Aj=8~ \u000b\u001e.\nThe logic de\fned so far is known as SO. If we require that all quanti\fers\nover second-order variables are existentials, we obtain a fragment known as\n9SO (existential second-order). If we require that all second-order variables have\narity 1, we obtain a fragment known as MSO (monadic second-order). If we make\nboth requirements, the fragment is called 9MSO.\nCombinators. In what follows, we shall be describing some rather large SO\nformulas. To do so concisely, we shall utilise the combinators from Figure 4. All\ncombinators are typeset in sf-fonts .\nLet us discuss two of the more interesting combinators: acyclic and TC. A\nrelationPis acyclic if it is included in a relation that is transitive and irre\rexive.\nWe remark that the de\fnition of acyclic is carefully chosen: even slight variations\n8can have a strong in\ruence on the runtime of solvers [23]. The combinator TCfor\nbounded transitive closure is interesting for another reason: it is higher-order. By\nway of example, let us illustrate its application to the subset combinator sub1.\nTC1(sub1)(P; Q)\n=eq1(P; Q)_ 9X\u0000\nsub1(P; X)^TC0(sub1)(X; Q)\u0001\n=(\n8x1\u0000\nP(x1)$Q(x1)\u0001\n_\n9X\u0000\n8x2\u0000\nP(x2)!X(x2)\u0001\n^eq1(X; Q)\u0001\n=(\n8x1\u0000\nP(x1)$Q(x1)\u0001\n_\n9X\u0000\n8x2\u0000\nP(x2)!X(x2)\u0001\n^ 8x3\u0000\nX(x3)$Q(x3)\u0001\u0001\nIn the calculation above, P,QandXhave arity 1. In what follows, we freely use\nthe combinators from Figure 4 and, occasionally, we de\fne some that are speci\fc\nto a memory model.\n4 Memory Models\nIn this section, we show that many memory models can be expressed conveniently\nin second-order logic. Before diving into the details of memory models, let us\n\frst discuss brie\ry the representation we use for programs and their behaviours;\nnamely, event structures. We \frst describe the theory of event structures (vocabu-\nlary and axioms), followed by some useful de\fnitions and notational conventions.\nWe do not describe how event structures are obtained from programs; for that,\nwe refer the reader to [27].\nVocabulary. A memory model decides if a program is allowed to have a certain\nbehaviour. We shall formulate this question as a model checking question, Aj=\u001e.\nThe vocabulary of Aconsists of the following symbols:\n{arity 1: final ,read ,write\n{arity 2: conflict ,justifies ,sloc ,\u0014, =\nThe symbol = always denotes the identity relation on events, f(x;x)jx2Ag.\nThe symbol\u0014corresponds to program order; we have x\u0014ywhen events xandy\ncome from program statements that are ordered in the program text. We have\njustifies (x;y) whenxreads the value that ywrote, to the same memory\nlocation. We have conflict (x;y) when events xandycannot belong to the\nsame execution; for example, events xandymay model the same read-statement\nbut for di\u000berent values that are being read. The sets read and write classify\nevents in the obvious way. We have sloc (x;y) whenxandyare access the same\nmemory location.\nThe symbol final is not a standard component of event structures. We will\nmake use of it to identify the set of executions that exhibit a behaviour of interest.\n9Axioms. The theory of event structures is de\fned by the following axioms:\nAj=8x\u0000\n:read (x)_:write (x)\u0001\n(6)\nAj=8xy\u0000\njustifies (x;y)!\u0000\nwrite (x)^read (y)\u0001\u0001\n(7)\nAj=8xy\u0000\nconflict (x;y)$conflict (y;x)\u0001\n(8)\nAj=8x:conflict (x;x) (9)\nAj=8xyz\u0000\u0000\nconflict (x;y)^(y\u0014z)\u0001\n!conflict (x;z)\u0001\n(10)\nAj=8xyz\u0000\u0000\nconflict (x;y)^(z<y )\u0001\n!(z<x )\u0001\n(11)\nAj=8xyz \u0000\nconflict (x;y)^conflict (y;z)\u0001\n!\u0000\nconflict (x;z)_(x=z)\u0001!\n(12)\nIntuitively, con\ricts can \frst occur when an event xis immediately followed in\nprogram-order by two events y1andy2which are incomparable to each-other; and\nonce a con\rict occurs it propagates to subsequent events. Furthermore, con\rict\nis irre\rexive, and becomes transitive when unioned with the identity relation.\nCurrently, our SO solver has no knowledge of the theory of event structures, so\nit does not exploit the axioms from above. But, it can check that the structures A\nwe produce satisfy the axioms, as they should.\nCon\fgurations and Executions. We distinguish two types of sets of events. A\ncon\fguration is a set of events that contains no con\rict and is downward closed\nwith respect to\u0014; that is,Xis a con\fguration when V(X) holds, where the\nVcombinator is de\fned by\nV(X):=8\n><\n>:8x8y\u0010\u0000\nX(x)^X(y)\u0001\n!:conflict (x;y)\u0011\n^8y\u0010\nX(y)!8x\u0000\n(x\u0014y)!X(x)\u0001\u0011 (13)\nWe say that a con\fguration Xis an execution of interest when every \fnal\nevent is either in Xor in con\rict with an event in X; that is,Xis an execution\nof interest when F(X) holds, where the Fcombinator is de\fned by\nF(X):=V(X)^8x \u0000\nfinal (x)^:X(x)\u0001\n!\n9y\u0000\nconflict (x;y)^final (y)^X(y)\u0001!\n(14)\nIntuitively, we shall put in final all the maximal events (according to \u0014) for\nwhich registers have the desired values.\nNotations. In the formulas below, Xwill stand for a con\fguration, which may be\nthe execution of interest. Variables Yrf,Yco,Yhband so on are used to represent\nthe relations that are typically denoted by rf,co,hb, . . . Thus,Xhas arity 1,\nwhile Yrf;Yco;::: have arity 2.\nIn what follows, we present four memory models: sequential consistency\n(subsection 4.1), release{acquire (subsection 4.2), C++ (subsection 4.3), and\n10J+R (subsection 4.4). The \frst three can be expressed in 9SO (and in \frst-order\nlogic). The last one uses both universal and existential quanti\fcation over sets.\nFor each memory model, we shall see their encoding in second-order logic.\n4.1 Sequential Consistency\nThe sequential consistency memory model is the oldest and the least relaxed we\nconsider. Intuitively, this model allows all interleavings of threads, and nothing\nelse. It is described by the following SO sentence:\nSC:=9XYcoYrf\u0000\nF(X)^co(X;Yco)^rf(X;Yrf)^acyclic (R(Yco;Yrf))\u0001\nIntuitively, we say that there exists a coherence order relation Ycoand a reads-\nfrom relation Yrfwhich, when combined in a certain way, result in an acyclic\nrelation R(Yco;Yrf). The formula co(X;Yco) says that Ycosatis\fes the usual\naxioms of a coherence order with respect to the execution X; and the formula\nrf(X;Yrf) says that Yrfsatis\fes the usual axioms of a reads-from relation with\nrespect to the execution X. Moreover, the formula F(X) asks that Xis an\nexecution of interest, which results in registers having certain values.\nco(X;Yco):=8xy \u0000\nX(x)^X(y)^write (x)^write (y)^sloc(x; y)^(x6=y)\u0001\n$\u0000\nYco(x; y)_Yco(y; x)\u0001!\n(15)\nrf(X;Yrf):=8\n<\n:inj(Yrf)^sub2(Yrf;justifies )^\n8y\u0010\u0000\nread(y)^X(y)\u0001\n! 9x\u0000\nwrite (x)^X(x)^Yrf(x; y)\u0001\u0011(16)\nWhenXis a potential execution and Ycois a potential coherence-order relation,\nthe formula co(X;Yco) requires that the writes in Xfor the same location includes\nsome total order. Because of the later condition that R(Yco;Yrf) is acyclic, Ycois\nin fact required to be a total order per location. When Xis a potential execution\nand Yrfis a potential reads-from relation, the formula rf(X;Yrf) requires that\nYrfis injective, is a subset of justifies , and relates all the reads in Xto some\nwrite inX.\nThe auxiliary relation R(Yco;Yrf) is the union of strict program-order ( <),\nreads-from ( Yrf), coherence-order ( Yco), and the from-reads relation:\nR(Yco;Yrf)(y;z):= (y<z )_Yco(y;z)_Yrf(y;z)_9x\u0000\nYco(x;z)^Yrf(x;y)\u0001\n(17)\n4.2 Release{Acquire\nThe Release{Acquire memory model is similar to sequential consistency but more\nrelaxed. The structure it operates has the same vocabulary, and the memory\n11model is captured by the formula RA, de\fned as follows:\nRA:=9XYcoYrf0\nBBB@F(X)^co(X;Yco)^rf(X;Yrf)^acyclic (Yco)\n^9Yhb0\nB@sub2(<;Yhb)^sub2(Yrf;Yhb)^trans(Yhb)\n^irre\r(Yhb)^irre\r(seq(Yco;Yhb))\n^irre\r(seq(inv(Yrf);seq(Yco;Yhb)))1\nCA1\nCCCA\n(18)\nThe existential SO variable Yhbover-approximates a relation traditionally called\nhappens-before.\n4.3 C++\nTo capture the C++ model in SO logic, we follow the .cat model of Lahav et\nal. [32]. Their work introduces necessary patches to the model of the standard [10]\nbut also includes \fxes and adjustments from prior work [8,31]. The model is more\nnuanced than the SC and RA models and requires additions to the vocabulary\nofA, but the key di\u000berence is more fundamental. C++ is a catch-\fre semantics:\nprograms that exhibit even a single execution with a data race are allowed to do\nanything at all, even burst into \rames, and this means that they satisfy every\nexpected outcome. This di\u000berence is neatly expressed in SO logic:\nCPP :=9XYcoYrf \nco(X;Yco)^rf(X;Yrf)^M(Yco;Yrf)\n^(F(X)_C(Yco;Yrf))!\n(19)\nThe formula reuses co,rfand F(X) and includes two new macros: M(Yco;Yrf)\nand C(Yco;Yrf).M(Yco;Yrf) captures the conditions imposed on a valid C++\nexecution, and is the analogue of the conditions applied in SCand RA.C(Yco;Yrf)\nholds if there is a race in the execution X. Note that the expected outcome is\nallowed if F(X) is satis\fed or if there is a race and C(Yco;Yrf) is true.\n4.4 Je\u000brey{Riely\nThe J+R memory model is captured by a sentence JRn, parametrised by an\nintegern. Unlike the formulas we saw before, JRnmakes use of three levels of\nquanti\fers (989), putting it on the third level of the polynomial hierarchy. We\nbegin by lifting3justifies from events to sets of events PandQ:\nJ(P;Q):=8y \u0000\n:P(y)^Q(y)^read (y)\u0001\n!9x\u0000\nP(x)^write (y)^justifies (x;y)\u0001!\n(20)\nAJ(P;Q):=J(P;Q)^sub1(P;Q)^V(P)^V(Q) (21)\n3Our de\fnition of Jis di\u000berent from the original one [27]: we require that only new\nreads are justi\fed, by including the conjunct :P(y). Without this modi\fcation, our\nsolver's results disagree with the hand-calculations reported by Je\u000brey and Riely;\nwith this modi\fcation, the results agree.\n12We read Jas `justi\fes', and AJas `always justi\fes'. Next, we de\fne what Je\u000brey\nand Riely call `always eventually justify'\nAeJn(P;Q):=8\n<\n:sub1(P;Q)^V(P)^V(Q)^\n8X\u0010\nTCn(AJ)(P;X)!9Y\u0000\nTCn(AJ)(X;Y )^J(Y;Q)\u0001\u0011(22)\nThe size of the formula TCn(AeJm)(P;Q) we de\fned above is \u0002(mn). In particular,\nit is bounded. Finally, we let4\nJRn:=9X\u0000\nTCn(AeJn)(;;X)^F(X)\u0001\n(23)\nand ask solve the model checking problem Aj=JRn. Since the formulas above\nare in MSO, it is su\u000ecient to pick n:=2jAj. Since all bounded transitive closures\ninclude the subset relation, they are monotonic, and it su\u000eces, in fact, to pick\nn:=jAj. For actual solving, we will use this observation.\n5 Encoding in QBF\nIn the previous section, we saw that deciding whether a given program behaviour\nis allowed by a given memory model can often be expressed naturally as a model\nchecking problem Aj=\u001ein second-order logic. Now we want to solve such\nproblems. We do not use existing model \fnders and solvers [13,15,16]: we \fnd\nthose for \frst-order logic are e\u000ecient, but not expressive enough; whereas those\nfor higher-order logic are expressive but not e\u000ecient. As a middle road, we reduce\nthe model-checking problem in second-order logic to checking the validity of a\nQBF. This reduction is simple and natural, and it lets us pro\ft from the recent\nimprovements in QBF solving. We \frst de\fne QBF (subsection 5.1) and then\npresent the translation from SO to QBF (subsection 5.2).\n5.1 Quanti\fed Boolean Formulas\nQBF can be seen as a restriction of second-order logic: (i) we banish second-order\nquanti\fers from formulas; and (ii) we \fx the structure. The universe contains\ntwo elements, 0Aand 1A, denoted by the constant symbols 0 and 1, respectively.\nThere is a unique relational symbol Twhich denotes the relation f1Ag. We denote\nthis \fxed structure by Aqbf. Instead of writing T(0) andT(1) we abuse notation,\nas is common, and write 0 and 1.\n4The symbol ;denotes the empty unary relation, as expected.\n135.2 Translation from SO to QBF\nGiven a structure Aand an SO sentence \u001e, we will construct a QBF sentence\nJAj=\u001eKsuch that Aj=\u001eholds if and only if Aqbfj=JAj=\u001eKholds:\nJAj=P(t1;:::;tk)K\r;\u0000:=\u0000(P)(\r(t1);:::;\r (tk)) (24)\nJAj=\u001e1Z\u001e2K\r;\u0000:=JAj=\u001e1K\r;\u0000ZJAj=\u001e2K\r;\u0000(25)\nJAj=8x\u001eK\r;\u0000:=n^\ni=1JAj=\u001eK\r[x7!aA\ni];\u0000(26)\nJAj=9x\u001eK\r;\u0000:=n_\ni=1JAj=\u001eK\r[x7!aA\ni];\u0000 (27)\nq\nAj=8Xk\u001ey\n\r;\u0000:=8~xJAj=\u001eK\r;\u0000[Xk7!~x](28)\nq\nAj=9Xk\u001ey\n\r;\u0000:=9~xJAj=\u001eK\r;\u0000[Xk7!~x] (29)\nAs before,\rmaps \frst-order variables to universe elements. Unlike before, \u0000maps\nSO variables Xkto (total) functions from Akto QBF terms. For example,\n\u0000(X2)(aA\n1;aA\n2) is a QBF term. As before, we make the convention that the empty\n\frst-order environment maps constants to the elements they denote: \u000f(a):=aA.\nFor the empty SO environment E, we make the following convention:\nE(R)(~ a):=(\n0 if~ a2RA\n1 if~ a62RA(30)\nAbove, 0 and 1 are QBF constants, and ~ a2Akwherekis the arity of R. The\nnotation JAj=\u001eKis shorthand for JAj=\u001eK\u000f;E.\nIn(28) and(29), SO quanti\fers are handled by introducing jAjkQBF vari-\nables~x, wherekis the arity. The SO environment \u0000is extended with a binding\nfrom the SO variable Xkto a bijective function from Akto the fresh variables.\nIn(24), this function is extracted from the environment and applied. Intuitively,\nthe QBF variable ~x(aA\n1;:::;aA\nk) tracks whether ( aA\n1;:::;aA\nk) belongs to Xk.\nIn(26) and(27), \frst-order quanti\fers are handled by simply expanding\nthem into corresponding boolean connectives. This eager expansion is a potential\ntarget for optimisation in the future.\n6 Evaluation\nThe evaluation aims to analyse the performance and correctness of the developed\ntool. To this end we included \\tricky\" benchmarks that are studied in the\nliterature and benchmarks for scaling. Additionally, various beckends to the\npresented tool PrideMM are considered.\n14 0 1000 2000 3000 4000 5000 6000\n 8 10 12 14 16 18 20 22 24Execution Time (s)\nThreads in SB testPrideMM+QFUN\nPrideMM+QFMHerd7Figure 5: Comparison between Herd\nand PrideMM on the store bu\u000ber\nproblem.Prob. SAT caqe (s) qfun (s) qfm (s)\n1 N ? 610 2\n2 N ? 23 2\n3 Y ? ? 222\n4 Y ? 2 5\n5 Y ? 78 51\n6 N 5 4 1\n7 Y ? 280 56\n8 N ? 2 2\n9 N ? 2 1\n10 Y ? 36 10\n11 Y ? 598 335\n13 Y 1 1 1\n14 Y ? 29 33\n15 Y ? 512 157\n16 N ? ? 12\n17 N ? 39 311\n18 N ? 359 190\n#17 #2 #15 #17\nTable 1: CPU time for solving the lit-\nmus tests with J+R model; ?represents\ntime/mem-out.\nSolvers. We evaluate the QBF approach using o\u000b-the-shelf solvers CAQE [46]\nand QFUN [22], the respective winners of the CNF and non-CNF tracks at 2017's\nQBFEVAL competition [44]. Our QBF benchmarks were \frst produced in the\ncircuit-like format QCIR [28], natively supported by QFUN. The inputs to CAQE\nwere produced by converting to CNF through standard means, followed by a\npreprocessing step with bloqqer [12].\nEncouraged by the results of the QBF approach, we have started the develop-\nment of a dedicated solver for SO model checking. The solver is called QFM and\nit accepts as input a structure and an SO formula. Currently the solver expands\nall \frst-order quanti\fcations, following a similar approach to the translation of\nSection 5.2. The QBF problem is then solved using the non-prenex version of\nthe RAReQS algorithm [24]. A dedicated SO solver is able to use specialised\ntechniques, e.g. lazily expanding quanti\fers. Such techniques present a particular\nadvantage for universes with large number of elements: the inherent exponential\ncharacteristic of the expansion step will eventually lead to issues in the translation\nto QBF.\nInstances and memory models. In our \frst set of instances, we simulate a series\nof n-threaded store-bu\u000bering tests (Figure 6) over sequential consistency [33],\nand compare the performance of PrideMM and Herd7 [5]. The results of this\ncomparison are shown in Figure 5. In a second set of instances, we simulate\nthe J+R model on the Java causality tests [36]. There are no other tools to\n15initially x1=0;x2=0; : : : ; xn=0\nx1=1x2=1 : : : xn\u00001=1 xn=1\nr1=xnr2=x1 : : : rn\u00001=xn\u00002rn=xn\u00001\nr1==0^r2==0^: : :^rn\u00001==0^rn==0allowed?\nFigure 6: The store-bu\u000ber problem.\nbenchmark against; ours is the only simulator for this model. Instead, we provide\na comparative evaluation between our QBF and QFM backends. In a \fnal set of\ninstances, we simulate a collection of standard tests taken from the literature on\naxiomatic memory models [48]. Each of these completes in under 6s.\nDiscussion of the results. Figure 5 indicates a stark contrast in the scalability of\nthe store-bu\u000bering problem on PrideMM when compared with Herd7. PrideMM\nenables the practical simulation of far larger tests: 25-thread SB { with 100\nevents { solves in 1 minute. Axiomatic tests reduce to SAT problems, so one\nmight expect similar performance from QFUN and QFM, but QFUN has the\nmore mature implementation.\nTable 1 demonstrates the viability of our approach to simulating the J+R\nmodel. QFUN solves all but two instances, whereas QFM solves all of them, taking\nno longer than 6 min on any instance. We found the CNF-based QBF solver\nCAQE to be inadequate for these problems. The timeout was set to 30 minutes,\nand the memory available was 32GB. The dedicated SO solver QFM performs\nbetter than the o\u000b-the-shelf QBF solver QFUN { even though they implement\nthe same algorithm. We attribute this to a more e\u000ecient implementation of\nthe expansion of \frst-order logic quanti\fers (e.g. repetition of subformulas is\navoided by hash-consing already during expansion). Additionally, QFM supports\nnon-prenex input, while QFUN operates on prenex form. The satis\fability of\neach instance matches the expected results [27].\n7 Related Work\nOur evaluation was limited to 4 memory models: SC, RA, C++ and J+R.\nAlthough we have covered a breadth of axiomatic models, there are several others\nthat fall into the class of the J+R model that we have not covered, i.e. the\npromising model of Kang et al. [29], or the model of Pichon{Pharabod and Sewell\n(P+S) [42]. It is clear that Promising and P+S are de\fnable in higher-order logic\nand hence in second-order logic, by the standard encoding of higher-order in\nsecond-order (over \fnite structures). Moreover, for J+R, we do not show that the\nmodel de\fnable directly as a second-order logic formula \u001e, but instead describe it\nas a sequencef\u001engn\u00150of formulas, one for each universe size. Thus, our decision\nto stay in second-order logic and use parametrised formulas does not prevent us\nfrom representing other models, and experimental validation indicates that we\nhave found a pragmatic sweet-spot for simulating this new class of models.\n16We use Herd as a performance benchmark because it is the predominant\nweak-memory modelling tool, but there are others. CDSChecker [40] is a model\nchecker entirely specialised to the axiomatic model of C++. Memalloy [53] uses\nSAT solvers to model a range of models, but cannot model the J+R model\ne\u000eciently.\nThere are other weak-memory questions that one might seek to answer auto-\nmatically beyond simulation: Memalloy [53] can compare axiomatic memory\nmodels to \fnd programs that act as di\u000berentiating counterexamples, with execu-\ntions allowed by one and not the other. Bornholt and Torlak's MemSynth [14]\ncan synthesise axiomatic memory models from sets of litmus tests. We choose\nsynthesis as our task because it is a good starting point with clear utility.\n8 Conclusion\nThis paper presents PrideMM, a tool that vastly exceeds the performance of\nHerd, a state-of-the-art simulator for axiomatic concurrency models, and that\nsimulates one of a new class of models for which previous techniques do not apply.\nWe argue that for weak-memory model simulation, SO logic provides a useful\nbalance of expressiveness and performance when combined with state-of-the-art\nsolvers.\n17References\n1.Alglave, J., Batty, M., Donaldson, A.F., Gopalakrishnan, G., Ketema, J., Po-\netzl, D., Sorensen, T., Wickerson, J.: GPU concurrency: Weak behaviours and\nprogramming assumptions. In: Proceedings of the Twentieth International Con-\nference on Architectural Support for Programming Languages and Operating\nSystems, ASPLOS '15, Istanbul, Turkey, March 14-18, 2015. pp. 577{591 (2015),\nhttp://doi.acm.org/10.1145/2694344.2694391\n2.Alglave, J., Cousot, P.: Syntax and analytic semantics of LISA. https://arxiv.\norg/abs/1608.06583 (2016)\n3.Alglave, J., Cousot, P., Maranget, L.: Syntax and analytic semantics of the weak con-\nsistency model speci\fcation language CAT. https://arxiv.org/abs/1608.07531\n(2016)\n4.Alglave, J., Maranget, L., Sarkar, S., Sewell, P.: Fences in weak memory models\n(extended version). Formal Methods in System Design 40(2), 170{205 (2012),\nhttps://doi.org/10.1007/s10703-011-0135-z\n5.Alglave, J., Maranget, L., Tautschnig, M.: Herding cats: Modelling, simulation,\ntesting, and data mining for weak memory. ACM Trans. Program. Lang. Syst.\n36(2), 7:1{7:74 (2014), http://doi.acm.org/10.1145/2627752\n6.Ans\u0013 otegui, C., Gomes, C.P., Selman, B.: The Achilles' heel of QBF. In: AAAI. pp.\n275{281 (2005)\n7.Balabanov, V., Jiang, J.R., Mishchenko, A., Scholl, C.: Clauses versus gates in\nCEGAR-Based 2QBF solving. In: Beyond NP, AAAI Workshop (2016)\n8.Batty, M., Donaldson, A.F., Wickerson, J.: Overhauling SC atomics in C11 and\nopencl. In: Proceedings of the 43rd Annual ACM SIGPLAN-SIGACT Symposium\non Principles of Programming Languages, POPL 2016, St. Petersburg, FL, USA,\nJanuary 20 - 22, 2016. pp. 634{648 (2016), http://doi.acm.org/10.1145/2837614.\n2837637\n9.Batty, M., Memarian, K., Nienhuis, K., Pichon-Pharabod, J., Sewell, P.: The prob-\nlem of programming language concurrency semantics. In: Programming Languages\nand Systems - 24th European Symposium on Programming, ESOP 2015, Held\nas Part of the European Joint Conferences on Theory and Practice of Software,\nETAPS 2015, London, UK, April 11-18, 2015. Proceedings. pp. 283{307 (2015),\nhttps://doi.org/10.1007/978-3-662-46669-8_12\n10.Batty, M., Owens, S., Sarkar, S., Sewell, P., Weber, T.: Mathematizing C++\nconcurrency. In: Proceedings of the 38th ACM SIGPLAN-SIGACT Symposium on\nPrinciples of Programming Languages, POPL 2011, Austin, TX, USA, January\n26-28, 2011. pp. 55{66 (2011), http://doi.acm.org/10.1145/1926385.1926394\n11.Biere, A., Heule, M., van Maaren, H., Walsh, T. (eds.): Handbook of Satis\fability,\nFrontiers in Arti\fcial Intelligence and Applications, vol. 185. IOS Press (2009)\n12.Biere, A., Lonsing, F., Seidl, M.: Blocked clause elimination for QBF. In: The 23rd\nInternational Conference on Automated Deduction CADE (2011)\n13.Blanchette, J.C., Nipkow, T.: Nitpick: A counterexample generator for higher-order\nlogic based on a relational model \fnder. In: Interactive Theorem Proving, First\nInternational Conference (ITP). pp. 131{146 (2010), https://doi.org/10.1007/\n978-3-642-14052-5_11\n14.Bornholt, J., Torlak, E.: Synthesizing memory models from framework sketches and\nlitmus tests. In: Proceedings of the 38th ACM SIGPLAN Conference on Program-\nming Language Design and Implementation, PLDI 2017, Barcelona, Spain, June\n18-23, 2017. pp. 467{481 (2017), http://doi.acm.org/10.1145/3062341.3062353\n1815.Brown, C.E.: Satallax: An automatic higher-order prover. In: Automated Reasoning\n- 6th International Joint Conference (IJCAR). pp. 111{117 (2012), https://doi.\norg/10.1007/978-3-642-31365-3_11\n16.Cimatti, A., Griggio, A., Mover, S., Tonetta, S.: IC3 modulo theories via implicit\npredicate abstraction. In: TACAS (2014)\n17.Goultiaeva, A., Bacchus, F.: Exploiting QBF duality on a circuit representation.\nIn: AAAI (2010)\n18.Goultiaeva, A., Seidl, M., Biere, A.: Bridging the gap between dual propagation\nand CNF-based QBF solving. In: DATE. pp. 811{814 (2013)\n19.Gray, K.E., Kerneis, G., Mulligan, D.P., Pulte, C., Sarkar, S., Sewell, P.: An\nintegrated concurrency and core-isa architectural envelope de\fnition, and test\noracle, for IBM POWER multiprocessors. In: Proceedings of the 48th International\nSymposium on Microarchitecture, MICRO 2015, Waikiki, HI, USA, December 5-9,\n2015. pp. 635{646 (2015), http://doi.acm.org/10.1145/2830772.2830775\n20.Janota, M., Klieber, W., Marques-Silva, J., Clarke, E.M.: Solving QBF with counter-\nexample guided re\fnement. In: SAT. pp. 114{128 (2012)\n21.Janota, M., Marques-Silva, J.: An Achilles' heel of term-resolution. In: EPIA\nConference on Arti\fcial Intelligence. pp. 670{680 (2017)\n22.Janota, M.: Towards generalization in QBF solving via machine learning. In: AAAI\nConference on Arti\fcial Intelligence (2018)\n23.Janota, M., Grigore, R., Manquinho, V.: On the quest for an acyclic graph. In:\nRCRA (2017)\n24.Janota, M., Klieber, W., Marques-Silva, J., Clarke, E.: Solving QBF with counter-\nexample guided re\fnement. Arti\fcial Intelligence 234, 1{25 (2016)\n25.Janota, M., Marques-Silva, J.: Abstraction-based algorithm for 2QBF. In: SAT. pp.\n230{244 (2011)\n26.Janota, M., Marques-Silva, J.: Solving QBF by clause selection. In: International\nJoint Conference on Arti\fcial Intelligence (IJCAI) (2015)\n27.Je\u000brey, A., Riely, J.: On thin air reads towards an event structures model of relaxed\nmemory. In: Proceedings of the 31st Annual ACM/IEEE Symposium on Logic\nin Computer Science. pp. 759{767. LICS '16, ACM, New York, NY, USA (2016),\nhttp://doi.acm.org/10.1145/2933575.2934536\n28.Jordan, C., Klieber, W., Seidl, M.: Non-CNF QBF solving with QCIR. In: AAAI\nWorkshop: Beyond NP. AAAI Workshops, vol. WS-16-05. AAAI Press (2016)\n29.Kang, J., Hur, C., Lahav, O., Vafeiadis, V., Dreyer, D.: A promising semantics\nfor relaxed-memory concurrency. In: Proceedings of the 44th ACM SIGPLAN\nSymposium on Principles of Programming Languages, POPL 2017, Paris, France,\nJanuary 18-20, 2017. pp. 175{189 (2017), http://dl.acm.org/citation.cfm?id=\n3009850\n30.Klieber, W., Sapra, S., Gao, S., Clarke, E.M.: A non-prenex, non-clausal QBF\nsolver with game-state learning. In: SAT (2010)\n31.Lahav, O., Giannarakis, N., Vafeiadis, V.: Taming release-acquire consistency. In:\nProceedings of the 43rd Annual ACM SIGPLAN-SIGACT Symposium on Principles\nof Programming Languages, POPL 2016, St. Petersburg, FL, USA, January 20 -\n22, 2016. pp. 649{662 (2016), http://doi.acm.org/10.1145/2837614.2837643\n32.Lahav, O., Vafeiadis, V., Kang, J., Hur, C., Dreyer, D.: Repairing sequential consist-\nency in C/C++11. In: Proceedings of the 38th ACM SIGPLAN Conference on Pro-\ngramming Language Design and Implementation, PLDI 2017, Barcelona, Spain, June\n18-23, 2017. pp. 618{632 (2017), http://doi.acm.org/10.1145/3062341.3062352\n1933.Lamport, L.: How to make a multiprocessor computer that correctly executes\nmultiprocess programs. IEEE Trans. Computers 28(9), 690{691 (1979), https:\n//doi.org/10.1109/TC.1979.1675439\n34. Libkin, L.: Elements of Finite Model Theory. Springer (2004)\n35. Lonsing, F., Egly, U., Seidl, M.: Q-resolution with generalized axioms. In: Theory\nand Applications of Satis\fability Testing - SAT. pp. 435{452 (2016)\n36.Manson, J., Pugh, W., Adve, S.V.: The java memory model. In: Proceedings of\nthe 32nd ACM SIGPLAN-SIGACT Symposium on Principles of Programming\nLanguages, POPL 2005, Long Beach, California, USA, January 12-14, 2005. pp.\n378{391 (2005), http://doi.acm.org/10.1145/1040305.1040336\n37.Marin, P., Narizzano, M., Pulina, L., Tacchella, A., Giunchiglia, E.: Twelve years of\nQBF evaluations: QSAT is PSPACE-hard and it shows. Fundam. Inform. 149(1-2),\n133{158 (2016), https://doi.org/10.3233/FI-2016-1445\n38.Marques-Silva, J.P., Sakallah, K.A.: GRASP: A search algorithm for propositional\nsatis\fability. IEEE Transactions on Computers 48(5), 506{521 (1999)\n39.Morisset, R., Pawan, P., Nardelli, F.Z.: Compiler testing via a theory of sound optim-\nisations in the C11/C++11 memory model. In: ACM SIGPLAN Conference on Pro-\ngramming Language Design and Implementation, PLDI '13, Seattle, WA, USA, June\n16-19, 2013. pp. 187{196 (2013), http://doi.acm.org/10.1145/2491956.2491967\n40.Norris, B., Demsky, B.: A practical approach for model checking c/c++11 code.\nACM Trans. Program. Lang. Syst. 38(3), 10:1{10:51 (May 2016), http://doi.acm.\norg/10.1145/2806886\n41.Peitl, T., Slivovsky, F., Szeider, S.: Dependency learning for QBF. In: Theory\nand Applications of Satis\fability Testing - (SAT). pp. 298{313 (2017), https:\n//doi.org/10.1007/978-3-319-66263-3_19\n42.Pichon-Pharabod, J., Sewell, P.: A concurrency semantics for relaxed atomics\nthat permits optimisation and avoids thin-air executions. In: Proceedings of the\n43rd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming\nLanguages, POPL 2016, St. Petersburg, FL, USA, January 20 - 22, 2016. pp.\n622{633 (2016), http://doi.acm.org/10.1145/2837614.2837616\n43. QBF Eval, http://www.qbflib.org/index_eval.php\n44. QBF Eval 2017, http://www.qbflib.org/event_page.php?year=2017\n45.Rabe, M.N., Seshia, S.A.: Incremental determinization. In: Theory and Applications\nof Satis\fability Testing - SAT. pp. 375{392 (2016)\n46.Rabe, M.N., Tentrup, L.: CAQE: A certifying QBF solver. In: Formal Methods in\nComputer-Aided Design, FMCAD. pp. 136{143 (2015)\n47.Ranjan, D.P., Tang, D., Malik, S.: A comparative study of 2QBF algorithms. In:\nSAT. pp. 292{305 (2004)\n48.Sarkar, S., Sewell, P., Alglave, J., Maranget, L., Williams, D.: Understanding\nPOWER multiprocessors. In: Proceedings of the 32nd ACM SIGPLAN Conference\non Programming Language Design and Implementation, PLDI 2011, San Jose, CA,\nUSA, June 4-8, 2011. pp. 175{186 (2011), http://doi.acm.org/10.1145/1993498.\n1993520\n49.Tentrup, L.: Non-prenex QBF solving using abstraction. In: Theory and Applications\nof Satis\fability Testing (SAT). pp. 393{401 (2016)\n50.Van Gelder, A.: Primal and dual encoding from applications into quanti\fed boolean\nformulas. In: CP. pp. 694{707 (2013)\n51.\u0014Sev\u0014 c\u0013 \u0010k, J., Aspinall, D.: On validity of program transformations in the Java\nmemory model. In: ECOOP 2008 - Object-Oriented Programming, 22nd European\nConference, Paphos, Cyprus, July 7-11, 2008, Proceedings. pp. 27{51 (2008),\nhttps://doi.org/10.1007/978-3-540-70592-5_3\n2052.Wickerson, J., Batty, M., Beckmann, B.M., Donaldson, A.F.: Remote-scope promo-\ntion: cl"}
{"date": "2024-01-04-22-29", "error": false, "url": "PDF", "text_blocks": "Gender bias in academic recruitment1 \n \nGiovanni Abramo (corresponding author)  \nLaboratory for Studies of Research and Technology Transfer  \nInstitute for System Analysis and Computer Science (IASI -CNR)  \nNational Research Council of Italy  \nADDRESS: Consiglio Nazionale delle Ricerche  \nIstituto di Analisi dei Sistemi e Informatica  \nVia dei Taurini 19, 00185 Roma – ITALY  \ntel. and fax +39 06 72597362, giovanni.abramo@uniroma2.it  \n \nCiriaco Andrea D’Angelo  \nDepartment of Engineering and Management -University of Rome “Tor Vergata”  \nADDRESS: Dipartimento di Ingegneria dell’Impresa  \nUniversità degli Studi di Roma “Tor Vergata”,  \nVia del Politecnico 1, 00133 Roma – ITALY  \ntel. and fax +39 06 72597362, dangelo@dii.uniroma2.it  \n \nFrancesco Rosati  \nDepartment of Management Engineeri ng-Technical University of Denmark  \nADDRESS: Technical University of Denmark  \nProduktionstorvet Building 426  \n2800 Kgs. Lyngby - Denmark  \ntel +45 45256021, frro@dtu.dk  \n \n \nAbstract  \n \nIt is well known that women are underrepresented in the academic systems of many \ncountries. Gender discrimination is one of the factors that could contribute to this \nphenomenon. This study considers a recent  national academic recruitment  campaign  in \nItaly, examining whether women are subject to more or less bias than men. The findings \nshow that no gender -related differences occur among the candidates who benefit from \npositive bias, while  among those candidates affected by negative bias, the incidence of \nwomen is lower than that of men. Among the factors that determine success in a \ncompetition for an academic position, the number of the applicant’s career years in the \nsame university as the committee members assumes greater weight for male candidates \nthan fo r females. Being of the same gender as the committee president is also a factor that \nassumes greater weight for male applicants. On the other hand, for female applicants, the \npresence of a full professor in the same university with the same family name as the \ncandidate assumes greater weight than for male candidates.  \n \nKeywords  \n \nResearch evaluation; bibliometrics; FSS; Italy.  \n                                                           \n1 Abramo, G., D'Angelo, C.A., Rosati, F. (2016). Gender bias in academic recruitment. Scientometrics , \n106(1), 119 -141. DOI: 10.1007/s11192 -015-1783 -3 2 1. Introduction  \n \nIt is commonly understood that women are  underrepresented in the research systems \nof many countries. In fact the data on national research staffing reveal a significant gap \nin the presence of women. Only four of 28 OECD nations2 (Portugal, Estonia, Slovak \nRepublic, Iceland) have a percentage of w omen greater than 40% in their national \nsystems, and in none of these cases does female representation exceed 46% (OECD \n2014). In the UK, women represent only 38.3% of total researchers, and in Italy only \n34.5%. In France the share drops below 26.0%, and i n Germany below 25%. Women \nresearchers in Japan make up just 13.8% of the national staff. Although the four Nordic \ncountries (Denmark, Finland, Norway, Sweden) are popularly considered progressive in \nwomen’s rights, in these nations male scientists still o utnumber their female colleagues \ntwo to one. The question that naturally arises is which of a series of factors could be the \ncause of this underrepresentation:  lower numbers of women graduates; less interest \namong women for research activity; lesser scient ific merit, and/or phenomena of gender \nbias in recruitment processes. The intention of the present work is to verify the hypothesis \nof the latter cause, thus contributing to a line of current studies on gender bias in the \nrecruitment of academic staff (Zin ovyeva and Bagues, 201 5; Moss -Racusin et al., 2012: \nvan den Brink et al., 2010; Wright et al., 2003; Fuchs et al., 2001). One branch of this \nliterature demonstrates that discriminatory phenomena tend to appear when evaluations \nare not based on transparent criteria (Rees, 2004; Ziegler, 2001; Husu, 2000; Ledwith and \nManfredi, 2000; Allen, 1988). In effect, academic recruitment is often described as an \ninformal process, in which a few powerful professors promote or select new professors \nthrough mechanisms of cooptation (van den Brink et al., 2010; Husu, 2000; Fogelberg et \nal., 1999; Evans, 1995). A series of studies also show that women professors progress \nmore slowly through academic ranks, tend not to attain important leadership roles, and \nearn less than men  in comparable positions (Rotbart et al., 2012; Bilimoria and Liang, \n2011; McGuire et al., 2004; Wright et al., 2003). The fact that women are \nunderrepresented in decision -making positions appears to reduce probabilities for the \nrecruitment and advancement  of female candidates (Moss -Racusin et al., 2012; Corrice, \n2009). De Paola and Scoppa (201 5) find that “female candidates are less likely to be \npromoted when the committee is composed exclusively by males, while the gender gap \ndisappears when the candidate s are evaluated by a mixed sex committee ”. Zinovyeva and \nBagues (201 5, 2011) find that in competitions for full professor positions in Spain, \nevaluators tend to favor candidates who belong to their own academic network and are \nalso of the same gender. In I taly, Abramo et al. (201 5a) observed a moderate positive \nassociation between competitions with expected outcomes and the fact that the committee \npresident was a woman. Bagues et al. (2014) estimated the causal effect of the gender \ncomposition of committees  in the 2012 Italian competitions for qualification for associate \nand full professor positions. Differently from other studies, they found that each \nadditional female evaluator decreases the success rate of female candidates by 2 \npercentage points.  \nThe res ults of the preceding two studies on the Italian case are in our opinion not \nnecessarily to be considered in disagreement. In fact the positive link between the \nincreasing presence of women in the competition committees and the consideration of \n                                                           \n2 Data for the remaining 6 OECD nations (Australia, Canada, Israel, Mexico, New Zealand, and United \nStates) are not available.  3 merit over favoritism (Abramo et al., 201 5a) could coexist with the link between the \nincrease in female representation in the committees and the diminution of success rates \nfor women candidates (Bagues et al., 2014). The joint observations would indeed be \nlogical, si nce it has been shown that female researchers are less productive than males in \nmost disciplines (Larivière et al., 2013; Mauleón and Bordons, 2006; Xie and Shauman, \n2004;  Long, 1992; Fox, 1983), although gender differences are lessening over time \n(Frietsch et al., 2009; Abramo et al., 2009a; Alonso -Arroyo et al., 2007; Leahey, 2006; \nXie and Shauman, 1998; Cole and Zuckerman, 1984). Moreover, the productivity gap is \nespecially remarkable among top scientists (Abramo et al., 2009b; Bordons et al., 200 3), \nwho are those more likely to apply for higher academic positions.  \nThe Italian context is particularly suited to studies of gender bias given the high rate \nof favoritism in competitions for the public sector, which includes the university sphere. \nAccord ing to The Global Competitiveness Report 2013 -2014 (Schwab, 2013), Italy ranks \n126th out of 148 countries in favoritism in decisions of government officials. It is no \nsurprise then that the nationally governed  competitions for faculty positions have come \nunder frequent  fire, and that the Italian word “concorso”  has gained international note for \nits implications of rigged competition, favoritism, nepotism and other unfair selection \npractices (Gerosa, 2001).  Cases of favoritism in the faculty recruitment have  been the \nsubject of frequent media attention, and have even arrived before the courts (Zagaria, \n2007; Perotti, 2008). A series of empirical studies have demonstrated that in Italy, \nscientific merit is not always the prevailing criteria for selection (Abra mo et al., 2015 b, \n2014a, 2014b; Allesina, 2011; Durante et al., 2011, 2009).  \nIn a context where favoritism is very diffuse it becomes easier to verify if, among \nthose who are the subject of possible bias , there are differences in gender. In carrying out \nthis verification, we distinguish between positive bias and negative bias in the \ncompetition outcomes. We then ask if the weights of the diverse factors that may \ndetermine the competition outcome indeed di ffer by gender. The two potential \ndeterminants of interest are: i) the scientific merit of the candidates, and ii) the \npossibilities for favoritism towards the candidates arising from factors of social proximity \nand research collaboration between the candi dates and their evaluators, particularly \ninvolving the committee president.  \nThe literature on gender discrimination and inequality in universities features several \nstreams of activity, particularly qualitative research based on interviews (Bagilhole, 1993)   \nand quantitative research based on surveys and questionnaires (McGuire et al., 2004; \nWright et al., 2003), as well as analyses of academic faculties and their selection \nprocedures (Rotbart et al., 2012; Moss -Racusin et al., 2012; Ceci and Williams, 2011) . \nThese studies identify the principle phenomena of gender discrimination as being: lesser \nprobability for women to achieve promotion or tenure; lesser probability of obtaining \nleadership roles such as division head, department head, or dean; assignment of  salaries \nthat are lower than those of their male colleagues. However these studies, often focused \non selected disciplines, lead to results that are difficult to generalize. Van den Brink et al. \n(2006) overcome these limits in their analysis of the reports  from selection committees \nfor 682 professorships in seven different disciplines for six large Dutch universities, over \nthe period 1999 -2003. However these authors themselves note a fundamental limitation \nin their work: the impossibility to elaborate a str ict measurement of gender bias, given \nthat they are unable to measure the quality of the applicants. The current study overcomes \nthis limit by analyzing nearly the entirety of all scientific disciplines active in Italy, and \nevaluating the merit of the appl icants through a bibliometric indicator of their research 4 productivity.  \nThe next section of the paper describes the recruitment process in Italian universities, \nparticularly the measures adopted in 2008 for the recruitment of associate professors. \nSection 3 presents the dataset used for the analyses. Section 4 presents the results of our \nanalyses on the gender bias, followed by  the results of the regression analyses in Section \n5. The work concludes with the authors’ discussion.  \n \n \n2. Recruitment in Italian universities  \n \nThe Italian Ministry of Education, Universities and Research (MIUR) recognizes a \ntotal of 96 universities as authorized to issue degrees. Sixty -seven of these are public \nuniversities, employing around 95% of all Italian faculty members.  \nIn ke eping with the so -called Humboldtian model of university policy, there are no \n“teaching -only”  universities in Italy. All professors are required to carry out both research \nand teaching. Legislation includes a provision that each faculty member must provide  a \nminimum of 350 hours of teaching per year. All new personnel enter the university system \nthrough public competitions, and career advancement can only proceed by further public \ncompetitions. Salaries are regulated at the centralized level and are calcula ted according \nto role (administrative, technical, or professorial), rank within role (for example assistant, \nassociate or full professor) and seniority. None of a professor’s salary depends on merit. \nMoreover, as in all Italian public administration, the d ismissal of unproductive employees \nis unheard of.  \nThe recruitment and advancement of professors is regulated by laws, which are \noverseen by the MIUR. There have been major reforms over recent years. Law 240 of \n2010 introduced a double evaluation procedure for the selection of associate and full \nprofessors. The first level is a stage of national prequalification for the candidates, \nmanaged directly by the MIUR. A second stage of evaluations is managed by the \nindividual universities, to then choose the prequa lified individuals best suited to the \nspecific needs of each institution. Prior to Law 240, the processes of recruitment and \ncareer advancement were in the hands of the individual universities, which were to follow \nprocedures set by the national ministry. The last major set of competitions under the old \nsystem was held in 2008: the relevant data on these competitions, which are the context \nfor the present work, is described in Section 3.  \nIn the Italian university system all professors are classified in one and only field \n(Scientific Disciplinary Sector or SDS, 370 in all), grouped into disciplines (University \nDisciplinary Areas or UDAs, 14 in all)3. In both the new and old system, competitions \nfor recruitment and advancement are organized at the SDS level. T he 2008 competition \nprocedures required appointment of committees to judge the curricula of the candidates. \nEach committee was to be composed of five full professors belonging to the SDS for \nwhich the position was open. One member, the president, was desig nated by the \nuniversity holding the competition and the other four were drawn at random from a short \nlist of other full professors in the national SDS. The short list was in turn established by \na vote of all full professors in the national SDS.  \nThe task of  each committee was to provide a judgment of all candidates based on \nexamination of their documented qualifications, and name at most two winners. The \n                                                           \n3 For the complete list see http://attiministeriali.miur.it/UserFiles/115.htm , last access  21/07/2015 . 5 university announcing the competition could then hire one of the two top finishers. The \nother top finishe r remained eligible for hiring by any other university in the national \nsystem without further competition, at any time over the next five years.  \nIn order to rationalize the process of the individual competitions over the entire \nsystem, the MIUR monitored a nd gathered the hiring proposals of the various universities \nand supported the evaluation procedures through information management systems \nintended to guarantee greater transparency. One of the ministry measures was to provide \na Web portal4 with all the b asic information on the competition procedures, the posts \navailable, the number of candidates for each competition, the scheduling of the \nprocedures and final results (lists of winners, etc.). The transparency provisions, the \nnomination of a national commi ttee of experts in the field, and the timely issue of \nregulations for the evaluation procedures were all intended to ensure efficiency in the \nselection process. In reality, the characteristics of Italian system – such as the generally \nstrong inclination to  favoritism, the structured lack of consequences for poor performance \nby research units, and the lack of incentive schemes for merit – undermined the credibility \nof selection procedures for the hiring and advancement of university professors. In a \nprecedin g work (Abramo et al., 2014b), we revealed several critical issues, particularly \nconcerning unsuccessful candidates who remarkably outperformed the competition \nwinners in terms of productivity over the subsequent triennium, as well as a number of \ncompetiti on winners who resulted as totally unproductive. An analysis of the individual \ncompetitions showed that almost half of them selected candidates who would go on to \nachieve below -median productivity in their field of reference over the subsequent period. \nIn a subsequent study (Abramo et al., 2015 b), we found that the most important \ndeterminant of a candidate’s success was not his or her scientific merit, rather the number \nof their years of service in the same university as the committee president. In the current \nof these studies we now wish to inve stigate whether gender differences in discrimination \nand favoritism occurred in such competitions.  \n \n \n3. Dataset  \n \nIn 2008, 1,232 competitions for associate professor positions were announced by a \ntotal of 74 Italian universities. The competitions concerned a total of 299 SDSs. At the \nend of all the selection processes, which lasted an average of over two years, the \ncommittees had named 2,339 winners from a total of 16,500 candidates5. The ratio of the \nnumber of competition winners to the size of the existing  national associate professor \nfaculty was 12.8. The competitions generally announced two winners (only 39 announced \none winner).  \nTo ensure the representativeness of publications as proxy of research output for the \nbibliometric assessment of the research me rit of candidates, our analysis focuses only on \nthe competitions in what we define the “bibliometric sectors ”, i.e. those SDSs where at \nleast 50% of professors produced at least one publication indexed in the Web of Science™ \n(WoS) over the period 2004 -2008 . The bibliometric SDSs cover all the hard sciences and \na few fields of Economics. For the observed period, there were 654 competitions that met \n                                                           \n4 The MIUR Web portal, titled  “Comparative evaluation in the recruitment of University Professors and \nResearchers (Law 3, 3 July 1998,  no. 210 )”, is at http://reclutamento.murst.it/  (last access ed 21/07/2015) . \n5 These figures relate to the 1,221 competition procedures that were officially completed (out of 1,232 \nlaunched) at the time of preparing the current research paper.  6 such criteria, in a range of 193 SDSs. The only way to identify all the applicants in these \ncompetitions would be to read the minutes of each competition, as were generally \npublished on -line by the individual universities. Given the prohibitive scope of such a \ntask we have selected a further subset of 287 competitions was extracted from the \npopulation (44% of the t otal 654 in the hard sciences, in 124 SDSs). For this subset, the \nwinners (550 in all) represent 22% of the total candidates (2,590). The rate of selection \nwas more favorable for candidates who were incumbent assistant professors \n(532/2,314=23.0%) than it was for other individuals (18/276=6.5%). Due to the \ndifficulties of authorship disambiguation, our research method is only able to measure the \nproductivity of applicants who are already incumbent faculty members, thus our analysis \nof career advancement con centrates solely on the assistant professor candidates. In \naddition, for reasons of robustness, the measure of research productivity must be \ncalculated over a sufficiently long period (Abramo et al., 2012a). Because of this, the \nanalysis excludes assistant  professors who entered faculty less than three years prior to \nthe date of the competition. The dataset for the analysis is thus composed of 1,979 \nassistant professors, 473 of which were competition winners. Table 1 provides the \ncharacteristics of our data set by UDA and its coverage with respect to overall \ncompetitions in the 193 SDSs of the hard sciences. On average there were nine \nparticipants per competition, of which eight were Italian -national academics. However \nthe number of candidates shows significa nt variation (standard deviation 5.6), and 16 \ncompetitions involve 20 or more candidates. In the majority of competitions (263 out of \n287) the committee designated two winners, with only 24 competitions resulting in a \nsingle winner.  \n \nTable 1: Population subset selected for analysis (in parentheses the percentage with respect to the overall \nreference population by UDA)  \nUDA  Competitions  SDSs  \nconcerned  Winners  Academic w inners with \nseniority ≥ 3 years  \nMathematics and computer science  26 (46%)  7 (78%)  50 (46%)  45 (47%)  \nPhysics  19 (42%)  5 (63%)  37 (43%)  30 (41%)  \nChemistry  25 (46%)  8 (67%)  47 (46%)  44 (48%)  \nEarth sciences  6 (30%)  4 (33%)  10 (27%)  5 (17%)  \nBiology  25 (34%)  14 (74%)  49 (34%)  39 (31%)  \nMedicine  62 (41%)  32 (68%)  116 (40%)  87 (40%)  \nAgricultural and veterinary sciences  15 (31%)  11 (39%)  27 (29%)  26 (30%)  \nCivil engineering  11 (42%)  6 (86%)  22 (43%)  22 (46%)  \nIndustrial and information engineering  86 (60%)  31 (74%)  170 (62%)  155 (62%)  \nPedagogy and psychology  5 (24%)  3 (60%)  8 (20%)  7 (21%)  \nEconomics and statistics  7 (39%)  3 (75%)  14 (39%)  13 (41%)  \nTotal  287 (44%)  124 (64%)  550 (43%)  473 (44%)  \n \n \nTable 2 presents the descriptive statistics concerning the candidates, by gender.  \n 7 Table 2: Descriptive statistics for the candidates involved in the dataset of competitions, by gender  \n     Candidates per competition  \n  Winners  Non winners  Total  Average  Median  Std Dev  Max \nTotal candidates  Female  162  586 748 3 2 2.6 14 \nMale  388 1,454  1,842  6 5 4.7 24 \nTotal  550 2,040  2,590  9 8 5.6 29 \nAcademics  Female  154 518 672 2 2 2.5 14 \nMale  378 1,264  1,642  6 5 4.3 23 \nTotal  532 1,782  2,314  8 7 5.4 28 \nOthers  Female  8 68 76 0 0 0.5 2 \nMale  10 190 200 1 0 1.0 5 \nTotal  18 258 276 1 1 1.2 6 \nAcademics with seniority \n≥ 3 years  Female  141 467 608 2 1 2.3 12 \nMale  332 1,039  1,371  5 4 3.8 22 \nTotal  473 1,506  1,979  7 6 4.6 26 \nAcademics with seniority \n< 3 years  Female  13 51 64 0 0 0.6 3 \nMale  46 225 271 1 1 1.2 5 \nTotal  59 276 335 1 1 1.3 6 \n \n \n4. Bias in  academic recruitment  \n \nThe selection committees judge the applicants for academic positions based on both \nquantitative and qualitative criteria. The committees are free to define the evaluation \nmodels they will apply, relative to the scientific sector and academic rank of concer n. Our \nown investigation of the possible cases of unfair evaluation is based only on the research \nperformance of the candidates. Furthermore, The bibliometric assessment of research \nperformance by quantity and quality of output neglects other attributes of  the scientists’ \nactivities, for example the ability to manage research teams, to attract funds, their \nactivities in consulting, teaching, editorial work, outreach, and so on. Still, common sense \nwould lead one to believe that there is a strong correlation  between research productivity \nand all other dimensions of scientific merit . For example, Marsh and Hattie (2002), Elton \n(2001), and Hattie and Marsh (1996) show evidence of a positive correlation between \nresearch productivity and teaching effectiveness. The assessment of potential cases of \ndiscrimination and favoritism in academic recruitment is therefore subject to a certain \ndegree of uncertainty. Furthermore, like all measures, the FSS measurement itself embeds \nsome degree of uncertainty. In the followin g, when we refer to bias in recruitment, we \nalways imply the embedded uncertainty. For simplicity of language we will generally \nrefer to negative bias as  “discrimination ”, and to positive bias as  “favoritism ”. Because \nof the limits and assumptions embedded  in the methodology and performance indicator \napplied to identify possible cases of bias in recruitment, the usual warnings in the \ninterpretations of results apply.  \n \n \n4.1 Negative bias  \n \nWe define negative bias (discrimination) as a situation where a non -winner candidate \nis observed to have scientific merit notably higher than that of at least one the competition \nwinners, and not less than that of the other non -winner candidates. As the in dicator of the \nscientific merit of a candidate we use their research productivity, quantified by an \nindicator named Fractional Scientific Strength, or FSS, which embeds both the number 8 of publications and their field -normalized citations (for a detailed de scription of the index \nand the underlying theory, see Appendix).  \nSince the committees also apply criteria other than research productivity in making \ntheir selections, we assume that within a difference of 20 FSS percentiles6 the other \ndimensions of merit c ould compensate for the difference in research productivity. This \nthreshold appears reasonable, since it is coherent to expect a positive relation between \nresearch performance and the other variables of academic merit. Thus if a candidate \nplaces 20 percent iles above another, according to the convention we adopt, he or she \nsurely has more merit. If the difference is less than 20, we cannot affirm that there is a \ndifference in merit. Since it is possible that all applicants in a competition would be of \nlittle merit, in order for a candidate to be defined as  “discriminated against ” it is also \nnecessary that their FSS must in all cases be higher than the median of the national \nperformance distribution of all their colleagues of the same rank and SDS. In this reg ard, \nwe also recall the committees would have been free not to name any winners.  \nIn summary, the conditions necessary for a candidate to be defined as subject to \nnegative bias are:  \ni. There must be a positive difference of 20 percentiles (national ranking of assistant \nprofessors, by FSS) between the non -winner candidate and the worst of the \nwinners;  \nii. The FSS of the candidate must not be less than the median of the national \ndistribution of assistant professors in the SDS;  \niii. There must be a negative difference of p erformance of not more than 20 \npercentiles between the non -winning candidate and the best of those that satisfy \nthe first two conditions.  \nGiven the above conditions there could more than one subject of discrimination per \ncompetition.  \nTo ensure a robust ana lysis of bibliometric productivity (Abramo et al., 2012a), of the \n287 competition analyzed in detail up to this point we now further exclude those \ncompetitions (44 out of 287) lacking at least a winner and a non -winning participant with \nat least three year s in a faculty position over the 2004 -2008 period. Given the exclusions, \nwe reduce the number of competitions observed to 243.  \nWe now present the results of the gender differences in discrimination, analyzed from \ntwo points of view: the numerosity of the s ubjects of discrimination and the extent of the \ndiscrimination.  \nWe first measure the FSS of all candidates and assistant professors in the SDSs where \nthe 243 competitions were launched. On the basis of the defined conditions we then \nidentify the candidates  that were subject to discrimination during the judgment of the \ncompetition. Finally we investigate the gender differences of such discrimination, by \nUDA (Table 3).  \nFrom the analysis it emerges that there are a total of 323 cases of discrimination out \nof 1,883 applicants, relative to 422 winners. Of the subjects of discrimination, 24.1% are \nwomen against 75.9% that are men, compared to 30.6% of applicants being female and \n64.9% being male. Student’s t -test confirms that female applicants are significantly l ess \nsubject to discrimination than males (p -value<0.01).  \n \n                                                           \n6 As explained in detail in the Appendix, the FSS percentile refers to the distribution of productivity of all \nthe national assistant professors in the same SDS.  Table 3: Candidates biased against, applicants, and correlation between FSS and competition outcome, by gender and UDA (% in brackets)  \nUDA  Biased against  Applicants  Correlation FSS -competition outcome  \nF M Tot F M Tot F M Tot \nMathematics and computer science  7 (21.2)  26 (78.8)  33 101 (35.3)  185 (64.7)  286 0.330***  0.255***  0.284***  \nPhysics  5 (16.1)  26 (83.9)  31 40 (23.7)  129 (76.3)  169 0.007  0.187*  0.123  \nChemistry  9 (31.0)  20 (69.0)  29 65 (46.1)  76 (53.9)  141 0.108  0.347**  0.207*  \nEarth sciences  - - - 5 (22.7)  17 (77.3)  22 0.409  0.298  0.313  \nBiology  15 (53.6)  13 (46.4)  28 110 (65.5)  58 (34.5)  168 -0.019  -0.090  -0.038  \nMedicine  12 (19.0)  51 (81.0)  63 65 (21.9)  232 (78.1)  297 -0.013  0.076  0.062  \nAgricultural and veterinary sciences  4 (44.4)  5 (55.6)  9 15 (38.5)  24 (61.5)  39 -0.160  -0.146  -0.133  \nCivil engineering  2 (8.0)  23 (92.0)  25 24 (21.8)  86 (78.2)  110 0.443**  -0.004  0.097  \nIndustrial and information engineering  16 (17.2)  77 (82.8)  93 113 (19.6)  465 (80.4)  578 0.222**  0.134***  0.144***  \nPedagogy and psychology  3 (60.0)  2 (40.0)  5 11 (55.0)  9 (45.0)  20 0.098  0.030  0.055  \nEconomics and statistics  5 (71.4)  2 (28.6)  7 27 (50.9)  26 (49.1)  53 0.238  0.182  0.216  \nTotal  78 (24.1)  245 (75.9)  323 576 (30.6)  1,307 (69.4)  1,883  0.140***  0.101***  0.113***  \nStatistical significance: *p -value < 0.10, **p -value <0.05, ***p -value <0.01.  \nStatistical significance level adjusted using Bonferroni corrections  \n Deepening the examination to the level of the UDAs, the analyses show that the \nincidence of discriminated women out of the total of subjects of discrimination is the \nhighest in Biology (53.6%), where we also observe the highest percentage of female \napplicants (65.5%). Civil engineering has the lowest percentage of female subjects of \ndiscrimination out of the total (8%).  The gender differences in terms of concentration of \nthose discriminated in relation to concentration of applicants results as significant in three \nUDAs out of 107: men result as more discriminated in Mathematics and computer science \n(p-value = 0.053), Civ il engineering (p -value = 0.058), and Chemistry (p -value = 0.069); \nwomen do not result as more subject to discrimination in any of the UDAs.  \nTable 3 also presents the correlation between FSS and competition outcome \n(competition outcome = 1, if the applican t wins the competition; 0, otherwise), by gender \nand UDA. In the case of women, Civil engineering has the highest Pearson correlation \n(0.443). In the case of the men, the highest correlation is observed in Chemistry (0.347).  \nFor each of the 323 applicants subject to discrimination we measure the level of \ndiscrimination in percentiles of FSS, calculated as follows:  \nD= FSS d−(FSS w+20) \n [1] \nWhere:  \nD = level of discrimination;  \nFSS d = FSS percentile of the candidate discriminated;  \nFSS w = FSS percentile of the worst of the winners.  \n \nTable 4 shows the average, maximum and standard deviation of the level of \ndiscrimination, by gender and UDA.  \nThe general analysis shows that the highest discrimination occurs in Civil engineering \n(average dis crimination = 35.4 FSS percentiles), the lowest in Economics and statistics \n(average discrimination = 7.4 FSS percentiles). The average discrimination for women \ncandidates is 21.0 FSS percentiles; that for male candidates is 21.1 percentiles. Student’s \nt-test shows that the averages of female and male levels of discrimination are not \nsignificantly different (p -value=0.459).  \nIn effect, the gender differences in the level of discrimination result as significant in \nonly one UDA out of 10, which is Pedagogy and  psychology (34.5 for women vs. 1.9 for \nmen, p -value = 0.023).  \n \n  \n                                                           \n7 For Earth sciences, since there are no subjects of dis crimination it is not possible to deepen the analyses \nfor the gender differences in this regard.  11 Table 4: Levels of negative bias by gender and UDA, measured in percentiles of FSS  \nUDA  F M Tot \nAvg Std \ndev. Max Avg Std \ndev. Max Avg Std \ndev. Max \nMathematics and computer science  11.9 9.0 27.0 12.7 10.9 35.6 12.5 10.4 35.6 \nPhysics  16.3 10.5 32.8 20.5 15.9 52.1 19.8 15.1 52.1 \nChemistry  20.5 16.2 47.5 18.0 13.2 42.2 18.8 14.0 47.5 \nEarth sciences  - - - - - - - - - \nBiology  23.1 14.5 59.1 19.0 15.0 57.2 21.2 14.6 59.1 \nMedicine  21.6 12.1 37.9 22.9 12.4 50.6 22.6 12.3 50.6 \nAgricultural and veterinary sciences  25.8 32.5 73.2 37.9 19.0 62.7 32.5 24.8 73.2 \nCivil engineering  36.2 47.9 70.1 35.4 31.2 79.2 35.4 31.5 79.2 \nIndustrial and information engineering  23.1 18.8 58.3 19.7 16.6 73.7 20.3 16.9 73.7 \nPedagogy and psychology  34.5 30.3 58.5 1.9 0.2 2.0 21.5 27.9 58.5 \nEconomics and statistics  6.6 8.1 19.8 9.6 0.6 10.1 7.4 6.8 19.8 \nTotal  21.0 17.5 73.2 21.1 17.7 79.2 21.1 17.6 79.2 \n \n \n4.2 Positive bias  \n \nIf there is negative bias (discrimination) against some of the candidates in a \ncompetition then at least one winner must have undergone positive bias and been favored. \nIn this section we analyze the gender differences among those favored in the \ncompetitions. We def ine favoritism as the situation where the winner of a competition has \na lower scientific merit than at least one non -winning candidate, or in any case lower than \nwhat we would have expected of a winner with respect to all the other colleagues of the \nsame a cademic rank and SDS.  \nAs in the case of the calculation of discrimination, since FSS is not the only criterion \nfor selection in the competitions, we assume that within 20 percentile points the other \nvariables for merit could compensate for the difference i n research productivity. Thus, if \na candidate places 20 percentiles below another for FSS, he or she is surely less worthy. \nIf the difference is less than 20, this cannot be concluded.  \nSummarizing, the sufficient conditions for identifying a candidate as f avored in a \ncompetition are either of the following:  \ni. There is a negative difference in performance of not less than 20 percentile points \n(national ranking of assistant professors, by FSS) between the winning candidate \nand the best of the non -winning applic ants;  \nii. The FSS of the winner is less than the national median of the assistant professors \nin the SDS.  \nAs much as the occurrence of the second condition seems unlikely, we observe that: \nin 78 competitions at least one winner showed performance less than the national median; \nin 13 competitions a candidate resulted as selected while satisfying the second cond ition \nonly; in one competition all the candidates had productivity below the national median, \nbut two winners were still chosen. The question that naturally arises is not why assistant \nprofessors with a poor scientific portfolio would have entered the comp etitions, but why \nthose with a high profile did not. Among those familiar with the culture and the practices \nof favoritism in the Italian university environment it is well known that, for purposes of \n“taking turns ” in sharing out of positions, full professors will often place pressure on \nworthy assistant professors in their universities to hold back from entering competitions, \nin order not to create problems at the moment when the committees move to select the \nprede termined individual for that occasion.  12 For the same 243 competitions examined in the analysis of discrimination, we thus \nidentify those candidates that were favored in the judgment stage and analyze the potential \ngender differences that may have occurred i n such favoritism (Table 5).  \nFrom the analysis there emerge a total of 186 favored candidates out of 422 winners and \n1,833 applicants. Some 32.8% of the total favored candidates are women, against 67.2% \nmen; compared to 30.6% of the applicants being of fem ale gender and 64.9% male. \nStudent’s t -test does not indicate gender differences among favored candidates (p -\nvalue=0.246).  \n \nTable 5: Candidates benefitting from positive bias and applicants, by gender and UDA (% in brackets)  \nUDA  Favored candidates  Applicants  \nF M Tot F M Tot \nMathematics and computer science  3 (23.1)  10 (76.9)  13 101 (35.3)  185 (64.7)  286 \nPhysics  6 (33.3)  12 (66.7)  18 40 (23.7)  129 (76.3)  169 \nChemistry  10 (52.6)  9 (47.4)  19 65 (46.1)  76 (53.9)  141 \nEarth sciences  - - - 5 (22.7)  17 (77.3)  22 \nBiology  10 (50)  10 (50)  20 110 (65.5)  58 (34.5)  168 \nMedicine  10 (28.6)  25 (71.4)  35 65 (21.9)  232 (78.1)  297 \nAgricultural and veterinary sciences  3 (50)  3 (50)  6 15 (38.5)  24 (61.5)  39 \nCivil engineering  1 (16.7)  5 (83.3)  6 24 (21.8)  86 (78.2)  110 \nIndustrial and information engineering  15 (24.6)  46 (75.4)  61 113 (19.6)  465 (80.4)  578 \nPedagogy and psychology  3 (60)  2 (40)  5 11 (55)  9 (45)  20 \nEconomics and statistics  0 (0)  3 (100.0)  3 27 (50.9)  26 (49.1)  53 \nTotal  61 (32.8)  125 (67.2)  186 576 (30.6)  1,307 (69.4)  1,883  \nDeepening the analysis by UDA, we observe that the incidence of favored women in \nthe total of favored candidates is highest in Pedagogy and psychology (60.0%). Civil \nengineering has the lowest percentage of favored women in the total (16.7%). Gender \ndifferences among favored winners result as significant in two UDAs out of 108. In both \ncases it is the men that result as more favored than women: in Economics and Statistics \n(p-value=0.036) and in Biology (p -value=0.061).  \nTable 6 shows the level of favoritism in percentiles of FSS, calculated as follows:  \nF= FSS a−(FSS f+20) \n [2] \nWhere:  \nF = level of favoritism;  \nFSS a = percentile of FSS of the best non -winner candidate;  \nFSS f = percentile of FSS of the favored candidate.  \n \nThe analyses show the average, the standard deviation and the maximum level of \nfavoritism, by gender and UDA. The general analysis shows that the highest level of \nfavoritism is in Civil engineering (average f avoritism = 35.8 percentiles of FSS), the \nlowest is in Economics and statistics (average = 10.5 percentiles of FSS). The average \nfavoritism for the women candidates equals 19.8 percentiles of FSS ; that for the men \ncandidates equals 19.5 percentiles of FSS.  Student’s t -test shows that the averages of \nfemale and male favoritism or not significantly different (p -value=0.456).  \nIn the analyses at the more detailed level, the gender differences in level of favoritism \nresult as not significant for all the UDAs.  \n  \n                                                           \n8 For Earth sciences, since there are no subjects of favoritism it is not possible to deepen the analyses for \nthe gender differences in this regard . 13 Table 6: Level of positive bias by gender and UDA, measured in percentiles of FSS  \nUDA  F M Tot \nAvg Std \ndev. Max Avg Std \ndev. Max Avg Std \ndev. Max \nMathematics and computer science  17.4 15.1 27.0 9.7 10.7 35.6 11.5 11.6 35.6 \nPhysics  20.5 19.2 52.1 17.0 15.0 40.2 18.2 16.1 52.1 \nChemistry  18.3 15.5 47.5 17.1 13.3 39.6 17.7 14.0 47.5 \nEarth sciences  - - - - - - - - - \nBiology  17.5 10.0 35.0 21.3 18.3 59.1 19.4 14.4 59.1 \nMedicine  20.6 13.2 47.9 20.9 12.7 50.6 20.8 12.6 50.6 \nAgricultural and veterinary sciences  14.9 8.2 23.0 46.4 37.8 73.2 30.6 29.9 73.2 \nCivil engineering  21.4 - 21.4 38.7 33.7 79.2 35.8 31.0 79.2 \nIndustrial and information engineering  21.8 16.7 60.8 18.7 18.5 73.7 19.6 18.0 73.7 \nPedagogy and psychology  24.6 30.0 58.5 2.0 - 2.0 18.9 26.9 58.5 \nEconomics and statistics  - - - 10.5 9.2 19.8 10.5 9.2 19.8 \nTotal  19.8 14.8 60.8 19.5 18.2 79.2 19.6 17.1 79.2 \n \n \n5. Statistical Analysis  \n \nFor the competitions of our dataset, we formulate a statistical model that links  the \ncompetition outcome to the possible determinants, as described below.  \nThe dependent variable, the competition outcome, is a Boolean type variable with \nvalue of 1 in the case that the applicant wins, or 0 otherwise. The eight independent \nvariables are:  the parental link between applicant and full professors in the same \nuniversity (NE); the career years that an applicant has spent in the same university and \nsame SDS as the committee president (CP); the career years that an applicant has spent \nin the same  university and the same SDS as other committee members (CE); the \npercentage of the president’s publications coauthored with the candidate (PP); the number \nof other committee members with which the applicant has co -authored publications (PE); \nthe applicant ’s scientific productivity (FSS) for the five years 2004 -2008, as proxy of \nscientific merit; the agreement between the gender of the applicant and the gender of the \ncommittee president (SP); and the agreement between the gender of the applicant and at \nleast three committee members (president included) (SE).  \nTo study the effect of gender on the eight independent variables which determine the \ncompetition outcome, we introduce the Boolean independent variable G, whose value is \n1 in the case that the applicant is female, and 0 otherwise. In addition to the eight \nindependent variables presented above we introduce in the model the same variables each \nmultiplied by G.  \nAs the basis of the statistical model we choose the logistic regression function \n(linearized by th e logit function), which is particularly suited for modeling dichotomous \ndependent variables. Formally, the statistical model is described as:  \n \n𝑙𝑜𝑔𝑖𝑡 (𝑝)=𝛽0+𝛽1𝐺+𝛽2𝐹𝑆𝑆 +𝛽3𝐺∙𝐹𝑆𝑆 +𝛽4𝑁𝐸+𝛽5𝐺∙𝑁𝐸+𝛽6𝐶𝑃+𝛽7𝐺∙𝐶𝑃\n+𝛽8𝐶𝐸+𝛽9𝐺∙𝐶𝐸+𝛽10𝑃𝑃+𝛽11𝐺∙𝑃𝑃+𝛽12𝑃𝐸+𝛽13𝐺∙𝑃𝐸\n+𝛽14𝑆𝑃+𝛽15𝐺∙𝑆𝑃+𝛽16𝑆𝐸+𝛽17𝐺∙𝑆𝐸) \n [3] \nWhere:  \nlogit (p) = logp(E)\n1-p(E) [4] \nE = competition outcome: 1, if the applicant wins the competition; 0, otherwise;  14 p(E) = probability of event E;  \nβ = generic regression coefficient;  \nG = 1, if the applicant is female; 0, if the applicant is male.  \nFSS = applicant’s research productivity over the period 2004 -2008, expressed on a 0 -100 \npercentile scale;  \nNE= 1, if the applicant and a full professor in the same university have the same family \nname; 0, otherwise.  \nCP = applicant’s career years in the same university and same SDS as the committee \npresident over the period 2001 -2010.  \nCE = applicant’s career years in the same university and the same SDS as the other \nevaluation committee members over the period 2001 -2010.  \nPP = percentage of committee president’s publications in co -authorship with the \ncandidate over the period 2001 -2010.  \nPE = number of other committee members with which the applicant has co -authored \npublications over the period 2001 -2010.  \nSP = 1, if the applicant has the same gender as the committee president; 0, otherwise.  \nSE = 1, if the applicant has the same gender as at least three committee members \n(president included); 0, otherwise.  \n \n \n5.1 Descriptive statistics  \n \nPrior to applying the statistical model we present the descriptive statistics for the basic \nvariables in Table 7, distinguishing by applicant gender. For each variable we show the \naverage, standard deviation (SD) and the maximum value occurring for the winners, non -\nwinners and total applicants in the dataset.  \nIn the case of the female applicants,  the winners’ scientific performance is on average \nhigher than that of non -winners (65.13 for winners versus 57.14 for non -winners). The \naverage number of years that the female applicant spent in the same university as the \ncommittee president (CP) is 1.99;  for winners this figure rises to 4.16 and for non -winners \nit drops to 1.34. For the set of all female applicants, the average number of years spent in \nthe same university as the other committee members (CE) is 1.50, compared to 1.13 for \nthe winners and 1. 62 for non -winners. Concerning co -authored publications, on average \nthe full set of female participants contribute to 2.45% of the president’s scientific \nproduction; winners contribute to 8.10% and non -winners to 0.75%. Some 14% of the \nfemale applicants ar e of the same gender as the committee president; this percentage rises \nto 16% in the case of the winners and remains at 14% for the non -winners.  \nIn the case of male applicants, once again the winners’ scientific performance is on \naverage higher than that o f non -winners (69.64 for winners versus 63.80 for non -\nwinners), although the difference is less than for females (65.13 for winners versus 57.14 \nfor non -winners). The average number of years that the male applicant spent in the same \nuniversity as the commi ttee president is 2.16; for winners this figure rises to 4.31 and for \nnon-winners it drops to 1.47. For the set of all male applicants, the average number of \nyears spent in the same university as the other evaluators is 1.17, compared to 1.27 for \nthe winne rs and 1.14 for the non -winners. Concerning research collaboration, on average \nthe full set of male participants contribute to 2.34% of the president’s scientific \nproduction; winners contribute to 6.55% and non -winners to 0.99%. Some 91% of the \nmale applic ants are the same gender as the committee president; this percentage equals 15 95% in the case of winners and 90% in the case non -winners. Finally, we note that \nconcerning the variable NE (signal of possible cases of nepotism), an average of 4% of \nfemale appl icants have the same family name as a full professor in the university holding \nthe competition. This percentage increased to 7% in the case of female winners and drops \nto 3% in the case of female non -winners. In the case of male applicants this percentage \nequals 4% both for the winners and non -winners.  \n \nTable 7: Descriptive statistics for logistic regression variables, by applicant gender  \nFemale Applicants  \nVar. Winners  Non winners  Total  \nAvg SD Max Avg SD Max Avg SD Max \nFSS 65.13  21.03  99.12  57.14  24.65  100 58.99  24.08  100 \nNE 0.07 0.26 0 0.03 0.17 1 0.04 0.19 1 \nCP 4.16 4.37 10 1.34 3.15 10 1.99 3.67 10 \nCE 1.13 3.59 20 1.62 4.01 21 1.50 3.92 21 \nPP 8.10 18.55  71.88  0.75 4.85 68.89  2.45 10.35  71.88  \nPE 0.13 0.42 3 0.09 0.30 2 0.10 0.33 3 \nSP 0.16 0.36 1 0.14 0.34 1 0.14 0.35 1 \nSE 0.08 0.27 1 0.08 0.27 1 0.08 0.27 1 \n          \nMale Applicants  \nVar. Winners  Non winners  Total  \nAvg SD Max Avg SD Max Avg SD Max \nFSS 69.64  24.20  100 63.80  24.93  99.73  65.21  24.87  100 \nNE 0.04 0.20 1 0.04 0.20 1 0.04 0.20 1 \nCP 4.31 4.37 10 1.47 3.15 10 2.16 3.69 10 \nCE 1.27 3.44 20 1.14 3.03 20 1.17 3.13 20 \nPP 6.55 16.32  91.18  0.99 6.76 97.36  2.34 10.23  97.36  \nPE 0.12 0.35 2 0.08 0.28 2 0.09 0.30 2 \nSP 0.95 0.21 1 0.90 0.30 1 0.91 0.28 1 \nSE 0.97 0.16 1 0.97 0.16 1 0.97 0.16 1 \n \n \n5.2 Correlation Analysis  \n \nTable 8 presents the correlations between the basic regressors , comparing the case of \nthe female applicants to that of the male applicants. In the case of the women, the Pearson \ncorrelation analysis indicates that the highest correlations are between CP and PP, at \n0.386, and between CE and PE, at 0.361. This is in li ne with what we expect, since \nscientists in the same university and SDS would tend to cooperate in shared research \nwork. The test of multicollinearity between the variables shows that the average VIF \n(Variance inflation factor) is 1.10. In the case of the male applicants, the Pearson \ncorrelation analysis indicates that the highest correlations are once again between PP and \nCP (0.356) and PE and CE (0.335). The test of multicollinearity shows that the average \nVIF is 1.09.  \nThus from the Pearson correlation an alysis and the test of multicollinearity between \nvariables, for both cases of male and female applicants it emerges that the hypothesis of \nindependence between the variables can be considered valid.  \n \n  16 Table 8: Correlation among v ariables, by applicant gender  \nFemale applicants  \n E FSS NE CP CE PP PE SP SE \nE 1         \nFSS 0.140***  1        \nNE 0.089  0.013  1       \nCP 0.326***  0.054  -0.020  1      \nCE -0.052  -0.049  -0.022  -0.188***  1     \nPP 0.300***  0.026  0.055  0.386***  -0.091  1    \nPE 0.060  -0.028  -0.035  -0.137**  0.361***  -0.071  1   \nSP 0.023  0.097  -0.058  0.055  0.024  0.026  -0.079  1  \nSE -0.002  -0.048  0.003  -0.021  0.028  0.071  -0.014  0.039  1 \n \nMale applicants  \n E FSS NE CP CE PP PE SP SE \nE 1         \nFSS 0.101***  1        \nNE 0.002  -0.027  1       \nCP 0.330***  -0.031  -0.010  1      \nCE 0.018  -0.047  0.001  -0.210***  1     \nPP 0.233***  0.051  -0.017  0.356***  -0.072  1    \nPE 0.065  0.033  -0.035  -0.070  0.335***  -0.019  1   \nSP 0.081*  -0.018  0.027  0.038  -0.002  0.052  0.047  1  \nSE -0.000  -0.028  0.012  0.014  0.020  0.011  -0.027  -0.036  1 \nStatistical significance: *p -value <0.10, **p -value <0.05, ***p -value <0.01  \nStatistical significance level adjusted using Bonferroni corrections  \n \n \n5.3 The Logistic Regression Model  \n \nTable 9 presents the logistic regression results predicting the competition outcomes.  \nThe odds ratio for the competition outcomes (i.e. probability of winning the \ncompetition relative to the probability of not winning) is formalized as:  \n𝑝(𝐸)\n1−𝑝(𝐸)=exp(−3.282 +0.404  𝐺+0.012 𝐹𝑆𝑆 +0.004  𝐺∙𝐹𝑆𝑆 +0.127  𝑁𝐸+0.983  𝐺\n∙𝑁𝐸+0.188  𝐶𝑃−0.028  𝐺∙𝐶𝑃+0.067  𝐶𝐸−0.085  𝐺∙𝐶𝐸+0.024  𝑃𝑃\n+0.020  𝐺∙𝑃𝑃+0.435  𝑃𝐸+0.533  𝐺∙𝑃𝐸+0.691  𝑆𝑃−0.646 𝐺∙𝑆𝑃\n−0.032 𝑆𝐸+0.011  𝐺∙𝑆𝐸) \n [5] \nThe value eb, calculated for each potential explanatory variable, represents the odds \nratio (OR)9 in Table 9. The values calculated for standardized  b (last column, Table 9) \npermit comparison of the effects of the variables measured in different metrics.  \nThe data indicate that the factor having the greatest influence on the competition \noutcomes ( bStd CP=0.693, p -value<0.01) seems to be the number of the applicant’s years \nin the same university and same SDS as the committee president (CP). In particular, every \nunit increase in the number of career years shared with the pres ident increases the odds \nof success by a factor of 1.207. Gender differences are not significant for this regressor.  \nThe applicant’s scientific productivity (FSS) also has remarkable bearing on the \ncompetition results ( bStd PP=0.304, p -value<0.01): every pe rcent increase in FSS \n                                                           \n9 The “odds ratio” is used in statistics to quantify how strongly the presence or absence of property A is \nassociated with the presence or absence of property B, in a given population. In our case, where OR equals \n1 the associated explanatory variable would hav e no effect on the dependent variable , i.e. on com"}
{"date": "2024-01-04-22-29", "error": false, "url": "PDF", "text_blocks": "1\nDeep Representation Learning for Clustering of\nHealth Tweets\nOguzhan Gencoglu\nAbstract —Twitter has been a prominent social media platform\nfor mining population-level health data and accurate clustering\nof health-related tweets into topics is important for extracting\nrelevant health insights. In this work, we propose deep convo-\nlutional autoencoders for learning compact representations of\nhealth-related tweets, further to be employed in clustering. We\ncompare our method to several conventional tweet representation\nmethods including bag-of-words, term frequency-inverse docu-\nment frequency, Latent Dirichlet Allocation and Non-negative\nMatrix Factorization with 3 different clustering algorithms. Our\nresults show that the clustering performance using proposed\nrepresentation learning scheme signiﬁcantly outperforms that of\nconventional methods for all experiments of different number\nof clusters. In addition, we propose a constraint on the learned\nrepresentations during the neural network training in order to\nfurther enhance the clustering performance. All in all, this study\nintroduces utilization of deep neural network-based architectures,\ni.e., deep convolutional autoencoders, for learning informative\nrepresentations of health-related tweets.\nIndex Terms —text clustering, Twitter, deep neural networks,\nconvolutional autoencoders, representation learning\nI. I NTRODUCTION\nSocial media plays an important role in health informatics\nand Twitter has been one of the most inﬂuential social me-\ndia channel for mining population-level health insights [1]–\n[3]. These insights range from forecasting of inﬂuenza epi-\ndemics [4] to predicting adverse drug reactions [5]. A notable\nchallenge due to the short length of Twitter messages is\ncategorization of tweets into topics in a supervised manner,\ni.e., topic classiﬁcation, as well as in an unsupervised manner,\ni.e., clustering.\nClassiﬁcation of tweets into topics has been studied exten-\nsively [6]–[8]. Even though text classiﬁcation algorithms can\nreach signiﬁcant accuracy levels, supervised machine learning\napproaches require annotated data, i.e, topic categories to\nlearn from for classiﬁcation. On the other hand, annotated\ndata is not always available as the annotation process is\nburdensome and time-consuming. In addition, discussions in\nsocial media evolve rapidly with recent trends, rendering\nTwitter a dynamic environment with ever-changing topics.\nTherefore, unsupervised approaches are essential for mining\nhealth-related information from Twitter.\nProposed methods for clustering tweets employ conven-\ntional text clustering pipelines involving preprocessing applied\nto raw text strings, followed by feature extraction which is then\nfollowed by a clustering algorithm [9]–[11]. Performance of\nO. Gencoglu is with Faculty of Medicine and Health Tech-\nnology, Tampere University, Tampere, 33014, Finland e-mail:\n(oguzhangencoglu90@gmail.com).such approaches depend highly on feature extraction in which\ncareful engineering and domain knowledge is required [12].\nRecent advancements in machine learning research, i.e., deep\nneural networks, enable efﬁcient representation learning from\nraw data in a hierarchical manner [13], [14]. Several natural\nlanguage processing (NLP) tasks involving Twitter data have\nbeneﬁted from deep neural network-based approaches includ-\ning sentiment classiﬁcation of tweets [15], predicting potential\nsuicide attempts from Twitter [16] and simulating epidemics\nfrom Twitter [17].\nIn this work, we propose deep convolutional autoencoders\n(CAEs) for obtaining efﬁcient representations of health-related\ntweets in an unsupervised manner. We validate our approach\non a publicly available dataset from Twitter by comparing the\nperformance of our approach and conventional feature extrac-\ntion methods on 3 different clustering algorithms. Furthermore,\nwe propose a constraint on the learned representations during\nneural network training in order to further improve the clus-\ntering performance. We show that the proposed deep neural\nnetwork-based representation learning method outperforms\nconventional methods in terms of clustering performance in\nexperiments of varying number of clusters.\nII. R ELATED WORK\nDevising efﬁcient representations of tweets, i.e., features,\nfor performing clustering has been studied extensively. Most\nfrequently used features for representing the text in tweets\nas numerical vectors are bag-of-words (BoWs) and term\nfrequency-inverse document frequency (tf-idf) features [10],\n[11], [18]–[20]. Both of these feature extraction methods are\nbased on word occurrence counts and eventually, result in\na sparse (most elements being zero) document-term matrix.\nProposed algorithms for clustering tweets into topics include\nvariants of hierarchical, density-based and centroid-based clus-\ntering methods; k-means algorithm being the most frequently\nused one [10], [20], [21].\nNumerous works on topic modeling of tweets are available\nas well. Topic models are generative models, relying on\nthe idea that a given tweet is a mixture of topics, where\na topic is a probability distribution over words [22]. Even\nthough the objective in topic modeling is slightly different\nthan that of pure clustering, representing each tweet as a topic\nvector is essentially a way of dimensionality reduction or\nfeature extraction and can further be followed by a clustering\nalgorithm. Proposed topic modeling methods include conven-\ntional approaches or variants of them such as Latent Dirichlet\nAllocation (LDA) [10], [18], [20], [23]–[30] and Non-negativearXiv:1901.00439v1  [cs.CL]  25 Dec 20182\nMatrix Factorization (NMF) [19], [31]. Note that topic models\nsuch as LDA are based on the notion that words belonging to\na topic are more likely to appear in the same document and\ndo not assume a distance metric between discovered topics.\nIn contrary to abovementioned feature extraction methods\nwhich are not speciﬁc to representation of tweets but rather\ngeneric in natural language processing, various works propose\ncustom feature extraction methods for certain health-related\ninformation retrieval tasks from Twitter. For instance, Lim et\nal. engineered sentiment analysis features to discover latent\ninfectious diseases from Twitter [32]. In order to track public\nhealth condition trends from Twitter, speciﬁc features are pro-\nposed by Parker at al. employing Wikipedia article index, i.e.,\ntreating the retrieval of medically-related Wikipedia articles\nas an indicator of a health-related condition [33]. Custom user\nsimilarity features calculated from tweets were also proposed\nfor building a framework for recommending health-related\ntopics [28].\nThe idea of learning effective representations from raw\ndata using neural networks has been employed in numerous\nmachine learning domains such as computer vision and natural\nlanguage processing [13], [14]. The concept relies on the hier-\narchical, layer-wise architecture of neural networks in which\nthe raw input data is encoded into informative representations\nof lower dimensions (representations of higher dimensions are\npossible as well) in a highly non-linear fashion. Autoencoders,\nDenoising Autoencoders, Convolutional Autoencoders, Sparse\nAutoencoders, Stacked Autoencoders and combinations of\nthese, e.g., Denoising Convolutional Autoencoders, are the\nmost common deep neural network architectures speciﬁcally\nused for representation learning. In an autoencoder training,\nthe network tries to reconstruct the input data at its output,\nwhich forces the model to capture the most salient features of\nthe data at its intermediate layers. If the intermediate layers\ncorrespond to a lower dimensional latent space than the origi-\nnal input, such autoencoders are also known as undercomplete .\nActivations extracted from these layers can be considered as\ncompact, non-linear representations of the input.\nAnother signiﬁcant advancement in neural network-based\nrepresentation learning in NLP tasks is word embeddings (also\ncalled distributed representation of words ). By representing\neach word in a given vocabulary with a real-valued vector\nof a ﬁxed dimension, word embeddings enable capturing of\nlexical, semantic or even syntactic similarities between words.\nTypically, these vector representations are learned from large\ncorpora and can be used to enhance the performance of\nnumerous NLP tasks such as document classiﬁcation, question\nanswering and machine translation. Most frequently used word\nembeddings are word2vec [34] and GloVe (Global Vectors for\nWord Representation) [35]. Both of these are extracted in an\nunsupervised manner and are based on the distributional hy-\npothesis [36], i.e., the assumption that words that occur in the\nsame contexts tend to have similar meanings. Both word2vec\nand GloVe treat a word as a smallest entity to train on. A\nshift in this paradigm was introduced by fastText [37], which\ntreats each word as a bag of character n-grams. Consequently,\nfastText embeddings are shown to have better representations\nfor rare words [37]. In addition, one can still construct a vectorrepresentation for an out-of-vocabulary word which is not\npossible with word2vec or GloVe embeddings [37]. Enhanced\nmethods for deducting better word and/or sentence represen-\ntations were recently introduced as well by Peters et al. with\nthe name ELMo (Embeddings from Language Models) [38]\nand by Devlin et al. with the name BERT (Bidirectional\nEncoder Representations from Transformers) [39]. All of these\nword embedding models are trained on large corpora such as\nWikipedia, in an unsupervised manner. For analyzing tweets,\nword2vec and GloVe word embeddings have been employed\nfor topical clustering of tweets [40], topic modeling [41], [42]\nand extracting depression symptoms from tweets [21].\nMetrics for evaluating the performance of clustering algo-\nrithms varies depending on whether the ground truth topic\ncategories are available or not. If so, frequently used metrics\nareaccuracy andnormalized mutual information . In the case\nof absence of ground truth labels, one has to use internal clus-\ntering criterions such as Calinski-Harabasz (CH) score [43]\nand Davies-Bouldin index [44]. Arbelaitz et al. provides an\nextensive comparative study of cluster validity indices [45].\nIII. M ETHODS\nA. Dataset\nFor this study, a publicly available dataset is used [46]. The\ndataset consisting of tweets has been collected using Twitter\nAPI and was initially introduced by Karami et al. [47]. Earliest\ntweet dates back to 13 June 2011 where the latest one has\na timestamp of 9 April 2015. The dataset consists of 63,326\ntweets in English language, collected from Twitter channels of\n16 major health news agencies. List of health news channels\nand the number of tweets in the dataset from each channel can\nbe examined from Table I.\nTABLE I\nNUMBER OF TWEETS ,TOTAL NUMBER OF WORDS ,NUMBER OF UNIQUE\nWORDS AND AVERAGE NUMBER OF WORDS FOR TWEETS FROM 16\nHEALTH -RELATED TWITTER CHANNELS .\nTwitter Channel Number\nof TweetsNumber\nof WordsNumber\nof Unique\nWordsMean\nWord\nCount\nBBC Health 3,929 22,543 4,334 5.7\nCBC Health 3,741 34,144 6,529 9.1\nCNN Health 4,061 45,369 6,568 11.2\nEveryday Health 3,239 37,032 3,966 11.4\nFox News Health 2,000 18,134 4,315 9.1\nGuardian Healthcare 2,997 42,481 4,139 14.2\nGoodhealth 7,864 105,370 8,002 13.4\nKaiser Health 3,509 39,182 5,133 11.2\nLA Times Health 4,171 50,715 7,648 12.2\nMSN Health 3,199 26,252 4,275 8.2\nNBC Health 4,215 35,909 5,910 8.5\nNPR Health 4,837 43,427 7,303 9.0\nNY Times Health 6,245 62,726 8,567 10.0\nReuters Health 4,719 44,210 6,482 9.4\nUS News Health 1,400 16,546 2,869 11.8\nWSJ Health 3,200 40,317 6,792 12.6\nThe outlook of a typical tweet from the dataset can be\nexamined from Figure 1. For every tweet, the raw data consists\nof the tweet text and in most cases followed by a url to\nthe original news article of the particular news source. This\nurl string, if available, is removed from each tweet as it3\ndoes not possess any natural language information. As Twitter\nallows several ways for users to interact such as retweeting\normentioning , these actions appear in the raw text as well.\nFor retweets, an indicator string of ”RT” appears as a preﬁx\nin the raw data and for user mentions, a string of form\n”@username” appears in the raw data. These two tokens are\nremoved as well. In addition, hashtags are converted to plain\ntokens by removal of the ”#” sign appearing before them (e.g.\n<#pregnancy >becomes <pregnancy >). Number of words,\nnumber of unique words and mean word counts for each\nTwitter channel can also be examined from Table I. Longest\ntweet consists of 27 words.\nB. Conventional Representations\nFor representing tweets, 5 conventional representation meth-\nods are proposed as baselines.\n1)Word frequency features : For word occurrence-based\nrepresentations of tweets, conventional tf-idf and BoWs\nare used to obtain the document-term matrix ofN\u0002P\nin which each row corresponds to a tweet and each\ncolumn corresponds to a unique word/token, i.e., Ndata\npoints and Pfeatures. As the document-term matrix ob-\ntained from tf-idf or BoWs features is extremely sparse\nand consequently redundant across many dimensions,\ndimensionality reduction and topic modeling to a lower\ndimensional latent space is performed by the methods\nbelow.\n2)Principal Component Analysis (PCA) : PCA is used to\nmap the word frequency representations from the origi-\nnal feature space to a lower dimensional feature space by\nanorthogonal linear transformation in such a way that\nthe ﬁrst principal component has the highest possible\nvariance and similarly, each succeeding component has\nthe highest variance possible while being orthogonal to\nthe preceding components. Our PCA implementation has\na time complexity of O(NP2+P3).\n3)Truncated Singular Value Decomposition (t-SVD) : Stan-\ndard SVD and t-SVD are commonly employed dimen-\nsionality reduction techniques in which a matrix is\nreduced or approximated into a low-rank decomposition.\nTime complexity of SVD and t-SVD for Scomponents\nareO(min(NP2; N2P))andO(N2S), respectively\n(depending on the implementation). Contrary to PCA,\nt-SVD can be applied to sparse matrices efﬁciently as\nit does not require data normalization. When the data\nmatrix is obtained by BoWs or tf-idf representations\nas in our case, the technique is also known as Latent\nSemantic Analysis .\n4)LDA: Our LDA implementation employs online varia-\ntional Bayes algorithm introduced by Hoffman et al.\nwhich uses stochastic optimization to maximize the\nobjective function for the topic model [48].\n5)NMF : As NMF ﬁnds two non-negative matrices whose\nproduct approximates the non-negative document-term\nmatrix, it allows regularization. Our implementation\ndid not employ any regularization and the divergence\nfunction is set to be squared error, i.e., Frobenius norm.\n...\nWord \nEmbeddings \nthe health benefits of alcohol consumption are more limited than \npreviously thought, researchers say \n.\n.\n.\nthehealth researchers say benefits ...\nConv-2D \nMaxPool-2D \nConv-2D \nMaxPool-2D \nConv-2D \nMaxPool-2D \nConv-2D \nUpSampling-2D \nConv-2D \nUpSampling-2D \nConv-2D \nUpSampling-2D \nConv-2D 2D output 2D input \nFlatten Representations L2-norm \nconstraint .\n.\n..\n.\n..\n.\n..\n.\n.DECODER ENCODER Fig. 1. Proposed representation learning method depicting the overall ﬂow\nstarting from a tweet to the learned features, including the architecture of the\nconvolutional autoencoder.4\nC. Representation Learning\nWe propose 2D convolutional autoencoders for extracting\ncompact representations of tweets from their raw form in a\nhighly non-linear fashion. In order to turn a given tweet into\na 2D structure to be fed into the CAE, we extract the word\nvectors of each word using word embedding models, i.e., for\na given tweet, t, consisting of Wwords, the 2D input is\nIt2RW\u0002Dwhere Dis the embedding vector dimension.\nWe compare 4 different word embeddings namely word2vec ,\nGloVe ,fastText andBERT with embedding vector dimensions\nof 300, 300, 300 and 768, respectively. We set the maximum\nsequence length to 32, i.e., for tweets having less number of\nwords, the input matrix is padded with zeros. As word2vec and\nGloVe embeddings can not handle out-of-vocabulary words,\nsuch cases are represented as a vector of zeros. The process\nof extracting word vector representations of a tweet to form\nthe 2D input matrix can be examined from Figure 1.\nThe CAE architecture can be considered as consisting of 2\nparts, ie., the encoder and the decoder . The encoder, fenc(\u0001),\nis the part of the network that compresses the input, I, into a\nlatent space representation, U, and the decoder, fdec(\u0001)aims\nto reconstruct the input from the latent space representation\n(see equation 1). In essence,\nU=fenc(I) =fL(fL\u00001(:::f1(I))) (1)\nwhere Lis the number of layers in the encoder part of the\nCAE.\nThe encoder in the proposed architecture consists of three\n2D convolutional layers with 64, 32 and 1 ﬁlters, respectively.\nThe decoder follows the same symmetry with three convo-\nlutional layers with 1, 32 and 64 ﬁlters, respectively and an\noutput convolutional layer of a single ﬁlter (see Figure 1).\nAll convolutional layers have a kernel size of (3 \u00023) and an\nactivation function of Rectiﬁed Linear Unit (ReLU) except\nthe output layer which employs a linear activation function.\nEach convolutional layer in the encoder is followed by a 2D\nMaxPooling layer and similarly each convolutional layer in\nthe decoder is followed by a 2D UpSampling layer, serving\nas an inverse operation (having the same parameters). The\npooling sizes for pooling layers are (2 \u00025), (2\u00025) and (2\u00022),\nrespectively for the architectures when word2vec, GloVe and\nfastText embeddings are employed. With this conﬁguration,\nan input tweet of size 32\u0002300(corresponding to maximum\nsequence length\u0002embedding dimension, D) is downsampled\nto size of 4\u00026out of the encoder (bottleneck layer). As\nBERT word embeddings have word vectors of ﬁxed size 768,\nthe pooling layer sizes are chosen to be (2 \u00028), (2\u00028) and\n(2\u00022), respectively for that case. In summary, a representation\nof4\u00026 = 24 values is learned for each tweet through the\nencoder, e.g., for fastText embeddings the ﬂow of dimensions\nafter each encoder block is as such : 32\u0002300!16\u000260!\n8\u000212!4\u00026.\nIn numerous NLP tasks, an Embedding Layer is employed\nas the ﬁrst layer of the neural network which can be initialized\nwith the word embedding matrix in order to incorporate\nthe embedding process into the architecture itself instead of\nmanual extraction. In our case, this was not possible becauseof nonexistence of an inversed embedding layer in the decoder\n(as in the relationship between MaxPooling layers and UpSam-\npling layers) as an embedding layer is not differentiable.\nTraining of autoencoders tries to minimize the reconstruc-\ntion error/loss, i.e., the deviation of the reconstructed output\nfrom the input. L2-loss or mean square error (MSE) is chosen\nto be the loss function. In autoencoders, minimizing the\nL2-loss is equivalent to maximizing the mutual information\nbetween the reconstructed inputs and the original ones [49].\nIn addition, from a probabilistic point of view, minimizing\ntheL2-loss is the same as maximizing the probability of the\nparameters given the data, corresponding to a maximum likeli-\nhood estimator . The optimizer for the autoencoder training is\nchosen to be Adam due to its faster convergence abilities [50].\nThe learning rate for the optimizer is set to 10\u00005and the batch\nsize for the training is set to 32. Random split of 80% training-\n20% validation set is performed for monitoring convergence.\nMaximum number of training epochs is set to 50.\nD.L2-norm Constrained Representation Learning\nCertain constraints on neural network weights are com-\nmonly employed during training in order to reduce overﬁtting,\nalso known as regularization . Such constraints include L1\nregularization, L2regularization, orthogonal regularization etc.\nEven though regularization is a common practice, standard\ntraining of neural networks do not inherently impose any\nconstraints on the learned representations (activations), U,\nother than the ones compelled by the activation functions\n(e.g. ReLUs resulting in non-negative outputs). Recent ad-\nvancements in computer vision research show that constraining\nthe learned representations can enhance the effectiveness of\nrepresentation learning, consequently increasing the clustering\nperformance [51], [52].\nminimize L= 1=NkI\u0000fdec(fenc(I))k2\n2\nsubject tokfenc(I)k2\n2= 1(2)\nWe propose an L2norm constraint on the learned repre-\nsentations out of the bottleneck layer, U. Essentially, this is\na hard constraint introduced during neural network training\nthat results in learned features with unit L2norm out of the\nbottleneck layer (see equation 2 where Nis the number of data\npoints). Training a deep convolutional autoencoder with such\na constraint is shown to be much more effective for image data\nthan applying L2normalization on the learned representations\nafter training [52]. To the best of our knowledge, this is the\nﬁrst study to incorporate L2norm constraint in a task involving\ntext data.\nE. Evaluation\nIn order to fairly compare and evaluate the proposed meth-\nods in terms of effectiveness in representation of tweets, we\nﬁx the number of features to 24 for all methods and feed\nthese representations as an input to 3 different clustering\nalgorithms namely, k-means ,Ward andspectral clustering with\ncluster numbers of 10, 20 and 50. Distance metric for k-\nmeans clustering is chosen to be euclidean and the linkage5\n/uni00000013 /uni00000015 /uni00000017 /uni00000019 /uni0000001b /uni00000014/uni00000013 /uni00000014/uni00000015\n/uni00000048/uni00000053/uni00000052/uni00000046/uni0000004b/uni00000056/uni00000013/uni00000011/uni00000013/uni00000013/uni00000013/uni00000011/uni00000013/uni00000018/uni00000013/uni00000011/uni00000014/uni00000013/uni00000013/uni00000011/uni00000014/uni00000018/uni00000013/uni00000011/uni00000015/uni00000013/uni00000013/uni00000011/uni00000015/uni00000018/uni00000030/uni00000036/uni00000028/uni00000057/uni00000055/uni00000044/uni0000004c/uni00000051/uni0000004c/uni00000051/uni0000004a\n/uni00000059/uni00000044/uni0000004f/uni0000004c/uni00000047/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051\n/uni00000057/uni00000055/uni00000044/uni0000004c/uni00000051/uni0000004c/uni00000051/uni0000004a/uni00000003/uni0000000b/uni0000002f/uni00000015/uni00000010/uni00000051/uni00000052/uni00000055/uni00000050/uni0000000c\n/uni00000059/uni00000044/uni0000004f/uni0000004c/uni00000047/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000003/uni0000000b/uni0000002f/uni00000015/uni00000010/uni00000051/uni00000052/uni00000055/uni00000050/uni0000000c\nFig. 2. Learning curves depicting training and validation losses of CAE and\nL2-norm constrained CAE architectures for fastText embeddings.\ncriteria for Ward clustering is chosen to be minimizing the\nsum of differences within all clusters, i.e., recursively merging\npairs of clusters that minimally increases the within-cluster\nvariance in a hierarchical manner. For spectral clustering,\nGaussian kernel has been employed for constructing the afﬁn-\nity matrix. We also run experiments with tf-idf and BoWs\nrepresentations without further dimensionality reduction as\nwell as concatenation of all word embeddings into a long\nfeature vector. For evaluation of clustering performance, we\nuse Calinski-Harabasz score [43], also known as the variance\nratio criterion . CH score is deﬁned as the ratio between the\nwithin-cluster dispersion and the between-cluster dispersion.\nCH score has a range of [0;+1]and a higher CH score\ncorresponds to a better clustering. Computational complexity\nof calculating CH score is O(N).\nFor a given dataset Xconsisting of Ndata points, i.e.,\nX=\b\nx1; x2; :::; x N\t\nand a given set of disjoint clusters C\nwithKclusters, i.e., C=\b\nc1; c2; :::; c K\t\n, Calinski-Harabasz\nscore, SCH, is deﬁned as\nSCH=N\u0000K\nK\u00001P\nck2CNk\r\rck\u0000X\r\r2\n2P\nck2CP\nxi2ckkxi\u0000ckk2\n2(3)\nwhere Nkis the number of points belonging to the cluster ck,\nXis the centroid of the entire dataset,1\nNP\nxi2Xxiandckis\nthe centroid of the cluster ck,1\nNkP\nxi2ckxi.\nFor visual validation, we plot and inspect the t-Distributed\nStochastic Neighbor Embedding (t-SNE) [53] and Uniform\nManifold Approximation and Projection (UMAP) [54] map-\npings of the learned representations as well. Implementation\nof this study is done in Python (version 3.6) using scikit-learn\nandTensorFlow libraries [55], [56] on a 64-bit Ubuntu 16.04\nworkstation with 128 GB RAM. Training of autoencoders are\nperformed with a single NVIDIA Titan Xp GPU.\nIV. R ESULTS\nPerformance of the representations tested on 3 different\nclustering algorithms, i.e., CH scores, for 3 different cluster\nnumbers can be examined from Table II. L2-norm constrained\nCAE is simply referred as L2-CAE in Table II. Same table\nshows the number of features used for each method as well.\nDocument-term matrix extracted by BoWs and tf-idf features\nresult in a sparse matrix of 63;326\u000213;026with a sparsityof 0.9994733. Similarly, concatenation of word embeddings\nresult in a high number of features with 32\u0002300 = 9 ;600\nfor word2vec, GloVe and fastText, 32\u0002768 = 24 ;576\nfor BERT embeddings. In summary, the proposed method\nof learning representations of tweets with CAEs outperform\nall of the conventional algorithms. When representations are\ncompared with Hotelling’s T2test (multivariate version of t-\ntest), every representation distribution learned by CAEs are\nshown to be statistically signiﬁcantly different than every other\nconventional representation distribution with p < 0:001. In\naddition, introducing the L2-norm constraint on the learned\nrepresentations during training enhances the clustering perfor-\nmance further (again p <0:001when comparing for example\nfastText+CAE vs. fastText+ L2-CAE). An example learning\ncurve for CAE and L2-CAE with fastText embeddings as input\ncan also be seen in Figure 2.\nDetailed inspection of tweets that are clustered into the\nsame cluster as well as visual analysis of the formed clusters\nis also performed. Figure 3 shows the t-SNE and UMAP\nmappings (onto 2D plane) of the 10 clusters formed by k-\nmeans algorithm for LDA, CAE and L2-CAE representations.\nBelow are several examples of tweets sampled from one of the\nclusters formed by k-means in the 50 clusters case (fastText\nembeddings fed into L2-CAE):\n\u000f<Suicide risk falls after talk therapy >\n\u000f<Air pollution may be tied to anxiety >\n\u000f<Stress, depression boost risks for heart patients >\n\u000f<Nearly 1 in 5 Americans who has been out of work for\nat least 1 year is clinically depressed. >\n\u000f<Study shows how exercise protects the brain against\ndepression >\nV. D ISCUSSION\nOverall, we show that deep convolutional autoencoder-\nbased feature extraction, i.e., representation learning, from\nhealth related tweets signiﬁcantly enhances the performance\nof clustering algorithms when compared to conventional text\nfeature extraction and topic modeling methods (see Table II).\nThis statement holds true for 3 different clustering algorithms\n(k-means, Ward, spectral) as well as for 3 different number\nof clusters. In addition, proposed constrained training ( L2-\nnorm constraint) is shown to further improve the clustering\nperformance in each experiment as well (see Table II). A\nCalinski-Harabasz score of 4,304 has been achieved with\nconstrained representation learning by CAE for the experiment\nof 50 clusters formed by k-means clustering. The highest CH\nscore achieved in the same experiment setting by conventional\nalgorithms was 638 which was achieved by LDA applied of\ntf-idf features.\nVisualizations of t-SNE and UMAP mappings in Figure 3\nshow that L2-norm constrained training results in higher sep-\narability of clusters. The beneﬁt of this constraint is especially\nsigniﬁcant in the performance of k-means clustering (see\nTable II). This phenomena is not unexpected as k-means\nclustering is based on L2distance as well. The difference in\nlearning curves for regular and constrained CAE trainings is\nalso expected. Constrained CAE training converges to local6\n/uni00000057/uni00000049/uni00000010/uni0000004c/uni00000047/uni00000049/uni00000003/uni0000000e/uni00000003/uni0000002f/uni00000027/uni00000024\n /uni00000025/uni00000028/uni00000035/uni00000037/uni00000003/uni0000000e/uni00000003/uni00000026/uni00000024/uni00000028\n /uni00000025/uni00000028/uni00000035/uni00000037/uni00000003/uni0000000e/uni00000003/uni0000002f/uni00000015/uni00000010/uni00000026/uni00000024/uni00000028\n/uni00000057/uni00000049/uni00000010/uni0000004c/uni00000047/uni00000049/uni00000003/uni0000000e/uni00000003/uni0000002f/uni00000027/uni00000024\n /uni00000025/uni00000028/uni00000035/uni00000037/uni00000003/uni0000000e/uni00000003/uni00000026/uni00000024/uni00000028\n/uni00000057/uni00000010/uni00000036/uni00000031/uni00000028\n/uni00000038/uni00000030/uni00000024/uni00000033/uni00000025/uni00000028/uni00000035/uni00000037/uni00000003/uni0000000e/uni00000003/uni0000002f/uni00000015/uni00000010/uni00000026/uni00000024/uni00000028\n/uni00000013/uni00000014/uni00000015/uni00000016/uni00000017/uni00000018/uni00000019/uni0000001a/uni0000001b/uni0000001c\nFig. 3. UMAP and t-SNE visualizations of representations extracted by LDA, CAE and L2-norm constrained CAE (each having a length of 24) and coloring\nbased on k-means clustering of the representations into 10 clusters.\nTABLE II\nCALINSKI -HARABASZ SCORES FOR SEVERAL CONVENTIONAL METHODS AND PROPOSED CAE -BASED METHODS FOR 3DIFFERENT CLUSTERING\nALGORITHMS AND 3DIFFERENT NUMBER OF CLUSTERS .\n10 clusters 20 clusters 50 clusters\nTweet Representation Features k-means Ward spectral k-means Ward spectral k-means Ward spectral\ntf-idf 13026 23 14 9 15 12 7 12 9 5\nBoW 13026 23 25 9 18 19 7 15 13 5\nword2vec (concatenated) 9600 174 152 110 78 61 64 41 33 21\nGloVe (concatenated) 9600 157 131 119 97 63 71 43 37 27\nfastText (concatenated) 9600 212 163 135 115 84 97 54 50 39\nBERT (concatenated) 24576 206 171 138 123 85 94 57 42 41\ntf-idf + PCA 24 443 333 320 421 316 309 421 396 395\nBoW + PCA 24 679 411 679 543 412 498 507 489 495\ntf-idf + t-SVD 24 419 294 284 437 326 337 404 384 394\nBoW + t-SVD 24 633 385 630 579 427 510 495 480 493\ntf-idf + LDA 24 684 497 627 621 486 620 638 433 614\nBoW + LDA 24 408 280 403 355 260 359 284 214 271\ntf-idf + NMF 24 444 406 434 413 452 449 521 527 594\nBoW + NMF 24 512 477 636 491 460 563 591 556 600\nword2vec + CAE 24 1851 1570 1726 1492 1357 1387 1317 1241 1040\nGloVe + CAE 24 1953 1612 1696 1499 1302 1278 1367 1278 1102\nfastText + CAE 24 3520 3173 3297 1914 1699 1772 1765 1567 1677\nBERT + CAE 24 3467 3203 3288 2032 1768 1882 1834 1645 1711\nword2vec + L2-CAE 24 3060 2964 2998 2513 2424 2501 2284 2043 2193\nGloVe + L2-CAE 24 3100 2931 3017 2602 2499 2526 2280 2076 2200\nfastText + L2-CAE 24 6894 6884 6803 5839 5684 5743 4304 4187 4016\nBERT + L2-CAE 24 7703 7071 6972 5768 5606 4554 4172 4014 2559\nminimum slightly later than unconstrained CAE, i.e., training\nofL2-CAE is slightly slower than that of CAE due to the\nintroduced contraint (see Figure 2).\nWhen it comes to comparison between word embeddings,\nfastText and BERT word vectors result in the highest CH\nscores whereas word2vec and GloVe embeddings result in\nsigniﬁcantly lower performance. This observation can be ex-\nplained by the nature of word2vec and GloVe embeddings\nwhich can not handle out-of-vocabulary tokens. Numerous\ntweets include names of certain drugs which are more likely\nto be absent in the vocabulary of these models, consequentlyresulting in vectors of zeros as embeddings. However, fastText\nembeddings are based on character n-grams which enables\nhandling of out-of-vocabulary tokens, e.g., fastText word vec-\ntors of the tokens <acetaminophen >and<paracetamol >are\ncloser to each other simply due to shared character sequence,\n<acetam >, even if one of them is not in the vocabulary. Note\nthat, <acetaminophen >and<paracetamol >are different\nnames for the same drug.\nUsing tf-idf or BoWs features directly results in very\npoor performance. Similarly, concatenating word embeddings\nto create thousands of features results in signiﬁcantly low7\nperformance compared to methods that reduce these features\nto 24. The main reason is that the bias-variance trade-off is\ndominated by the bias in high dimensional settings especially\nin Euclidean spaces [57]. Due to very high number of features\n(relative to the number of observations), the radius of a given\nregion varies with respect to the nth root of its volume,\nwhereas the number of data points in the region varies roughly\nlinearly with the volume [57]. This phenomena is known\nascurse of dimensionality . As topic models such as LDA\nand NMF are designed to be used on documents that are\nsufﬁciently long to extract robust statistics from, extracted\ntopic vectors fall short in performance as well when it comes\nto tweets due to short texts.\nThe main limitation of this study is the absence of topic\nlabels in the dataset. As a result, internal clustering measure\nof Calinski-Harabasz score was used for evaluating the perfor-\nmance of the formed clusters instead of accuracy or normal-\nized mutual information. Even though CH score is shown to\nbe able to capture clusters of different densities and presence\nof subclusters, it has difﬁculties capturing highly noisy data\nand skewed distributions [58]. In addition, used clustering\nalgorithms, i.e., k-means, Ward and spectral clustering, are\nhard clustering algorithms which results in non-overlapping\nclusters. However, a given tweet can have several topical\nlabels.\nFuture work includes representation learning of health-\nrelated tweets using deep neural network architectures that\ncan inherently learn the sequential nature of the textual\ndata such as recurrent neural networks, e.g., Long Short-\nTerm Memory (LSTM), Gated Recurrent Unit (GRU) etc.\nSequence-to-sequence autoencoders are main examples of\nsuch architectures and they have been shown to be effective\nin encoding paragraphs from Wikipedia and other corpora\nto lower dimensions [59]. Furthermore, encodings out of a\nbidirectional GRU will be tested for clustering performance,\nas such architectures have been employed to represent a given\ntweet in other studies [60]–[62].\nVI. C ONCLUSION\nIn summary, we show that deep convolutional autoencoders\ncan effectively learn compact representations of health-related\ntweets in an unsupervised manner. Conducted analysis show\nthat the proposed representation learning scheme outperforms\nconventional feature extraction methods in three different\nclustering algorithms. In addition, we propose a constraint\non the learned representation in order to further increase the\nclustering performance. Future work includes comparison of\nour model with recurrent neural architectures for clustering\nof health-related tweets. We believe this study serves as an\nadvancement in the ﬁeld of natural language processing for\nhealth informatics especially in clustering of short-text social\nmedia data.\nREFERENCES\n[1] K. Vance, W. Howe, and R. P. Dellavalle, “Social internet sites as a\nsource of public health information,” Dermatologic clinics , vol. 27, no. 2,\npp. 133–136, 2009.[2] M. J. Paul and M. Dredze, “You are what you tweet: Analyzing twitter\nfor public health.” Icwsm , vol. 20, pp. 265–272, 2011.\n[3] “Twitter,” https://twitter.com/, accessed: 2018-10-12.\n[4] H. Achrekar, A. Gandhe, R. Lazarus, S.-H. Yu, and B. Liu, “Predicting\nﬂu trends using twitter data,” in Computer Communications Workshops\n(INFOCOM WKSHPS), 2011 IEEE Conference on . IEEE, 2011, pp.\n702–707.\n[5] J. Bian, U. Topaloglu, and F. Yu, “Towards large-scale twitter mining for\ndrug-related adverse events,” in Proceedings of the 2012 international\nworkshop on Smart health and wellbeing . ACM, 2012, pp. 25–32.\n[6] B. Sriram, D. Fuhry, E. Demir, H. Ferhatosmanoglu, and M. Demirbas,\n“Short text classiﬁcation in twitter to improve information ﬁltering,”\ninProceedings of the 33rd international ACM SIGIR conference on\nResearch and development in information retrieval . ACM, 2010, pp.\n841–842.\n[7] R. Batool, A. M. Khattak, J. Maqbool, and S. Lee, “Precise tweet\nclassiﬁcation and sentiment analysis,” in Computer and Information\nScience (ICIS), 2013 IEEE/ACIS 12th International Conference on .\nIEEE, 2013, pp. 461–466.\n[8] A. Theodotou and A. Stassopoulou, “A system for automatic clas-\nsiﬁcation of twitter messages into categories,” in International and\nInterdisciplinary Conference on Modeling and Using Context . Springer,\n2015, pp. 532–537.\n[9] Y . Lu, P. Zhang, J. Liu, J. Li, and S. Deng, “Health-related hot topic\ndetection in online communities using text clustering,” Plos one , vol. 8,\nno. 2, p. e56221, 2013.\n[10] K. D. Rosa, R. Shah, B. Lin, A. Gershman, and R. Frederking, “Topical\nclustering of tweets,” Proceedings of the ACM SIGIR: SWSM , 2011.\n[11] S. B. Kaleel and A. Abhari, “Cluster-discovery of twitter messages for\nevent detection and trending,” Journal of Computational Science , vol. 6,\npp. 47–57, 2015.\n[12] Y . LeCun, Y . Bengio, and G. Hinton, “Deep learning,” Nature , vol. 521,\nno. 7553, p. 436, 2015.\n[13] G. E. Hinton and R. R. Salakhutdinov, “Reducing the dimensionality of\ndata with neural networks,” science , vol. 313, no. 5786, pp. 504–507,\n2006.\n[14] Y . Bengio, A. Courville, and P. Vincent, “Representation learning: A\nreview and new perspectives,” IEEE transactions on pattern analysis\nand machine intelligence , vol. 35, no. 8, pp. 1798–1828, 2013.\n[15] A. Severyn and A. Moschitti, “Unitn: Training deep convolutional neural\nnetwork for twitter sentiment classiﬁcation,” in Proceedings of the 9th\ninternational workshop on semantic evaluation (SemEval 2015) , 2015,\npp. 464–469.\n[16] A. Benton, M. Mitchell, and D. Hovy, “Multi-task learning for mental\nhealth using social media text,” arXiv preprint arXiv:1712.03538 , 2017.\n[17] L. Zhao, J. Chen, F. Chen, W. Wang, C.-T. Lu, and N. Ramakrishnan,\n“Simnest: Social media nested epidemic simulation via online semi-\nsupervised deep learning,” in Data Mining (ICDM), 2015 IEEE Inter-\nnational Conference on . IEEE, 2015, pp. 639–648.\n[18] D. Ramage, S. T. Dumais, and D. J. Liebling, “Characterizing mi-\ncroblogs with topic models.” ICWSM , vol. 10, no. 1, p. 16, 2010.\n[19] W. Yang and L. Mu, “Gis analysis of depression among twitter users,”\nApplied Geography , vol. 60, pp. 217–223, 2015.\n[20] S. L. Lo, R. Chiong, and D. Cornforth, “An unsupervised multilingual\napproach for online social media topic identiﬁcation,” Expert Systems\nwith Applications , vol. 81, pp. 282–298, 2017.\n[21] L. Ma, Z. Wang, and Y . Zhang, “Extracting depression symptoms\nfrom social networks and web blogs via text mining,” in International\nSymposium on Bioinformatics Research and Applications . Springer,\n2017, pp. 325–330.\n[22] M. Steyvers and T. Grifﬁths, “Probabilistic topic models,” Handbook of\nlatent semantic analysis , vol. 427, no. 7, pp. 424–440, 2007.\n[23] D. M. Blei, A. Y . Ng, and M. I. Jordan, “Latent dirichlet allocation,”\nJournal of machine Learning research , vol. 3, no. Jan, pp. 993–1022,\n2003.\n[24] K. W. Prier, M. S. Smith, C. Giraud-Carrier, and C. L. Hanson,\n“Identifying health-related topics on twitter,” in International conference\non social computing, behavioral-cultural modeling, and prediction .\nSpringer, 2011, pp. 18–25.\n[25] L. Hannachi, O. Asfari, N. Benblidia, F. Bentayeb, N. Kabachi, and\nO. Boussaid, “Community extraction based on topic-driven-model for\nclustering users tweets,” in International Conference on Advanced Data\nMining and Applications . Springer, 2012, pp. 39–51.\n[26] M.-C. Yang and H.-C. Rim, “Identifying interesting twitter contents\nusing topical analysis,” Expert Systems with Applications , vol. 41, no. 9,\npp. 4330–4336, 2014.8\n[27] M. J. Paul and M. Dredze, “Discovering health topics in social media\nusing topic models,” PloS one , vol. 9, no. 8, p. e103408, 2014.\n[28] V . V . Kaveri and V . Maheswari, “A framework for recommending health-\nrelated topics based on topic modeling in conversational data (twitter),”\nCluster Computing , pp. 1–6, 2017.\n[29] A. Karami, A. A. Dahl, G. Turner-McGrievy, H. Kharrazi, and G. Shaw,\n“Characterizing diabetes, diet, exercise, and obesity comments on twit-\nter,” International Journal of Information Management , vol. 38, no. 1,\npp. 1–6, 2018.\n[30] A. Karami, F. Webb, and V . L. Kitzie, “Characterizing transgender health\nissues in twitter,” arXiv preprint arXiv:1808.06022 , 2018.\n[31] X. Yan, J. Guo, S. Liu, X.-q. Cheng, and Y . Wang, “Clustering short text\nusing ncut-weighted non-negative matrix factorization,” in Proceedings\nof the 21st ACM international conference on Information and knowledge\nmanagement . ACM, 2012, pp. 2259–2262.\n[32] S. Lim, C. S. Tucker, and S. Kumara, “An unsupervised machine learning\nmodel for discovering latent infectious diseases using social media data,”\nJournal of biomedical informatics , vol. 66, pp. 82–94, 2017.\n[33] J. Parker, Y . Wei, A. Yates, O. Frieder, and N. Goharian, “A framework\nfor detecting public health trends with twitter,” in Proceedings of\nthe 2013 IEEE/ACM International Conference on Advances in Social\nNetworks Analysis and Mining . ACM, 2013, pp. 556–563.\n[34] T. Mikolov, K. Chen, G. Corrado, and J. Dean, “Efﬁcient estimation of\nword representations in vector space,” arXiv preprint arXiv:1301.3781 ,\n2013.\n[35] J. Pennington, R. Socher, and C. Manning, “Glove: Global vectors\nfor word representation,” in Proceedings of the 2014 conference on\nempirical methods in natural language processing (EMNLP) , 2014, pp.\n1532–1543.\n[36] Z. S. Harris, “Distributional structure,” Word , vol. 10, no. 2-3, pp. 146–\n162, 1954.\n[37] P. Bojanowski, E. Grave, A. Joulin, and T. Mikolov, “Enriching word\nvectors with subword information,” arXiv preprint arXiv:1607.04606 ,\n2016.\n[38] M. E. Peters, M. Neumann, M. Iyyer, M. Gardner, C. Clark, K. Lee,\nand L. Zettlemoyer, “Deep contextualized word representations,” arXiv\npreprint arXiv:1802.05365 , 2018.\n[39] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “Bert: Pre-training\nof deep bidirectional transformers for language understanding,” arXiv\npreprint arXiv:1810.04805 , 2018.\n[40] X. Dai, M. Bikdash, and B. Meyer, “From social media to public\nhealth surveillance: Word embedding based clustering method for twitter\nclassiﬁcation,” in SoutheastCon, 2017 . IEEE, 2017, pp. 1–7.\n[41] V . K. R. Sridhar, “Unsupervised topic modeling for short texts using\ndistributed representations of words,” in Proceedings of the 1st workshop\non vector space modeling for natural language processing , 2015, pp.\n192–200.\n[42] D. Q. Nguyen, R. Billingsley, L. Du, and M. Johnson, “Improving\ntopic models with latent feature word representations,” arXiv preprint\narXiv:1810.06306 , 2018.\n[43] T. Cali ´nski and J. Harabasz, “A dendrite method for cluster analysis,”\nCommunications in Statistics-theory and Methods , vol. 3, no. 1, pp. 1–\n27, 1974.\n[44] D. L. Davies and D. W. Bouldin, “A cluster separation measure,” IEEE\ntransactions on pattern analysis and machine intelligence , no. 2, pp.\n224–227, 1979.\n[45] O. Arbelaitz, I. Gurrutxaga, J. Muguerza, J. M. P ´erez, and I. Perona,\n“An extensive comparative study of cluster validity indices,” Pattern\nRecognition , vol. 46, no. 1, pp. 243–256, 2013.\n[46] D. Dheeru and E. Karra Taniskidou, “UCI machine learning repository,”\n2017. [Online]. Available: http://archive.ics.uci.edu/ml\n[47] A. Karami, A. Gangopadhyay, B. Zhou, and H. Kharrazi, “Fuzzy\napproach topic discovery in health and medical corpora,” International\nJournal of Fuzzy Systems , vol. 20, no. 4, pp. 1334–1345, 2018.\n[48] M. Hoffman, F. R. Bach, and D. M. Blei, “Online learning for latent\ndirichlet allocation,” in advances in neural information processing\nsystems , 2010, pp. 856–864.\n[49] P. Vincent, H. Larochelle, I. Lajoie, Y . Bengio, and P.-A. Manzagol,\n“Stacked denoising autoencoders: Learning useful representations in a\ndeep network with a local denoising criterion,” Journal of machine\nlearning research , vol. 11, no. Dec, pp. 3371–3408, 2010.\n[50] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,”\narXiv preprint arXiv:1412.6980 , 2014.\n[51] P. Huang, Y . Huang, W. Wang, and L. Wang, “Deep embedding network\nfor clustering,” in Pattern Recognition (ICPR), 2014 22nd International\nConference on . IEEE, 2014, pp. 1532–1537.[52] C. Aytekin, X. Ni, F. Cricri, and E. Aksu, “Clustering and unsupervised\nanomaly detection with l2 normalized deep auto-encoder representa-\ntions,” arXiv preprint arXiv:1802.00187 , 2018.\n[53] L. v. d. Maaten and G. Hinton, “Visualizing data using t-sne,” Journal\nof machine learning research , vol. 9, no. Nov, pp. 2579–2605, 2008.\n[54] L. McInnes, J. Healy, N. Saul, and L. Großberger, “Umap: uniform\nmanifold approximation and projection,” The Journal of Open Source\nSoftware , vol. 3, no. 29, p. 861, 2018.\n[55] F. Pedregosa, G. Varoquaux, A. Gramfort, V . Michel, B. Thirion,\nO. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V . Dubourg et al. ,\n“Scikit-learn: Machine learning in python,” Journal of machine learning\nresearch , vol. 12, no. Oct, pp. 2825–2830, 2011.\n[56] M. Abadi, P. Barham, J. Chen, Z. Chen, A. Davis, J. Dean, M. Devin,\nS. Ghemawat, G. Irving, M. Isard et al. , “Tensorﬂow: a system for large-\nscale machine learning.” in OSDI , vol. 16, 2016, pp. 265–283.\n[57] J. H. Friedman, “On bias, variance, 0/1loss, and the curse-of-\ndimensionality,” Data mining and knowledge discovery , vol. 1, no. 1,\npp. 55–77, 1997.\n[58] Y . Liu, Z. Li, H. Xiong, X. Gao, and J. Wu, “Understanding of internal\nclustering validation measures,” in Data Mining (ICDM), 2010 IEEE\n10th International Conference on . IEEE, 2010, pp. 911–916.\n[59] J. Li, M.-T. Luong, and D. Jurafsky, “A hierarchical neural autoencoder\nfor paragraphs and documents,” arXiv preprint arXiv:1506.01057 , 2015.\n[60] B. Dhingra, Z. Zhou, D. Fitzpatrick, M. Muehl, and W. W. Cohen,\n“Tweet2vec: Character-based distributed representations for social me-\ndia,” arXiv preprint arXiv:1605.03481 , 2016.\n[61] B. Wang, M. Liakata, A. Zubiaga, and R. Procter, “A hierarchical topic\nmodelling approach for tweet clustering,” in International Conference\non Social Informatics . Springer, 2017, pp. 378–390.\n[62] S. Vakulenko, L. Nixon, and M. Lupu, “Character-based neural embed-\ndings for tweet clustering,” arXiv preprint arXiv:1703.05123 , 2017."}
{"date": "2024-01-04-22-29", "error": false, "url": "PDF", "text_blocks": " 1 \n \n \nAbstract—A fuzzy opinion is a Gaussian fuzzy set with the \ncenter representing the opinion and the standard deviation \nrepresenting the uncertainty about the opinion, and a fuzzy \nopinion network is a connection of a number of fuzzy opinions in a \nstructured  way. In this paper, we propose : (a) a top -down \nhierarchical fuzzy opinion network to model how the opinion of a \ntop leader is penetrated into the members in social organizations, \nand (b) a bottom -up fuzzy opinion network to model how the \nopinions of a large number of agents are agglomer ated \nlayer -by-layer into a consensus or a few opinions in the social \nprocesses such as an election. For the top -down hierarchical fuzzy \nopinion network, we prove that  the opinions of all the agents \nconverge to the leader ’s opinion, but the uncertainties of  the \nagents in different groups are generally converging to different \nvalues. We demonstrate that the speed of convergence is greatly \nimproved by organizing the agents in a hierarchical structure of \nsmall groups. For the bottom -up hierarchical fuzzy opinio n \nnetwork, we simulate how a wide spectrum of opinions are \nnegotiating and summarizing  with each other  in a layer -by-layer \nfashion in some typical situations . \n \nIndex Terms —Opinion  dynamics;  social hierarchy ; fuzzy \nopinion networks . \nI. INTRODUCTION  \nHierarchy is the most popular structure in social organizations \nsuch as government, ar my, company, etc.  [1,2,3 ]. In a company, \nfor example, it is typically structured with a relatively small top \nmanagement team, at least one layer of middle management, \nand a large n umber of lower le vel employees responsible  for \nday-to-day operations  [4]. Why is hierarchy so pervasive  in \nhuman societies  across almost all cultures  throughout time  [5], \ngiving the fact that hierarchy is in direct opposition to some of \nthe best ideas humanity has produced such as democracy, \nequality, fairness, and justice [ 1] ? The interdisciplinary \nresearch on social hierarchy  in sociology  [6,7], psychology  \n[8,9], management  [10], economics [ 11], and other  disciplines \nsuggest a number  of reasons . First, hierarchy establishes social \norder that is appealing psychologically  to individual s who  need  \n \nLi-Xin Wang  is with  the University of Chinese Academy of Sciences, \nBeijing, P.R. China (e -mail: lxwang@ucas.edu.cn ). safety and  stability  (people come and go, but the system \nremains) . Second, hierarchy provides incentives for individuals \nin organizations  to work hard  to obtain higher rank to satisfy \nmaterial self -interest an d their need for control  that in turn \nserves the organization’s interests  (motivating the individuals \nto work hard for the organizat ion). Third, hierarchy facilitates \ncoordination and improves efficiency in comparison to other \nmore egalitaria n structures such as free markets  (the rapid \ndevelopment of China’s “state capitalism” economy in recent \nyears is an example , which has l ed to the  deglobalization \nmovement  in the “laisser -faire capitalism ” economies to \nreestablish the hierarchy ). Fourth, hierarchical differentiation \nbetween people fosters more sat isfying working relationships  \n(leaders provide the guidance their followers need, and \nfollowers execute what the leaders want to be realized) . \n   Although  hierar chy has been studied in social sciences for a \nlong time (back to Marx  and Engels  [12] in 1846), the research \nis largely qual itative without mathematical modeling. Usually, \nsome concepts or variables are defined  verbally, then a t heory is \ndeveloped that describe s the relationships among these \nvariables using natural languages rather than mathematical \nequations  [13]. The most mathematically advanced study \nrelated to social hierarch y is perhaps  the multidisciplinary field  \nof opinion dynamics  where the researchers from mathematical \nsociology  [14], economics [ 15,16 ], physics [17,18 ], social \npsychology  [19], control [ 20], signal processing [ 21], fuzzy \nsystems [ 22], etc.,  join forces to tackle the problem. A \nshortcoming of the mainstream opinion dynamics models \n[23,24] is that the uncertainties  of the opinions are not included \nin the models. Human opinions are inherently uncertain  so that \nan opinion and its uncertainty should  be consider ed \nsimultaneously  to give the accurate picture of the opinion. For \nexample, when we are asked to review a research paper,  we \nneed to give an overall rat ing for the paper and, at the same time, \nwe must claim our level of expertise  on the subject  which is a \nmeasure of un certainty about the overall rat ing. In fact, the \nuncertainty may be more important than the opinion itself in \nmany situations, because the uncertainty is more directly \nrelated to the psychological pressure of the agent when the \nopinion is broa dcasted  [25]. Hierarchical Fuzzy Opinion Networks: \nTop-Down for Social Organizations and \nBottom -Up for Election  \nLi-Xin Wang   2 \nThe fuzzy opinion networks (FONs) proposed in [ 22] model \nan opinion by a Gaussian fuzzy set whose center  and standard \ndeviation  represent the opinion and  its uncertainty , respectively, \nso that the interactions between the opinions and their \nuncertainties are systematically exploited.  The goal of this \npaper is to use the FON framework  to model social hierarchy . \nAccording to [ 2], social hierarchies can be classified into two \ntypes: i) formal hierarchies that are delineated  by rule  and \nconsensually agreed upon , and ii) informal hierarchies that are \nestablished and subjectively understood  during the interaction \namong social members . Formal hierarchies are top -down – a \nhierarchical structure is designed first and members at different \nlevel s are then recruited; informal hierarchies are bottom -up – a \nhierarchical structure emerges after the free interaction among  \nthe community members. We will use fuzzy opinion networks \nto model both formal and informal hierarchies . To model the \nformal hierar chy, we first define a basic leader -follow group of \nfuzzy agents and study its basic convergence properties, then \nwe connect the basic leader -follower groups in a hierarchical \nfashion to get the final hierarchical fuzzy opinion network.  To \nmodel a n informa l hierarchy,  we let a large number of fuzzy \nagents to interact with each other based on a local reference \nscheme , and we see the initially very diversified opinions are \nmerging gradually in a hierarchical fashion into a consensus or \na number of representat ive opinions – a process very similar to \nan election in a democratic society.   \nThis paper is organized as follows. In Section II,  the \ntop-down hierarchical fuzzy opinion networks are constructed \nand their convergence properties are proved. We also show tha t \nthe speed of convergence to the top leader ’s opinion is greatly \nimproved by organizing the followers into a hierarchical \nstructure rather than in a flat  nonhierarchical fashion. In Section \nIII, we construct the bottom -up hierarchical fuzzy opinion \nnetwor ks through the natural process of free  interacting  among \na large number of fuzzy agents based on the local reference \nscheme, and we simulate a number of typical scenarios – \nconsensus  reaching , polarization , or converging to multiple \nends.  Finally, Section IV concludes the paper  and the App endix \ncontains the proofs of  the theorems in th e paper . \nII. TOP-DOWN HIERARCHICAL FUZZY OPINION NETWORKS  \nWe start with the definition of fuzzy opinion networks  (FON) \nand bounded confidence FONs1, and then introduce the basic \nleader -follower group which  is the basic building  block of the \ntop-down hierarchical fuzzy opinion networks .  \nDefinition 1:  A fuzzy opinion  is a Gaussian fuzzy set   with \nmembership function               \n   where the center     \nrepresents the opinion and the standard deviation      \ncharacterizes the uncertainty about the opinion  . A Fuzzy \n \n1 The concept of  FON was introduced in [ 22] and the basic convergence \nproperties of bounded co nfidence FONs were studied in  [26]. Opinion Network  (FON) is a connection of a number of \nGaussian nodes, where  a Gaussian node is a 2 -input -1-output \nfuzzy opinion    with Gaussian membership function \n                \n   whose center    and standard deviation    \nare two input fuzzy sets to the node and the fuzzy set    itself is \nthe output of the node. A Gaussian node is also called an agent , \na node , or a fuzzy node  throughout this paper.   \nThe connection of the fuzzy nodes can be static or \ndynamically changing with time and the status  of the nodes. \nThe bounded confidence fuzzy opinion networks , defined \nbelow , are FONs with connections that are dynamically \nchanging according to  the states of the nodes – if the fuzzy \nopinions of two nodes are close enough to each other, they are \nconnected; otherwise, they are disconnected.    \nDefinition 2:  A bounded confidence fuzzy opinion network  \n(BCFON)  is a dynamic connection of n fuzzy nodes       \n(         ) with membership functions           \n            \n      , where the center input         and the standard \ndeviation input         to node   at time     (         ) \nare determined as follows: the center input         is a \nweighted average of the outputs       of the n fuzzy nodes at \nthe previous time point  : \n                     \n                                 \nwith the weights  \n         \n               \n                                      \nwhere       (       ) is the collection of nodes that are \nconnected to node   at time t, defined as:  \n                                                \nwhere                  represents the closeness between \nfuzzy opinions       and      ,          are constants and \n        denotes the number of elements in      ; and, the \nstandard deviation input         are determin ed according to \none of the two schemes:  \n(a) Local reference  scheme : \n                  \n                \n                    \n(b) External reference  scheme : \n                                                \nwhere        denotes the center of fuzzy set      ,       is an \nexternal signal  and   is a positive scaling constant. The initial \nfuzzy opinions       (         ) are Gaussian fuzzy sets   3 \n                     \n    , where the initial opinions        and \nthe initial uncertainties        are given.    \nIt was proved in [ 26] that the opinions         and their \nuncertain ties       of the Gaussian nodes       in the BCFON \nare evolving according to the following dynamic equations.  \nThe Evolution of BCFON : The fuzzy opinions       \n(       ;           ) in the BCFON  are Gaussian fuzzy \nsets: \n                       \n                                                \nwhere the opinions          and their uncertainties       \n   are evolving according to the following dynamic equations:  \n                       \n                                          \n                     \n                            \nwhere the weights  \n         \n               \n                                           \n      \n     \n                              \n              \n   \n     \n              \nand the uncertainty input  \n                     \n                                      \nfor local reference  scheme , or \n                                                   \nfor external reference  scheme  with initial condition        \n    (initial opinion of agent  ) and           (uncertainty \nabout the initial opinion), where       ,     are \nconstants.     We now define the basic leader -follower group which is the \nbasic building  block of the top-down hierarchical fuzzy opinion \nnetworks  of this paper.  \nDefinition 3:  A basic leader -follower group  (BLFG), \nillustrated in Fig. 1, consists of a leader node        with \nmembership function                         \n         and n follower \nnodes        (         ) with membership functions  \n                       \n        , where the leader node passes his \nopinion        to each of the n follower nodes and the n \nfollower nodes are connected among themselves  in the \nbounded confidence  fashion. Specifically, the leader ’s opinion \n       and its uncertainty       are not influenced by the n \nfollowers, and the opinions         and their uncertainties       \nof the  n followers are evolving according to the following \ndynamic equations:  \n          \n                   \n                         \n         \n               \n                                 \nwhere       is given in (10)  with       , and the \nuncertainty input          is chosen either with the local \nreference scheme  (11), or with the leader reference scheme : \n                                                     \n  \nWe see from (13)  that the opinion     of follower i is updated \nas the average of the neighbor ’s opinions                  plus \nthe leader ’s opinion       . For the uncertainty    of follower i, \nwe see from (14) that it  is updated as the average of the \nneighbor’s uncertainties  \n                       plus the \nuncertainty input         which takes either the local \nreference scheme (11) or the leader reference scheme (15). In \nthe local reference scheme, agent i views  the average of his \nneighbor’s opinions as the reference, so the closer his opinion is   \nFig. 1:The basic leader -follower group, where  the leader  passes his opinion        to each of the n follower s who  are connected among \nthemselves in the bounded confidence fashion . \n2\n2()\n()en\nnx x t\nt\n2\n3\n2\n3()\n()ex x t\nt\n2\n2\n2\n2()\n()ex x t\nt\n2\n1\n2\n1()\n()ex x t\nt\n2\n2()\n()ea\nax x t\ntFollowersLeader\n()axt\n()axt\n()axt\n()axt 4 \n \nFig. 2: A simulation  run of the basic leader -follower group with local \nreference scheme, where the top and bottom sub-figure s plot the \nopinions        and the uncertainties       of the n=156 followers , \nrespectively; the leader ’s opinion          .  \n \nto this average, the less uncertainty he has. In the leader \nreference scheme, however, agent i views the leader ’s opinion \nas the reference, so the closer his opinion        is to the leader ’s \nopinion       , the less uncertainty he has.  \nTo get a feel of the dynamics of  the opinions and their \nuncertainties of the agents in  the basic leader -follower group, \nlet’s see an example.  \nExample 1 : Consider the  basic leader -follower group of Fig. \n1 with       follower s. With        ,       , the \nleader’s opinion            and the initial     (       ) \nuniformly distributed over t he interval [5,25] (       \n      \n            ) and their uncertainties       for all  \n       , Fig. 2 and Fig. 3  show the simulation run s of the \ndynamic model  with local reference scheme (11) and leader \nreference scheme (15), respectively , where  the top sub -figures \nof Figs. 2 and  3 plot the opinions        of the       \nfollower s and the bottom sub -figures plot the uncertainties  \n     .   \nWe see from Figs. 2 and 3 that for both the local and leader \nreference schemes, the opinions        of all the follower s \nconverge to the leader ’s opinion          , but the speed of \nconvergence is slow.  In the following theorem, we prove that \nconvergence to the leader ’s opinion is indeed guaranteed, but \nthe speed of convergence is greatly influenced by the number of \nfollowe rs in the group.  \nTheorem 1:  Consider the basic leader -follower dynamics of \n(13), (14) and (10) with local reference scheme (11) or leader \nreference scheme (15), and suppose the leader ’s opinion \n           is a constant.  Starting from arbitrary initial  \nopinions               and uncertainties               , \nwe have:   \nFig. 3: A simulation run of the basic leader -follower group with leader  \nreference scheme, where the top and bottom sub-figure s plot the \nopinions        and the uncertainties       of the n=156 followers , \nrespectively ; the leader ’s opinion          . \n \n(a) the   follower s converge to a consensus  in finite time , i.e.,  \nthere exists     such that              and             for all \n         and all     ; \n(b) the opinion consensus       converges to the leader ’s \nopinion     according to  \n            \n          \n                             \nwhere        ; \n(c) for local reference scheme (11), the uncertainty \nconsensus              (a constant ) for all     ; \n(d) for leader reference scheme (15), the uncertainty \nconsensus      is changing according to  \n                   \n                    \n          \n     \n           \nfor       , from which we get                    \n                     .      \n   The proof of Theorem 1 is given in the Appendix.  \n   From (16) in Theorem 1 we see that the opinion consensus \n      converges to the leader ’s opinion     with the factor  \n   , \ni.e., the error           is reduced by  \n    each time step, so in \nk time steps the error            is reduced by   \n     \n   \nwhich gives  \n      \n                                            \nWith        (reduce to error to 1%), Fig. 4 plots the k as \nfunction of n, from which we see that the steps needed to reduce \nthe error increases about linearly with the number of followers  \n \n0 20 40 60 80 100 120 140 160510152025O pi ni ons of  t he n=156 f ol l ow er s w i t h l ocal  r ef er ence schem e;  t he l eader  opi ni on xa=10\ntopi ni ons\n0 20 40 60 80 100 120 140 1600. 99511. 0051. 011. 0151. 021. 0251. 031. 035U ncer t ai nt i es of  t he n=156 f ol l ow er s w i t h l ocal  r ef er ence schem e\ntuncer t ai nt i es\n0 20 40 60 80 100 120 140 160510152025O pi ni ons of  t he n=156 f ol l ow er s w i t h l eader  r ef er ence schem e;  t he l eader  opi ni on xa=10\ntopi ni ons\n0 20 40 60 80 100 120 140 16011. 522. 533. 544. 5U ncer t ai nt i es of  t he n=156 f ol l ow er s w i t h l eader  r ef er ence schem e\ntuncer t ai nt i es 5 \n \nFig. 4: Plot of (18), the  steps k needed to reduce the error            to \n1% as function of number of followers n in group.  \nin the group, meaning that larger groups are more difficult to \nconverge to the leader ’s opinion than smaller groups.  \nThe conclusion from (18) and Fig. 4 is that to speed up the \nconvergence of the followers ’ opinions to the leader ’s opinion, \nreducing the size of the group is crucial. Organi zing the \nfollowers hierarchically in smaller groups, as we will do next \nthrough the top -down hierarchical fuzzy opinion networks, is \nan efficient way to speed up the convergence.  \nWe now introduce the  top-down  hierarchical fuzzy opinion \nnetworks.  \nDefinition  4: A top-down  hierarchical fuzzy opinion \nnetwork  (TD-HFON) , illustrated in Fig. 5,  is constructed from a \nnumber of basic leader -follower groups  of Fig. 1 in a \nmulti -layer structure , where an  agent      in Level l is a follower \nto an agent in Level l+1 and  is a leader to some agents in Level \nl-1. In the notation     , l is the level index (          ), i is \nthe group index (           ), j is the index in the group \n(           ), and      is a Gaussian fuzzy set with center \n         and standard deviation        .     \n   To see how fast the hierarchical structure can speed up the \nconvergence to the leader ’s opinion, we reorganize the n=156 \nfollowers in Example 1 into a 3 -level and a 4 -level TD -HFON s \nin the following example.  \nExample 2:  Consider the 3 -level and 4 -level TD -HFONs in \nFig. 6. In the 3 -level TD -HFON (left in Fig. 6), Level -1 consists \nof 12 groups with 12 agents in each group, Level -2 consists of a \nsingle group of 12 agents with each agent being the leader of \none the 12 groups in Level -1, and Level -3 is the top leader who \nis the leader of the 12 -agent group in Level -2. With        , \n      , the top leader ’s opinion           and the initial \nopinions of the 12 agents in a group          (           \n                          ) uniformly distributed over \nthe interval [5,25] (                  \n              ) and   \n \n \n all their uncertainties          , Figs. 7 and 8  show the \nsimulation run s of the dynamic model  with local reference \nscheme (11) and leader reference scheme (15), respectively , \nwhere  the top sub -figures of Figs. 7 and 8 plot the opinions \n         of the       agent s in Levels 1 and 2 and the bottom \nsub-figures plot the corresponding uncertainti es        . \nSimilarly, in the 4 -level TD -HFON (right in Fig. 6), Level -1 \nconsists of 25 groups with 5 agents in each group, Level -2 \nconsists of 5 groups with 5 agents in each group and these 25 \nagents are the leaders of the 25 groups in Level -1, Level -3 \nconsists of a single group of 5 agents who are the leaders of the \n5 groups in Level -2, and Level -4 is the top leader who is the \nleader of the 5 -agent group in Level -3. With        , \n      , the top leader ’s opinion           and the initial \nopinions of the 5 agents in a group          (             \n                                              ) \nuniformly distributed over t he interval [5,25] (            \n      \n            ) and all their uncertainties          , \nFigs. 9 and 10  show the simulation run s of the dynamic model  \nwith local reference scheme (11) and leader reference scheme \n(15), respectively , where  the top sub -figures of Figs. 9 and 10 \nplot the opinions          of the       agent s in Levels 1, 2 \nand 3 and the bottom sub -figures plot the corresponding \nuncertainties         .    \nComparing Fig. 2 and 3 with Figs. 7 -10, we have the \nfollowing observations:  \n(a) The opinions          of all the agents converge to the \nleader’s opinion no matter the agents are organized \nhierarchically in small groups or in one large group.   \n(b) The speed of convergence to the leader ’s opinion is \ngreatly improved when the agents are organized hierarchically \nin small groups; the more the levels or the smaller the groups, \nthe faster the convergence will be (comparing the top \nsub-figures of Figs. 2, 7 and 9 for the local reference scheme, \nand the top sub -figures of Figs. 3, 8 and 10 for the leader \nreference scheme).  \n(c) Although the opinions          of all the agents converge to \nthe leader ’s opinion, their uncertainties         in general \nconverge to different values for agents in different groups, \nreflecting the different processes that the agents in different \ngroups were experiencing dur ing the convergence to the \nleader’s opinion.  \nIndeed, we will prove in the following theorem that the \nobservations above are true in general.  \n \n \n \n \n \n \n0 20 40 60 80 100 120 140 160 180 20001002003004005006007008009001000St eps needed t o r educe er r or  t o 1%  as f unct i on of  f ol l ow er  num ber\nnum ber  of  f ol l ow er s n i n a gr oupst eps needed t o r educe t he er r or  t o 1% 6 \n \n \n   \nFig. 5:The top -down hierarchical fuzzy opinion networks.  \n \nFig. 6: Reorganizing the agents in Example 1 into a 3 -level TD -HFON with 12 followers in each group (left) and a 4 -level TD -HFON with \n5 followers in each group (right).  \n11XlLevel 1Level L (Top Leader)\nLevel 3\nLevel 2\n3Xll\nn\n2Xll\nn\n1Xll\nn\n22Xl\n21Xl\n13Xl\n12XlLevel l\nLevel l+1Level L-1\n2\n2()\n()ea\nax x t\nt\n()axt\n()axt\n()axt\n()axt\n11()lxt\n3()ll\nnxt\n2()ll\nnxt\n1()ll\nnxt\n22()lxt\n21()lxt\n13()lxt\n12()lxt\n1\n1XL\n11XLL\nn\n1\n3XL\n1\n2XL\n1\n1()Lxt\n11()LL\nnxt\n1\n2()Lxt\n1\n3()Lxt\n1\n11Xl\n1\n12Xl\n1\n11()lxt\n1\n12()lxt\n1\n11()lxt\n1\n12()lxt\nLevel 1Level 3\nLevel 2\n12 agents 12 agents 12 agents12 agents\n5 agents\n5 agents\n5 agents 5 agents\n5 agents\n5 agents25 agents in \n5 groups5 agentsLevel 4156 agents in a 3-level TD-HFON with \n12 followers each group155 agents in a 4-level TD-HFON with \n5 followers each group 7 \nFig. 7: The opinions (top) and their uncertainties (bottom) of the \nn=156 agents in the 3 -level TD -HFON of Fig. 6 with local reference \nscheme.  \n \nFig. 8 : The opinions (top) and their uncertainties (bottom) of the \nn=156 agents in the 3 -level TD -HFON of Fig. 6 with leader reference \nscheme.  \nTheorem 2 : Consider the general TD -HFON in Fig. 5 with \ndynami cs of all the groups following (13), (14) and (10) with \nlocal reference scheme (11) or leader reference scheme (15), \nand suppose the top leader ’s opinion            is a constant. \nStarting from arbitrary initial  opinions             and \nuncertainties             , we have:  \n(a) the opinions          of all the agents (            \n                           ) converge to  the leader ’s \nopinion    ; \n(b) the uncertainties         of the followers  in the same  \nleader -follower  group converge to a constant, but different \ngroups in general converge to different values.     \nThe proof of Theorem 2 is given in the Appendix.  \nWe now move to the next section to study the bottom -up \nhierarchical fuzzy opinion networks.   Fig. 9 : The opinions (top) and their unc ertainties (bottom) of the \nn=155  agents in the 4 -level TD -HFON of Fig. 6 with local reference \nscheme.  \nFig. 10 : The opinions (top) and their unc ertainties (bottom) of the \nn=155  agents in the 4 -level TD -HFON of Fig. 6 with leader  reference \nscheme.  \nIII. BOTTOM -UP HIERARCHICAL FUZZY OPINION NETWORKS  \nAs we discussed in the Introduction that although social \nhierarchy is prevalent  throughout culture and time, hierarchy is \nagainst some of the best values of humanity – hierarchy is \nundemocrat ic, unequal, unfair, and unjust. So, if we have to \nchoose hierarchy to govern a large population such as a nation, \nwe should have some counter measures to prevent those in the \nhigher levels to abuse their power. Election by the general \npublic is the way of  choice of most countries in the world to \nselect their top leaders. In the election scen ario, the opinions of \nthe large population are initially very diversified  and many \nsmall leaders are emerging to represent different interest groups, \nthen these small l eaders have to compromise  with each other to \nselect the middle -level  leaders , this process continues \nlevel -by-level in a bottom -up fashion until some consensuses \nare reached.  We now propose the bottom -up hierarchical fuzzy \nopinion networks to model such processes.    \n \n0 10 20 30 40 50 60 70 80 90 100510152025O pi ni ons of  t he n=156 agent s i n 3- l evel  TD - H FO N  w i t h l ocal  r ef er ence schem e;  t he l eader  opi ni on xa=10\ntopi ni ons\n0 10 20 30 40 50 60 70 80 90 10011. 0051. 011. 0151. 021. 025U ncer t ai nt i es of  t he n=156 agent s i n 3- l evel  TD - H FO N  w i t h l ocal  r ef er ence schem e\ntuncer t ai nt i es\n0 10 20 30 40 50 60 70 80 90 100510152025O pi ni ons of  t he n=156 agent s i n 3- l evel  TD - H FO N  w i t h l eader  r ef er ence schem e;  t he l eader  opi ni on xa=10\ntopi ni ons\n0 10 20 30 40 50 60 70 80 90 10011. 11. 21. 31. 41. 51. 61. 71. 8U ncer t ai nt i es of  t he n=156 agent s i n 3- l evel  TD - H FO N  w i t h l eader  r ef er ence schem e\ntuncer t ai nt i es\n0 10 20 30 40 50 60 70 80 90 100510152025O pi ni ons of  t he n=155 agent s i n 4- l evel  TD - H FO N  w i t h l ocal  r ef er ence schem e;  t he l eader  opi ni on xa=10\ntopi ni ons\n0 10 20 30 40 50 60 70 80 90 10011. 051. 11. 15U ncer t ai nt i es of  t he n=155 agent s i n 4- l evel  TD - H FO N  w i t h l ocal  r ef er ence schem e\ntuncer t ai nt i es\n0 10 20 30 40 50 60 70 80 90 100510152025O pi ni ons of  t he n=155 agent s i n 4- l evel  TD - H FO N  w i t h l eader  r ef er ence schem e;  t he l eader  opi ni on xa=10\ntopi ni ons\n0 10 20 30 40 50 60 70 80 90 10011. 11. 21. 31. 41. 5U ncer t ai nt i es of  t he n=155 agent s i n 4- l evel  TD - H FO N  w i t h l eader  r ef er ence schem e\ntuncer t ai nt i es 8 \nDefinition 5:  A bottom -up hierarchical fuzzy opinion \nnetwork  (BU-HFON),  illust rated in Fig. 11, is the layered \nconnection of a number of bounded confidence fuzzy opinion \nnetworks  (BCFON)  with local reference scheme (Definition 2), \nwhere the converged opinions of a lower level BCFON are  \npassed to  the upper level BCFON  as the initial opinions .       \nWe now simulate the BU -HFON to see how the initial fuzzy \nopinions are agglomerated layer -by-layer in some typical \nsituations . \nExample 3:  Consider a 5-level  BU-HFON of Fig. 11  (L=5) \nwith       agents in Level 1 whose initial opinions         \nand initial u ncertainties        (i=1,2, …, n) are randomly \ndistributed over the interval s [5,25] and  (0,1), respectively.  The \nfive BCFONs in the five levels are evolving according to the \ndynamic equations (7) -(11), where          for Level 1 \nBCFON,        for Lev el 2 BCFON,         for Level 3 \nBCFON,        for Level 4 BCFON and         for  \nLevel 5 BCFON.  The meaning of these   ’s are explained as \nfollows.  \nFor the Level 1 agents (the general public), we choose a large \n   (=0.95) because the general public has no obligation to reach \nsome consensuses so that they can show little sign of \ncompromise (a large    means talking  only to those whose opinions are very close to each other). For the Level 2 agents \n(the local repres entatives of the general public), they have to \nshow some sign of compromise in order for the process to \ncontinue, so we choose a little smaller    (=0.7) to model the \nsituation. Then,  the Level 3 agents  must be even more \ncompromising in order to reach so me rough consensuses, so we \nchoose a even smaller    (=0.45) for these middle level agents. \nThis process continues with smaller and smaller   ’s for the \nupper level agents  (       for Level 4 and         for  \nLevel 5)  because  the higher the level  they are in, the more \npressure  they have  to reach the final  consensus (this is why \nmany elected agents fall to realize their election promises when \nthey are in the office, because  they have to consider many \ndifferent concerns when they are in the higher lev els). \n With b=0.5 for all the BCFONs  and each BCFON evolving \n40 time steps , i.e., the Level 1 BCFON is operating from t=0 to \nt=40, then followed by the Level 2 BCFON which is operating \nfrom t=41 to t=80 with the converged fuzzy opinions of the \nLevel 1 BCFON as the initial values, this process continues  \nwith the Level 3 BCFON operating from t=81 to t=120, the \nLevel 4 BCFON operating from t=121 to t=160 and the Level 5 \nBCFON operating from t=160,  Fig. 12  show s a simulation  run \nin a typical situation, wher e the top and bottom sub -figures in   \nFig. 11:The bottom -up hierarchical fuzzy opinion networks.  \nLevel 1Level 2\n1\n1X0（）\n1X0n（）\n1\n-1X0n（）\n1\n-2X0n（）\n1\n5X0（）\n1\n4X0（）\n1\n3X0（）\n1\n2X0（）\nBCFON1\n2\n1X0（）\n2\n4X0（）\n2\n3X0（）\n2\n2X0（）\n22X0n（）\n22\n-1X0n（）\n3\n1X0（）\n3\n3X0（）\n3\n2X0（）\n33X0n（）\n33\n-1X0n（）\nInitial fuzzy opinionsConverged fuzzy opinions \nfrom Level 1Converged fuzzy opinions \nfrom Level 2\nBCFON2\nLevel L\nL\n1X0（）\n2X0L（）\nX0LL\nn（）\n1X\nmX\nConverged fuzzy opinions \nfrom Level L-1Final fuzzy opinions\nBCFONL 9 \n \nFig. 12:  The opinions (top) of the agents  in different levels  and their \nuncertainties (bottom).  \n \nFig. 13: The opinions  (top) of the agents  in different levels  and their \nuncertainties (bottom).  \n \nFig. 12 show the opinions (        of (7)) of the agents and their \nuncertainties (       of (8)), respectively. We see from top \nsub-figure of Fig. 12 that the Level 1 general public (      ) \nconverge to a large number of opinions due to the large    \n(=0.95), then with  a smaller    (=0.7) the Level 2 agents \nconverge to about 17 opinions , which are further combined by \nthe Level 3 agents (with        ) into 11 opinions, and \ncontinuing with         the Level 4 agents reach 5 opinions, \nfinally, the top level agents ha ve to ado pt a very small  \n        to reach a single consensus. The bottom sub -figure \nof Fig. 12 shows that the uncertainties are getting larger  and \nlarger for the higher  level agents, reflecting the fact that the \nhigher level agents must demonstrate more  compromises which  \nresult in more uncertainties about their decisions.   \nFig. 14: The opinions (top) of the agents in different levels and their \nuncer tainties (bottom).  \n \nFig. 15: The opinions (top) of the agents in different levels and their \nuncertainties  (bottom).  \n \nFigs. 13 -15 show the simulation runs in other typical \nsituations, where  a cons ensus is reached in Fig.  13, but in the \nsituations of Figs. 14 and 15, a consensus cannot be reached \nafter five rounds of negotiations.  Comparing the bottom \nsub-figures of Figs. 12 -15 we see that the uncertainties of the \nLevel 5 agents are high if they converge to a single consensus \n(Figs. 12 and 13) , but if they converge to two consensuses  (Fig. \n14), their uncertainties are much lower, and if they are allowed \nto keep  three different opinions (Fig. 15), their uncertainties are \neven lower. This demonstrates that the uncertainty       in our \nHFON model provides a good measure for the psychological \npressures of the agents in different levels.     \n \n \n \n \n \n0 20 40 60 80 100 120 140 160 180 200510152025O pi ni ons of  t he agent s i n di f f er ent  l evel s of  t he BU - H FO N\ntopi ni ons\n0 20 40 60 80 100 120 140 160 180 2000123456U ncer t ai nt i es of  t he agent s i n di f f er ent  l evel s of  t he BU - H FO N\ntuncer t ai nt i esLevel  1 Level  2 Level  3 Level  4 Level  5\nd=0. 95 d=0. 7 d=0. 45 d=0. 2 d=0. 05\n0 20 40 60 80 100 120 140 160 180 200510152025O pi ni ons of  t he agent s i n di f f er ent  l evel s of  t he BU - H FO N\ntopi ni ons\n0 20 40 60 80 100 120 140 160 180 2000123456U ncer t ai nt i es of  t he agent s i n di f f er ent  l evel s of  t he BU - H FO N\ntuncer t ai nt i esLevel  1 Level  2 Level  3 Level  4 Level  5\nd=0. 95 d=0. 7 d=0. 45 d=0. 2 d=0. 05\n0 20 40 60 80 100 120 140 160 180 200510152025O pi ni ons of  t he agent s i n di f f er ent  l evel s of  t he BU - H FO N\ntopi ni ons\n0 20 40 60 80 100 120 140 160 180 2000123456U ncer t ai nt i es of  t he agent s i n di f f er ent  l evel s of  t he BU - H FO N\ntuncer t ai nt i esLevel  1 Level  2 Level  3 Level  4 Level  5\nd=0. 95 d=0. 7 d=0. 45 d=0. 2 d=0. 05\n0 20 40 60 80 100 120 140 160 180 200510152025O pi ni ons of  t he agent s i n di f f er ent  l evel s of  t he BU - H FO N\ntopi ni ons\n0 20 40 60 80 100 120 140 160 180 2000123456U ncer t ai nt i es of  t he agent s i n di f f er ent  l evel s of  t he BU - H FO N\ntuncer t ai nt i esLevel  1 Level  2 Level  3 Level  4 Level  5\nd=0. 95 d=0. 7 d=0. 45 d=0. 2 d=0. 05 10 \nIV. CONCLUDING REMARK S \nThe top -down and bottom -up hierarchical fuzzy opinion \nnetworks (HFON) developed in this paper provide a \nmathematical framework to model the dynamical propagation \nand formation of opinions and their uncertainties through the \nhierarchical structures. For th e top -down HFON, we prove that \nthe opinions of all followers throughout the hierarchy converge \nto the  top leader’s opinion, but the uncertainties of the followers \nin different groups are different, which means that although all \nthe followers have to follow  the top leader ’s opinion , their \npsychological acceptance (the uncertainty) for the top leader ’s \nopinion is different. We show that the iterations needed to \nreduce the tracking error between the followers and leader ’s \nopinions by a certain percentage is pr oportional to the number \nof followers in the group, this means that organizing the \nfollowers hierarchically can greatly improve the efficiency; for \nexample, if we organize 155 followers in a 4 -level top -down \nHFON with five followers in each leader -follower  group, then \nthe speed of convergence to the top leader ’s opinion is \napproximately    \n       times faster than organizing the 155 \nfollowers in a single flat group.  For the bottom -up HFON, we \nshow that the psychological pressure (the uncertainty) of the \nagents in the higher levels is greater than those in the lower \nlevels  because the higher level agents have to make more \ncompromises  (tougher decisions) , also we show that the \nuncertainties are lower if the higher level agents are allowed to \nkeep different opi nions.  \nIn the future research, we will apply the HFON models to \nsome real organizations and real election scenarios.  \nAPPENDIX  \n \nProof of Theorem 1: (a) Let                                \nand                          with \n         \n                          \n                       \nfor        ,          , \n                                                         \nfor           and  \n                                                         \nThen , with the leader ’s opinion            being a constant,  \nthe opinion dynamic equation (13) can be rewritten in the \nmatrix form:  \n                                                   \nWe need the follow Lemma from [ 27] to continue our proof.  \nLemma : If the row-stochastic matrix       in (A 4)  satisfies \nthe following three conditions:  \ni) the diagonal of      is positive, i.e.,          for \n         , ii) there is     such that the lowest positive entry of      \nis greater than  , and  \niii)  any two nonempty saturated sets  for      have a \nnonempty intersection , where             is \nsaturated for      if          and     implies    , \nthen a consensus is reached for                 in finite time.  \n   We now show that the      of (A1) -(A3) satisfies the three \nconditions in the Lemma. Since         according to  the \ndefinition of       in (10), we have         \n            for \n       ; with                 , condition i) in the \nLemma is satisfied. Since          , it follows that any \npositive         \n           \n     , hence condition ii) of \nthe Lemma  is satisfied . To check condition iii), notice from (A1) \nthat             \n            for        , which implies \nthat any two nonempty saturated sets                  for \n     must contain the element    , hence condition iii) of \nthe Lemma  is satisfied . Consequently , according to the Lemma, \nthe   follower s                 converge to a consensus  in \nfinite time , i.e.,  there exists     such that              for all \n         and all     . \n  To prove              for          and     , notice \nthat for      ,           for the local reference scheme \n(11), and                      for the leader reference \nscheme (15). Substituting these         into the dynamic \nequation (14) of      , we have for       that \n         \n        \n                                             \nfor the local reference scheme (11), and  \n         \n        \n                                       \nfor the leader reference scheme (15). Since the right hand sides \nof both (A5) and (A6) are independent of  , we have in both \ncases that            . This completes the proof of (a) of \nTheorem 1.  \n  (b) Since              for all          when      , we \nhave from (13) that  \n         \n          \n                                 \nor \n             \n                                       \nfor      , and (16) follows from (A8).  \n  (c) The conclusion follows from (A5).  \n  (d) Substituting             into (A6), we have  \n                                                     \nfor      , and (17) follows from (A 9) and (16).     \n   Proof of Theorem 2: (a) Consider an arbitrary \nleader -follower group in the HFON and let          be the group  11 \nleader’s opinion  and             (           ) be the  followers ’ \nopinions.  Since all the      followers are connected to each other \nthrough the group lead er (the group leader is a common \nelement in any saturated set ), we have from the Lemma that the \nfollowers converge to a consensus in finite steps, i.e., there \nexists     such that                      when       , so from \n(13) we have  \n               \n                \n                             \nor \n                   \n                                                \n  \n                            \nfor      . If         converges to    , then since    \n        we \nhave from (A11) that           converges to    , i.e., if the group \nleader’s opinion converges to the top leader ’s opinion    , then \nconsensus of the followers in the group also converges to    . \nSince the top leader and the agents in Level L -1 for m a basic \nleader -follower group, we have f rom Theorem 1 that  the \nopinions of the agents in Level L -1 converge to the top leader ’s \nopinion    . Hence, by induction, we have that the opinions of \nall the agents converge to the top leader ’s opinion    . \n(b) For the agents in the same group  (say group   in Level  ), \nwe can use the same met hod as in the proof of Theorem 1 to \nshow that their uncertainties         (           ) reach a \nconsensus        in finite time which converges to the consta nt \n          for the local reference scheme  or to the constant \n                                  for the leader \nreference scheme. Since these converged values are group \ndependent, they are in general different for different groups.    \nREFERENC ES \n \n[1] Diefenbach , T.,  Hierarchy and Organisation: Toward a General \nTheory of Hierarchical Social Systems ,  Routledge , New York, \n2013.  \n[2] Magee , J.C. and A.D. Galinsky, “Social hierarchy: The \nself-reinforcing nature of power and status,” Academy of \nManagement Annals , vol. 2, no. 1, 2008.  \n[3] Acemoglu, D. and  J.A. Robinson, Economic Origins of \nDictatorship and Democracy , Cambridge University Press, NY, \n2006.  \n[4] Mintzberg, H. , The Structuring of Organizations: A Synthesis of \nthe Research , Englewood Cliffs, NJ: Prentice -Hall, 1979.  \n[5] Leavitt, H. J. , Top Down: Why Hierarchies Are Here to Stay and \nHow to Manage Them More Effectively , Boston, MA: Harvard \nBusiness School Press , 2005.  \n[6] Bearman , P.S. and P. Parigi, “Cloning headless frogs and other \nimport ant matters: Conversion topics and network structure,” \nSocial Forces 83: 535 -557, 2004.   [7] Sidanius, J., and F.  Pratto , Social Dominance: An Intergroup \nTheory of Social Hierarchy and Oppression , New York: \nCambridge University Press , 1999 . \n[8] Baron, J. N.  and J.  Pfeffer,  “The social psychology of \norganizations and inequality ,” Social Psychology Quarterly , vol. \n57, no.3, pp : 190 -209, 1994.  \n[9] Mason, W.A., F.R. Con rey and E.R. Smith, “Situating social \ninfluence processes: Dynamic, multidirectional flows of influence \nwithin social networks,” Personal ity and Social Psychology \nReview  11(3): 279 -300, 2007.  \n[10] Bunderson , J.S., G.S.  van der Vegt , Y. Cantimur  and F. Rink , \n“Different views of hierarchy and why they matter: Hierarchy as \ninequality or as cascading influence,” Academy of Management \nJournal , vol. 59, no. 4, 2016.   \n[11] Athey , S., E. Calvano  and S. Jha, “A theory of community \nformation and social  hierarchy,” https://ssrn.com/abstract  \n=2823777 , 2016.  \n[12] Marx, K.  and F.  Engels,  The German ideology (C. J. Arthur, \nEd.), New York: International Publishers , 197 0 (Originally \npublished 1846)  \n[13] Myers, D.G., Social Psychology (9th Edition ), McGraw -Hill \nEducation (Asia), 2008.  \n[14] Friedkin, N.E., “The problem of social control and coordination \nof complex systems in sociology: A look at the community \ncleavage problem,” IEEE Control Systems Magazine 35(3): \n40-51, 2015.  \n[15] Acemoglu , D. and A. Ozdaglar, “Opinion dynamics and learnin g \nin social networks,” Dynamic Games and Applications  1.1: 3 -49, \n2011.  \n[16] Jackson, M.O., Social and Economic Networks , Princeton \nUniversity Press, 2008.  \n[17] Lorenz, J., “Continuous opinion dynamics under bounded \nconfidence: A survey,”  International Journal of Modern Physics \nC 18(12):  1819–1838,  2007.  \n[18] Sornette, D., “Physics and financial economics (1776 -2014): \nPuzzles, Ising and agent -based models,” Rep. Prog. Phys.  77, \n2014.  \n[19] Hegselma nn, R. and U. Krause, “Opinion dynamics an d \nbounded confidence: Models, analysis, and simulations,” Journal \nof Artificial Societies and Social Simulations  5(3): \nhttp://jasss.soc.surrey.ac.uk/ 5/3/2.html , 2002.  \n[20] Proskurnikov,  A.V. and  R. Tempo, “A tutorial on modeling and \nanalysis of dynamic social networks. Part II ,” Annual Reviews in \nControl , vol. 45, pp. 166 -190, 2018.  \n[21] Chamley, C., A. Scaglio ne, and L. Li, “Models for the diffusion \nof beliefs in social networks: An overview,” Signal Processing \nMagazine  30(3): 16 -29, 2013.  \n[22] Wang, L.X.  and J.M. Mendel, “Fuzzy opinion networks: A \nmathematical framework for the evoluti on of opinions and their \nuncertainties across social networks,” IEEE Trans. on Fuzzy \nSystems , vol. 24, no. 4, pp. 880 -905, 2016.   \n[23] DeGroot, M.H., “Reaching a consensus,” Journal of the \nAmerican Statistical Association  69: 118 -121, 1974.  \n[24] Hegselma nn, R. and U. Krause, “Opinion dynamics under the \ninfluence of radical groups, charismatic leaders, and other \nconstant signals: A simple unifying model,” Networks and \nHeterogeneous Media  10(3): 477 -509, 2015.   12 \n[25] Kahneman,D., Thinking: Fast and Slow , Farrar, Straus, New \nYork, 2011.  \n[26] Wang, L.X.,  “Modeling stock price dynamics with fuzzy opinion \nnetworks,” IEEE Trans. on Fuzzy Systems , vol. 25, no. 2, pp. \n277-301, 2017.   \n[27] Krause , U., Positive Dynamical Systems in Discrete Time ： \nTheory, Models, and Applications , De Gruyter, Berlin, 2015.  \n \n "}
{"date": "2024-01-04-22-29", "error": false, "url": "PDF", "text_blocks": "Journal of Medical Internet Research / JMIR Mental Health  - Special Issue on Computing and Mental Health (2018)  (in press ) \nInstant  Automated Inference of Perceived Mental Stress through \nSmartphone PPG and Thermal Imaging  \n \nYoungjun Cho1,2, Simon J. Julier1, Nadia Bianchi -Berthouze1,2 \n \n1Department of Computer Science, University College London, London, WC1E 6BT, UK \n2Interaction Centre, Faculty of Brain Sciences, University College London, London, WC1E 6BT, UK  \n \n \nCorresponding Author:  \nYoungjun Cho  \nUCL Interaction Centre (UCLIC)  \nFaculty of Brain Sciences  \nUniversity College London  \n66 - 72 Gower Street  \nLondon  \nUnited Kingdom  \nPhone: +44 (0)20 3108 7177 (x57177)  \nEmail: youngjun.cho@ucl.ac.uk  \n \nAbstract  \nBackground:  A smartphone is a promising tool for daily cardiovascular measurement and mental stress monitoring. A \nsmartphone camera -based PhotoPlethysmoGraphy (PPG) and a low-cost therm al camera c an be used to create cheap, \nconvenient and mobile  monitoring  systems. Ho wever, to ensure reliable monitoring results , a person has to remain still for \nseveral minutes while a measurement is being taken. This is very cumbersome  and make s its use in real -life mobile situation s \nquite impractical.  \nObjective: We propose a system which combines PPG and thermography with the aim of improving cardiovascular  signal \nquality and capturing stress responses  quickly.   \nMethods:  Using a smartphone camera with a low cost thermal camera added on, we built a novel system which continuous ly \nand reliably measures two different types of cardiovascular events : i) blood volume pulse and ii) vasoconstriction/dilation -\ninduced temperature changes of the nose tip.  17 healthy participants, involved in a series of stress -inducing mental workload \ntasks, measured their physiological response s to stress ors over a short window of time (20 second s) immediately after each \ntask . Participants reported their level of perceived mental stress using a  10-cm Visual Analogue Scale  (VAS) . We used \nnormalized K -means clustering to reduce  interpersonal differences in the self -reported ratings.  For the instant  stress inference  \ntask , we built novel low -level feature sets representing variability of cardiovascular patterns . We then  used  the automatic \nfeature learning capability of artificial Neural Network s (NN) to improve the mapping between the extracted  set of feature s \nand the self -reported ratings . We compared our proposed method with existing hand -engineered features -based machine \nlearning methods.  \nResults:  First, we found that  the measured PPG signals presented  high quality cardiac cyclic information (relative p ower  \nSignal Quality Index , pSQI: M=0.755 , SD=0.068 ). We also found that the measured thermal changes of the nose tip presented  \nhigh  quality breathing cyclic information  and filtering helped extract vasoconstriction/dilation -induced patterns  with fewer \nrespiratory  effects ( respiratory pSQI: from M=0.714 to M=0.157).  Second,  we found low correlations between  the self -\nreported stress scores and  the existing metrics of the two cardiovascular signals  (i.e. heart rate variability and thermal \ndirectionality metrics) from short  measurements, suggesting they were not very dependent upon one another. Third, we \ntested  the performance of the instant perceived stress inference  method.  The proposed method achieved  significantly higher \naccuracies than existing pre-crafted features based -methods. In addition, the 17 -fold Leave -One -Subject -Out (LOSO) cross -\nvalidation  results  showed t hat combination of both modalities produced higher accuracy in comparison with the use of PPG or \nthermal imaging only (PPG +Thermal: 78.33 %; PPG : 68.53 %; Thermal: 58.82%). The multimodal results are comparable to the \nstate -of-the-art automatic stres s recognition methods that requir e long term measurements ( usually, at least a period of 2 \nminutes is required for an accuracy of  around 80%  from LOSO ). Lastly, we explored effects of different widely -used data \nlabeling strategies  on the sensitivity of our inference methods . Our results show ed the need for  separation of and \nnormalization between individual  data . \nConclusions: Results demonstrate the feasibility of using smartphone -based imaging  for instant mental stress recognition. \nGiven that this approach does not need long -term measurements requiring attention and reduced mobility,  we believe  it is \nmore suitable for mobile mental healthcare solution s in the wild.  \n \nKeywords :   \nAutomatic stress recognition;  mobile devices ; PPG ; low -cost thermal imaging ; blood volume pulse ; variability;  nose \ntemperature ; physiological computing; affective computing ; machine learning  Introduction  \nHuman physiological events are controlled by the actions of the Sympathetic and t he ParaSympathetic Nervous Systems (SNS \nand PSNS) . Of the many different types, cardiovascular and respiratory events have been shown to be importan t for \nmonitoring a person’s mental health and stress [1–5]. Recent studies have demonstrated that it is possible to use smartphone \nRGB camera s to measure Blood Volume Pulse (BVP)  [6–10] and mobile thermal camera s attached to a  smartphone  (or \nintegrated into it, for example, Cat S60)  to measure respiratory cycles [11] . These encouraging results suggest that \nsmartphone s could be come  a powerful apparatus for monitoring and supporting mental stress management on a daily basis  \nthrough biofeedback  [12] . Indeed, the combination of RGB and thermal camera s into  one device  has the potential to provide a \nvery large set of physiological measurements for stress monitoring  in our daily life . Smartphone apps with such capabilities \nare increasingly desired as possible tools  for facilitating stress self -management  [13–15] as people are often unaware of their \nlevel of stress and  of being stress -sensitive to particular situation s (e.g. chronic pain can cause a fear of movement [16] ). There \nis also strong interest within the industry in complement ing typically used questionnaires in order to enable improved \nassessment of wellbeing with personnel as well as revisiting work plans and work environments  [17] . Given their size and \nmobility, s uch sensors could be embedded into employees’ aids  for eas e of use . While these low -cost sensors are still not \nperfect, the literature  shows that their reliability is increasing, and we are contributing to this body of work. At the same time, \nwe hope that our work contributes to the literature in general using these signals as stress measures [18–20]. In this paper, we \naim to focus on  two  important  cardiovascular  events  that can be captured by low cost , low resolution sensor s: cardiac cyclic \nevents with smartphone PPG, and vasoconstriction/dilation -induced nose tip temperature dynamics with a low cost thermal \ncamera. In particular, we investigate how to instantly capture stress -induced variability of such physiological pattern s.  \n \nHeart Rate Variability (HRV)  is the time series of variation in heartbeats . It has been used to measure a person’s mental stress \n[4,18,20 –25]. HRV ’s popularity arises from the fact that  it has been shown to  abstract infor mation about  the sympathovagal \nbalance between the SNS and PSNS . When confronted with a stressor, the autonomic nervous system can produce a sequence \nof fight -or-flight responses  [1]. These manifest themselves  as alternations of accelerated and decelerated car diovascular \npatterns [1,26] . To characterize the HRV, various authors [4,21,22,27]  have proposed a variety of hand-craft ed HRV  metrics \nthat are computed over the time intervals between heartbeats . Although most of the HRV metrics were originally  built based \non the R-R intervals from ECG  (Electrocardiogram)  measurements [28] , the metrics have been applied to the P-P intervals \nfrom PPG  measuring blood volume pulse  [18,20,25,29] . In the case of PPG , the term Pulse Rate Variability  (PRV)  or PPG HRV \nare often used to clarify  the diff erent type (even if related) of event measured  [26,29 –31] with respect to ECG . Amongst  the \nmost commonly  used  are statistical metrics (such as the standard deviation  of R-R or P -P intervals ) and frequency -band \nmetrics (e.g. the normalized power in a frequency band of interest) . In particular , various studies have found that the Low \nFrequency (LF; 0.04Hz – 0.15Hz) and High Frequency (HF; 0 .15Hz – 0.4Hz) band s of the time intervals in heart rates  appear to  \nreflect the SNS and PSNS activities  [21] . Based on this observation , many studies have proposed to use  the LF/ HF ratio as a \nstress indicator [4,22,24,32] . Howeve r, the use of  such metrics has remained controversial in that they tend to oversimplify \nphysiological phenomenon  [33–35]. In particular, a single physiological metric itself does not strongly contribute to \nautomatically detecting  a person’s stress levels (i.e. machine learning tasks)  [33,36] . Hence, multiple HRV metrics -derived \nfeatures  have been  used together with those from other physiological activities suc h as perspirat ion and respiratory activities \nfor automatically inferring mental stress ( e.g. during driving tasks [37]  and desk activities [25] ). To ensure reliable \nmeasurements with such features, a relatively long term window of data (several minutes to a few hours) must also be used \n[25,36] . Although this is acceptable in specialist settings or with  medical devices, it is highly inconvenient in the real world \nwith unstructured settings using low cost devices (in particular, the PPG). For example, if  smartphone -based finger PPG was to \nbe used , a user would have to continuously make sure their finger is held stably in front of the camera . Another issue is that \nchanges in ambient light levels, as a user moves around, can corrupt long -term measurements.  \n \nAnother documented cardiovascular event wh ich happens as a reaction to mental stressors is vasoconstriction of blood \nvessels in a person’s nasal peripheral tissues [38,39] . This causes blood flow  to drop , result ing in a decrease in temperature \nwhich can be detected by monitoring the temperature of the nose tip. The study in [40]  found that a contact -based multi -\nchannel thermistor was able to detect a significant decrease in temperature of the nasal area as relative to the forehead in \nmentally str essful conditions. The same result has been repeatedly reported from the use of thermal imaging in mental stress \ninduction studies [38,41] , indicating that the thermal directionality ( i.e. temperature dro p) can be a potential barometer of \nmental stress.  However,  studies show similar limitations as they require keeping  the head still (often authors use  a chinrest) . \nIn addition, they also require to measure  baseline temperatures to compute the thermal direction which may limit its use in \nreal -life application s [42,43] . In this work, we addres s the former issue by using a state -of-the-art tracking method  [11] . \nFurthermore, we rely only on the instant measurement  with the area of interest (nose tip) to address the latter.  \n  \nThe reason for proposing the use of two sensors in this study rather than just one is that, despite the potential of thermal \nimaging in measuring BVP [44] , its accuracy is low and its ability in measuring P -P intervals has not been yet validated. \nInstead, camera -based PPG has been shown to be more reliable  [9,45]  and can be used simul taneously with thermal imaging , \npossibly compensating each unimodal performance in inference tasks . In addition , the use of finger PPG and thermal camera \nraises much less privacy concerns than RGB -based facial analysis  (i.e. remote PPG [8]). Further more , the use of multiple measurements increase s reliability of stress monitoring. Finally, even if not investigated in this paper, low cost thermal \nimaging could provide furt her measurements of stress -related phenomena ( e.g. respiration rate [11,36]  has already shown to \nbe possible with a mobile thermal camera, and possibly sweat  [46] ) to provide a wide battery of cue s for reliable assessment.  \n \nRather than focusing on all possible physiological signals that could be later added, this paper investigates the possibility to \nbuild a fast stress recognition system that only requires a very short time window of  PPG and thermal  measurements.  This is \nto ensure the possible use in real -life ubiquitous situations. In particular, we contribute  to the literature  on four fronts. First, \nwe propose new preprocessing techniques to enhance the quality of the signals  that are extracted from both the smartphone -\nbased PPG and thermal camera , and to reliably produce P -P intervals and thermal variability data  as low -level features . This is \nparticularly important when working with ultra -short measurements  [47] . Second, we explore correlations between currently \nused metrics from thermal and PPG signals over a short period of time and self-reported stress scores. Third, instead of using \nthe existing  metrics as high -level features, we propose to use the low -level features and let artificial neural networks (NNs) to \nlearn informative high -level ones  themselves . We evaluate the approach on a multimodal dataset purposely collected for this \nstudy. Finally, we furt her investigate sensitivities of different labeling strategies from self -reported stress scores within the \nperceived stress recognition performance.  \n \n \nMethods  \nThis section  presents  a method that enables quick inference of a person’s perceived stress level using smartphone -integrated  \nPPG and  thermography . We call these measurements instant measurements  to differentiate them from the short measurement s \n(typically between 2min and 5min) which have been previously defined  in the literature  [47] . \nFirst, we describe software we implemented. This includes a recording set-up and a set of techniques to produce reliable PPG -\nderived HRV profiles and sequential nose tip thermal variations (called hereafter  the thermal variability sequence ) from the \nthermal imaging sensor . We then introduce our study protocol to induce different levels of mental stress and collect short \nsequen ces (20s)  of cardiac pulse -related and thermal events together with self-reports of perceived mental stress scores. \nThird, we extract low -level (one -dimensional P -P intervals and thermal variability sequences) and high -level hand -engineered \nfeatures, comparing the perf ormance of our system over the two sets of features and sensor modalities. We conclude by \ncomparing our approach to data labeling with standard approaches to discuss the effect of inter -subjective variability in \nreporting stress scores.  \n \nToward Smartphone as a Reliable Multiple  Cardiovascular  Measure  \nThe main cardiovascular sensing channels of this work are the rear RGB camera of a mobile phone (LG Nexus 5) and a low -cost \nthermal camera (FLIR One 2G) attach ed to the phone.  Figure 1 shows the smartphone  with  the attached thermal camera, the \nrequired finger placement  and light emission  for PPG , and the physiological measurement interface.  \n \nAlthough the smartphone -imaging -based PPG measurement can be performed in  either a contact  [6,7]  or a contactless \nmanner  [8], in our work we only focus on a contact -based imaging PPG . The reason is based upon previously repeated \ninvestigation s within clinical studies  [6,10]  reporting its high accuracy . In addition, g iven that a normal RGB camera is only \nsensitive to a narrow electromagnetic spectral range of visible light in the so -called visible spectrum  [48] , adequate lighting is \nrequired before it can be used as a PPG sensor. Hence , a light emission from the rear flash LED is used  and a user is required to \nhold  the smartphone body and plac e his/her finger over both the back camera and flash light (Figure 1a,b). Unfortunately,  the \nuse of the back flash limits the duration of the measurements in some devices since its heat can  potentially burn a \nperson ’s skin. As shown in Figure 2, a large amount of heat is produced by the LED  emission from the chosen  \nsmartphone (LG Nexus 5) in just 25 -30 seconds of operation. A similar amount of heat  was observed  from another \nmobile phone (Samsun g Galaxy 6 in Figure 1b). Since temperature s above 50°C are potentially  damag ing to  human skin \ntissues  (e.g. skin erythema could occur from 25 seconds heating at 51.07°C [49] ), we limit the cardiovascular \nmeasurement to  a 20 second time period . This is also the required minimum duration for obtaining valid HRV metrics \nvalues (in particular, LF/HF [47] ). \n \nTo capture a time series of apparent thermal sequences, we developed bespoke  recording software using the FLIR One library . \nThe interface is shown in Figure 1c . Considering the  thermal propert ies of human skin , the emissivity of the thermal imaging \nsensor was fixed a t 0.98 [50] . As the thermal imaging system do es not guarantee a consistent frame rate [48] , the recording \ninterface store s the time stamp with  each image frame.  \n \n \n \n \n \n  \nFigure  1.  Smartphone RGB and thermal camera based physiological measurement: (a) a smartphone with an add -on thermal \ncamera, (b) flash LED emission and finger placement for PPG measurement, (c) designed software interface to collect BVP and \n1D thermal signature  from the nose.  \n \n \n \n \nFigure  2.  Heat produced by the rear flash LED of a smartphone (LG Nexus 5) measured by a thermal camera (FLIR One) : (a) \nbefore turning on the LED (36.3 °C), (b) after 10 -15 seconds (43 °C), and (c) after 25 -30 seconds (53.7 °C). \n \n \nBVP and P-P Interval Estimation through PPG  Imaging  \nFigure 3 summarizes the approach we use to extract BVP and P-P intervals through the smartphone imaging PPG. Following \n[6,7,10] , our method  estimate s the BVP signals  by captur ing subtle color variations associat ed with light absorptivity patterns \nof hemoglobin in the capillaries of a person’s skin. However, rather than us ing average values of the pixels of the red  (or green)  \nchannel to estima te the BVP value  (which is the most widely used method [6,7,9] ), we propose to use the temporal variations \nin spatial  Shannon’s entropy  [51]  of sequential R -channel images  as raw BVP signals . This is due to averaging which tends to \nignore fairly small but important variations in color distribution [11] . The estimated BVP value \n()tBX  at a given time t can be \nexpressed  as:  \n \n, 2 ,\n( , )( ) ( )log ( )t i j i j\nijB X p x p x−\n       (1) \n \nwhere  \n,ijx  is the brightness of pixel( i,j) and \n,()ijpx  is the probability distribution which is generally estimated using a \ngrayscale histogram in image analysis  [52]  (here, for the R channel) . \n \n \nFigure  3.  Overall procedure of BVP and P -P interval estimation from a person’s finger through the smartphone -imaging PPG. \nSee text for details.  \n \n \nAs our interest is in measuring raw P-P intervals from PPG signals , we used a simple signal processing  technique to create \nsimilar amplitudes of  each peak of BVP which helps detect peaks for measuring the time interval  (i.e. P-P interval) between the \npeaks. This was done by  the subtraction of  the k-sample moving average signals fro m the raw entropy signal (Figure 3b) which \ncan be expressed by  \n \n11ˆt\nt t i\ni t kB B Bk−\n=−=−\n.       (2) \n \nBecause a high sampling rate produces a higher sensitivity of the P -P intervals [53] , we up -sampled the raw sequen ces to 256 \nHz with spline interpolation  and used a 1s moving average  to smoot h heartbeat  induced variations within the duration where \nat least one heartbeat of a normal person is expected to appear [54] . Finally, we used the  simple local maxima detection [55]  \nwith a 0.5 second sliding window  to recover P -P intervals (Figure 3c).  \n \n \nContinuous Extraction of Nose Tip Thermal Variability Sequence  \nTo extract  the 1D sequential nose tip thermal changes , our approach uses the three computational steps shown in Figure 4. \nThese are:  i) nose -tip Region of Interest ( ROI) tracking, ii) breathing artifact reduction , and iii) post processing for extracting \nlow-level  features representing thermal variability .  \n \n \n \nFigure  4.  Overall procedure of the extraction of one -dimensional thermal variability signature from a person’s nose tip \nthrough smartphone thermal imaging.  \n \n \nFor ROI tracking, we  can take advantage of recent advanc es in thermal ROI -tracking techniques which help minimize the \neffects of motion artefacts and thermal environmental changes. In particular, we used the Optimal Quantization and Thermal \nGradient Flow methods (Figure 4a) introduced in [11] . Through the use of these techniques, we can continuously extract a \nspatial  average temperature sequence  over the ROI.  As breat hing causes thermal changes in the area close to the  nose  tip (see \nFigure 4b), we need to remove such effect s from the ROI for reliable measure ments . This is necessary despite  the fact that \nbreathing dynamics are significant indicator s of mental stress [3,36]  in itself.  For this, we propose to use  a low -pass filter with  \na cutoff frequency  lower than the normal range of breathing rates of healthy people ( e.g. 0.1-0.85Hz in [11] ). As a thermal \ndirectional change is a r elatively slow physiological event [56] , we set this to 0.08Hz  which is lower than the low boundary . \nFor the implementation, we used a zero -phase  filtering (seventh -order, Butterworth) to avoid a phase -shifted result. Finally , \nwe compute d the thermal variability sequences o f the nose tip (Figure 4c) by  down -sampling  with a linear interpolation  and \nfeature scaling  the signal . Here, down -sampling (1Hz ) is used to address the unsteady frame rate of the  thermal camera  and to \ncompute successive temperature differences  sampled at regular temporal points . Feature scaling (Figure 4c) was applied to \nminimize the effect of different levels of nasal temperature s across par ticipants and sessions and  to explore the thermal \ntemporal variability within short -term data . As this new method  helps extract  nose tip thermal variability sequences  \ncontinuously , it can produce richer feature sets in comparison with earlier methods [38,40,41] . In turn , this could  possibly \nprovid e useful information , even from an instant measurement , contributing to the  automatic inference of  a person’s stress .  \n \n \nData Collection Protocol  \nA da ta collection study was carried out to gather physiological data from participants during different tasks that induc ed \ndifferent levels of mental load. The data collection protocol is described below.  \nParticipants  \nA total of 17 healthy adults  (mean age 2 9.82 years, SD=12.02; 9 female) of varying ethnicities and different skin tones (pale \nwhite to black)  were recruited from the University College London and non -research community  through the UCL psychology \nsubject pool system . Participants  comp leted prescreening through the system which was designed to exclude participants with \nany history of psychiatric disorders  or medicine intakes which may influence their physiological signatures. Each participant  \nwas given the information sheet , asked to provide  a signed consent to take part in the study and to fill in the demographics \nform prior to the start of data acquisition. The study  was conducted in a quiet lab room with no distractions . Participant s were \ninformed that they could stop  the study at any time if they  felt uncomfortable . Only one experimenter was present in the room \nduring the data collection but kept his distance from  the participant  (further than 1.5 m). We compensated each participant  \nwith an £8 Amazon voucher after completion of the study. The experimental protocol was approved by the Ethics Committee \nof the University College London Interaction Centre (ID Number: STAFF/1011/005).  \n \nTask Structure and Instant Measurement s of Lasting Stress -induced Physiological Events  \nWe design ed a stress induction study protocol to collect physiological data and subjective self -reports in association with \nmental stress levels  due to mental load  [1,57] . From  the literature on mental stres s induction studies in psychology , \nneuroscience  and affective computing  (e.g. [2,25,58,59] ), we chose two cognitive -load induction tasks – the Stroop Color Word \ntest [60]  and the M athematical Serial Subtraction test [61] . These tests were selected as they have been shown in various \nstudies to induce mental stress by increasing  cognitive load . They have also been used in other thermal imaging studies  \n[39,41] . Each task was divided into two sub -tasks with varying difficult y levels  so as to elicit different stress levels (easy and \nhard : Se – Stroop easy, S h – Stroop hard , Me – Math easy, M h- Math hard ) and each sub -task was counterbalanced in a Latin \nsquared design as in  [36] . Between sub -tasks, we added a break period encouraging participants to fully reco ver (without any \nmeasurements, constraints) so as to avoid potential effects from previous sessions.  \n \nAlthough  it has been shown that the Stroop and Math tasks lead to cognitive overload [2,59 ], they are limited in the amount of \nstress they induce due to the lack of psycho social stress ors or other stressors  [2,62] . Hence, following  [2,40,59,62] , we also \nintroduce further stressors: a) social evaluative threats  (close observation and assessment of a person’s performance [2,62] ), \nb) time pressure  (e.g. 1.5 second limitation for each Stroop question [59] ), and c) loud sound feedback , in particular, an \nunpleasant sound for  wrong answers [40] . \n \nAs described above, heat caused by the use of the  smartphone PPG limited our data gathe ring  to a 20 second window \nimmediately after each task. The aim is to capture  the cardiovascular changes related to  stress responses  and their dynamics \nimmediately after  the stressor has ended  instead of measuring the signals during each task (Figure 5). Overall, this study \nprotocol consisted of : \n \n \n• waiting in the corridor, introduction and entering the study room (5-10 min)  \n• information/consent/demographics forms filled in (5-10 min)  \nSession 1  \n• [Rest  1] sitting, resting (5 min)  \n• 20s measurement and self -reporting of perceived stress (1 -2 min)  \n• [Task 1] Stroop Test 1  (5 min)  \n• 20s measurement and self -reporting of perceived stress (1 -2 min)  \n• break (5 min)  \n• [Task 2] Stroop Test 2  (5 min)  \n• 20s measurement and self -reporting of perceived stress (1 -2 min)  \n• break (3 min)  Session 2  \n• [Rest  2] sitting, resting  (5 min)  \n• 20s measurement and self -reporting of perceived stress (1 -2 min)  \n• [Task 3] Math Test 1  (5 min)  \n• 20s measurement and self -reporting of perceived stress (1 -2 min)  \n• break (5 min)  \n• [Task 4] Math Test 2  (5 min)  \n• 20s measurement and self -reporting of perceived stress (1 -2 min)  \n• break (5 min)  \nClosing  \n• wrap -up and participant’s feedback (5 -20 min)  \n \n \n \nFigure  5.  Experimental setup and self -report question: (a) during each stress -induction task session, (b) 20 second physiology \nmeasurement after sessions, and (c) 10cm VAS based questionnaire (R 1, R2: Rest from Session 1 and 2, Se: Stroop easy, Sh: \nStroop hard,  Me: Math easy, Mh: Math hard). The red marks ( x) represent an example of self -reported scores of one participant \nover the different tasks. The task labels have been added by the researchers for the purpose of this figure.  \n \nMeasuring and Self-Report of Per ceived Mental Stress  \nFor the 20s physiolog ical measurements, the person was asked to ho ld the ir index  finger on the smartphone RGB camera \nwhile keeping the smartphone add -on thermal camera facing their nose , as shown in Figure 5b. After each  20 second \nphys iological measurement, all participants were asked to answer a questionnaire about their perceived level of mental stress. \nWe used a 10 -cm Visual Analogue Scale (VAS), which allows participants to answer on an analog basis (continuous) to avoid \nnon-paramet ric properties [63,64] . The question asked was “ How much did you feel mentally stressed? ” (ranging from 0, not at \nall, to 10, very much). Only one VAS straight line was used for each participant to self-report his/her  perceived stress level s \nacross all  tasks and session s. This is to help participants easily compare stress scores  they report  between sessions as shown \nin Figure 5c. This approach combine s a numerical approach to self -report ing with a ranking one , as ranki ng is generally more \nreliable tha n simple quantization of a subjective state  [65–67]. The labels in Figure 5c have been added to  the figure by the \nresearche r to clarify their reference to  each of the task s (R1, R2: Rest from Session 1 and 2 , Se: Stroop easy, S h: Stroop hard , Me: \nMath easy, Mh: Math hard ). \n \n \nAutomatic Inference of Perceived Mental Stress  from Instant Measurement  \nLow -Level and High -Level Features  from Cardiovascular Events  \nThe 20 second -cardiovascular measurement with the developed interface (Figure 1c, 5b) simultaneously produces the \nfollowing signals : \na) one -dimensional P-P interval s \nb) one-dimensional thermal variability sequence  \n \nWe take the P-P intervals (Figure 3c) and thermal variability sequence  (Figure 4c) as low-level  features representing each \nmodality throughout this paper.  \n \nIn order to evaluate the effectiveness of our approach against standard approaches, we also extracted high -level  engineered \nfeatures for both BVP and nose tip temperature variations as the evaluation benchmark for our approach . We followed earlier \nstudies on stress inference using HRV metrics  as the features  [25,37,68,69]  (in our case, PPG -derived HRV; for readability, \nhereafter simply called PRV ), although we exclude d features directly from HR given its minor role repeatedly found in stress \ninference studies (e.g. [25] ). After the pre -processing method described above, we extracted  the following  PRV  features : \n \na) PRV F1: LF Power  \nb) PRV F2: HF Power  \nc) PRV F3: LF/HF ratio  \nd) PRV F4: SDPP (Standard Deviati on of P-P intervals)  \ne) PRV F5: RMSSD  (Root Mean Square of the Successive Differences of P-P intervals)  \nf) PRV F6: pPP50 (proportion of the number of the successive differences of P-P intervals greater than 50ms of the total \nnumber of the intervals ) \n \nAs for high -level  features representing  the nose tip thermal signature , we  used the most primarily used feature in the literature \n[38,40 –42]: \n \ng) Nose temperature F1: TD (Temperature Difference between data from the start and the end ) \nAdditionally, we extracted basic statistical features from the processed thermal variability sequence , similarly to SDPP from \nthe P -P intervals:  \nh) Nose temperature F2: SDSTV (Standard Deviation of the Successive differences of the Thermal V ariability  sequ ence ) \ni) Nose temperature F3: SDTV (Standard Deviation  of the Thermal Variability sequence)  \n \nThe sliding window was not used t o extract these features given the short period of time over which they were measure d.    \n \nLabeling Strategy and Machine Learning Classifiers  \nGiven th e focus on automated inference of a person’s perceived stress level, the labeling of self -reported stress scores is an \nimportant  step . However, i nterpersonal variability has been repeatedly found from  self-reports  of perceived mental stress \n[24,36,70] . This is a key issue which must be addressed if we are to create  automatic stress recognit ion system s that can \ngeneralize across people . Following  our earlier work [36] , we use the normalized  K-mean s clustering technique to label the \nmeasured events , as the K -means has been shown to be effective in handling self -reported data [71] . In detail, all perceived \nstress scores collected from each participant are normalized through feature scaling  that identifies the minimum and \nmaximum scores for a participant and rescales all the scores so the range is the same across all participants.  Then, the K-\nmeans  algorithm (k=3) is used to group the participants’ VAS scores into three levels of perceived stress scores corresponding \nto “None or low stress ”, “Moderate” and “Very high ” on the VAS we used  (see Figure 5c). In this paper, we focus on \ndisc riminati ng between two levels of stress , No-stress  and Stress  given the limited amount of data for a more refined \ndiscrimination . Hence , a third step is required. We split the labels into two groups: t he No-Stress  group referring to the K -mean \n“None or low stress scores”  cluster  and the Stress  group containing  both the  K-mean “Mo derate ” and “Very high ” score  \nclusters . Two obtained labelled groups are hence used to label the related physiological signatures from each 20s  window \n(L1) .  \n \nFurthermore, we exp lore d the possible effect of different data labeling strategies : a) L2: combining the first and second K-\nmeans clusters  (from k=3) into  No-stress by contrast with  L1, b) L3: K-means  with k=2, and lastly, c) L4: the original  stress \nscores divided by directly dividing the VAS scale intro three equal section s and then combining the “moderate” and “Very high” \nstress classes into one, i.e. “Not at all” and “ Moderate  + Very high ” (threshold at point  3.334 on the VAS scale in Figur e 5c). The \naim of L2 and L3 was to understand the sensitivity of our approach in separating  the moderate level of stress with the other \ntwo classes. L4 was used as a way to compare with more standard technique s used in the field  [72] .  \n \nTwo machine learning algorithms were tested . First, we used a single hidden -layer Neural Network  (NN ) which is suitable to \nwork with low -level features (i.e. P -P intervals and thermal variability vectors) capturing their temporal dynamics.  The use of \nartificial NNs can empower automatic learning of informative physiological features with back -propagation to repeatedly tune \ninternal parameters to let the features emerge from the data (this is also called representation learning). Second, w ith the \nhigh -level  engineered features, we used the k-Nearest Neighbor classifier  (denoted as kNN, k=1) as a benchmark stress \ninference model given that this is typically used in this area  [69] . By choosing this second algorithm , we aim to assess the \nlimitations of the use of handcrafted features which may simplify a person’s  dynamic physiological events , and in turn possibly \nmiss  out some fast , informative moments.  In particular, in the case of instant measurement s (short period of time), this cannot \nbe compensated by the use of a sliding window producing sequential feature values ( e.g. a 120 seconds sliding window used in \n[25]  to continuously produce PRV features during a 180 second task session).   \n \nFor the implementation  of NNs , we tested two  sizes of hidden layer node s: a) small (n=80 , NN1 ) and b) large (n=260 , NN2 ) – \neach node size was empirically chosen.  The mean and standard deviation  of the training data set were used to normalize both \nthe training and testing data set. The s igmoid was used as an activation function. In the training process, a fixed learning rate of \n0.5 was used for 100 epochs.  \n \n Results  \nIn this se ction we evaluat e our proposed approach. First , we report the statistical analysis of the collected data. Second,  we \ndiscuss the  recognition performance of our system over the different modalities and types of features. Finally, we compar e the \nresults for the different  labeling approaches.  \nReliability of Measured Physiological Patterns  \nFirst of all, we tested the reliability of the physiological measurement s. From the 17 participants , we collected 102  sets of the \nestimated BVP signals, P-P interv als and thermal variability sequences  from 20 s instant measurements  taken after each  Stroop \nand Math task and after each  resting session . However, 2 sets of data were not recorded  due to  phone battery issue s at the end \nof one experiment , and 1 set was not recorded as one participant clicked the turn -off button on the phone by mistake. 6 further \nsets had to be discarded because  some participant s’ nose was not visible on thermal images  (nose outside of the range of view \ndue to sudden severe coughing  during the 20sec , or because of head turned towards the experimenter , or the nose was \ncovered by  a person’s hand ). Although these disturbances were often transient, they meant that data could not b e collected \nwithin the 20s immediately following the end of the stressor. An analysis of the thermal data from Rest 1 also showed some \nextreme patterns in the nose tip temperature (e.g. sudden increase in temperature). This may be explained by the fact tha t the \nexperiment was conducted during the winter and temperatures outside of the experimental room were often significantly \nlower. This included both outdoors, and indoors in the corridor where the participants waited for the experiment. Despite the  \ntemper ature changes, the Rest 1 data was kept in the dataset. A total of 93 sets were used for the study.  \n \nAs the measurement capability of smartphone PPG has previously been thoroughly invest igated in earlier studies (e.g. \n[6,9,10] ), we only tested the reliability of the cardiac pulse signals measured with our approach  and compared it  with the \nmean brightness intensity -based method, which has been dominantly used  [6,7,9] . For this, w e used t he relative power  Signal \nQuality Index  (pSQI ), which  is to  assess the strength of  physiological signals  in a frequency range of interest , as a measure of \nquality  [11,53,73,74] . The pSQI for the BVP signals can be expressed  by:  \n  \nmax\nminˆ\nˆ ˆ\nmin max\nˆ()ˆˆ()\n()f\nB f\nB totalS f df\nP f f f\nS f df  \n\n      (3) \nwhere  \n01P , \nˆBS\n is the power spectral density of BVP signals (in our case,  \nˆB in Eq. (2)), and \nminˆf , \nmaxˆf  are the lower and \nupper boundary of expected HRs, respectively . Here, we set the expected HR range to [ 0.8Hz ( 48bpm ), 2.0Hz ( 120bpm )] given \nthat HRs of healthy adults mostly  fall into this range [54] . To minimize effects of the baseline wander and high -frequency noise  \non this signal quality test  [6,74] , we used band -pass filtered BVP signals (0.7 -4.0Hz) as in [6]. Figure 6 shows the better  quality \nof the estimated BVP signals \nˆB from the proposed method (Eq. (2)) than that from the mean intensity method  (Proposed : \nM=0.755 , SD=0.068; Traditional:  M=0.692, SD=0.075 ). \n \n \n \n \nFigure  6. Signal extraction quality comparison of our spatial entropy -based method (Eq.(2)) with the mean intensity approach \n[6,7,9]  by using pSQI: (a) box plot, (b) histogram.  \n \n \n \nFigure 7a shows examples of thermal images taken from the participants during the data collection study. F rom our \nobservation s, we found that respiration  influence s the nasal tip temperature  measurement in some cases . For instance, in \nFigure 7b , thermal images of  a person’s  nose tip surface  which were sequentially captured show that  inhaled air changed the \nnose tip temperature.  Hence, w e tested how much participants’  respiratory cycled events affected  the nose tip temperature  \nmeasur ements  by using the pSQI  in Eq. (3) with the expected respiratory rate of interest  (from 0.1Hz to 0.85Hz) as used in  \n[11] . Figure 7c demonstrates how the measured  nose tip temperature s involved respiratory cyclic patterns  (respiratory pSQI: \nM=0.714 , SD=0.163 ), indicating that such affected temperature patterns may lead to wrong stress level classification.  On the \nother hand,  the processing technique we propose  to use (Figure 4b ) instead led to reduc ing respiratory artifacts on the \nmeasurement ( respiratory pSQI: M=0.157, Sd=0.091 ). \n \n \n \nFigure  7. A person’s respiratory activity influences the nasal tip temperature: (a) examples of thermal images from \nparticipants (view angles were not constrained), (b) th e nasal temperature changes during inhalation (yellow: warmer, red: \nmoderate, black: colder), and (c) respiratory signal quality test using pSQI.  \n \n \n \nSelf-Reported Stress Ratings and Hand -engineered Metrics  \nAn important step was the analysis and possibl e normalization of the self -reported stress scores. The boxplot in Figure 8 a \nshows the distribution of the self -reported scores over the resting periods and the different sessions  and tasks. It is clear that \nthe stress  elicitation procedures did , overall , produce the wanted levels of stress with the hard sessions scoring higher than \nthe easy sessions and the latter scoring higher than the resting period s (Rest  from Session 1: M=1.49, SD=1.94; Rest from \nSession 2: M=1.30, SD=1.26;  Stroop Easy: M=2.17, SD=1.46; Math Easy:  M=2.66, SD=1.80;  Stroop Hard: M=3.92, SD=2.11; Math \nHard:  M=5.17, SD=2.55) despite two outliers. However, the wide boxplots also show inter -subject variability in self -reporting. \nIn addition, the ra nges (maximum - minimum) in scores for each participant differ quite highly (Maximum range: 8.75, \nMinimum range: 1.5 , Mean: 4.7, Std: 2.1 ) further suggesting the need for normalization  of the scores.  \nTherefore, we normalized the data for each participant with respect to their range of scores over all the sessions. Figure 8 b \nshows the original data and Figure 8 c shows the normalized data. The normalization helps to i dentify  two main modes in the \nscore distributions suggesting t he presence of two main clusters of stress levels.  Given the subjectivity of stress ratings and the \nlimited amount of data sets to carry a multi -level model, in this paper we focused on binary classification of perceived mental \nstress: no/low stress vs . medium/high (or very high) stress. The K -means separation between the two clusters is represented \nby each different color  in Figure 8c. \n \n \n \nFigure  8. (a) Inter -subject variability shown from the original  self-reported stress scores of the 17 participants (bo x plot, 95% \nconfidence interval) across each section (Rest 1, Stroop Easy, Stroop Hard, Rest 2, Math Easy, Math Hard). (b) Overall self -\nreported stress score distributions (from 17 participants over the sessions including the resting periods), (c) normalized  \nstress scores (normalization of scores from each participant) clustered into No -stress and Stress groups along with outputs of \nK-means.  \n \n \n \n \n \nWe tested the correlations between the original self -reported scores, normalized self -reported scores and the high -level hand -\ncrafted PRV and thermal metrics as summarized in Table 1 (using Pearson correlation coefficients). The normalized self -\nscores main tained a high correlation with the original scores (r=0.752, p<0.001). While some metrics of each physiological \nsensing channel were significantly correlated between themselves (e.g. PRV  F2 - F4: r=0.838, p<0.001; Thermal F1 - F3: \nr=0.803, p<0.001), the co rrelation values were lower across sensing channels. In addition, only SDSTV shows approaching \nsignificance but low correlation with the self -report scores (r = .196, p=0.059) , indicating that each individual engineered \nmetric alone could not lead to high discrimination between perceived levels of stress.  \n \n \n \nTable 1. Pearson correlation coefficients across self -reports, PRV  (PPG derived HRV ) and thermal metrics (High -level \nfeatures) . S1=Normalized self -reported scores, S2=original self -reported scores .      \n \n \n \nFigure 9 shows  values of each pre -crafted metric across  the sessions (rest and four stressful events , i.e. Stroop easy/ hard  and \nMath easy/ hard ) and  across the  label s produced by the labelling technique. As shown in Figure 9a, there was no common \npattern found between  two easy or hard tasks , although  they  were designed to induce similar levels of mental stress (e.g. easy: \nlow stress level, hard: high stress level) . For example, Thermal F1 appeared to strongly decrease during the Math hard task but \nnot during the Stroop hard task, Thermal F2 increased with the Stroop hard task, but less during the Math hard task. PRV  F5 \nwas generally high after both Math easy and hard task session s than Stroop hard session. This can indicate further that each \nmetric  alone from the instant measurement is less likely to contribute to the inference of each session. On the other hand, \nwhen we applied our labelling technique, Thermal F1 values grouped i nto stress  were generally lower than no-stress  data as \nshown in Figure 9b (consistent with findings from literature [38,40,41] ).    Self reports  PRV (PPG derived HRV)  Nose Temperature  \n \n  S1 S2 LF  \n(F1) HF  \n(F2) LF/HF  \n(F3) SDPP  \n(F4) RMSSD \n(F5) pPP50 \n(F6) TD (F1)  SDSTV \n(F2) SDTV \n(F3) Self Rep.  \nS1 Corr.  1 .752  0.007  0.011  -0.044  0.03  0.146  0.058  -0.154  0.196  0.02  \np-value   <0.001  0.943  0.911  0.665  0.77  0.148  0.569  0.139  0.059  0.848  \nS2 Corr.   1 -0.079  -0.044  -0.082  -0.002  0.083  0.097  -0.153  0.197  0.032  \np-value     0.438  0.664  0.422  0.987  0.414  0.338  0.14  0.058  0.758   PRV (PPG derived HRV)  F1 Corr.    1 0.394  0.573  0.638  0.098  0.134  0.016  0.12  0.047  \np-value     <0.001  <0.001  <0.001  0.336  0.186  0.88  0.251  0.657  \nF2 Corr.     1 -0.293  0.838  0.13  0.39  0.083  0.2 0.054  \np-value      0.003  <0.001  0.199  <0.001  0.431  0.054  0.608  \nF3 Corr.      1 0.007  -0.027  -0.178  0.056  0.057  0.123  \np-value       0.948  0.791  0.079  0.596  0.588  0.239  \nF4 Corr.       1 0.139  0.571  0.1 0.198  0.084  \np-value        0.171  <0.001  0.338  0.058  0.425  \nF5 Corr.        1 -0.067  -0.059  0.174  -0.067  \np-value         0.511  0.572  0.095  0.521  \nF6 Corr.         1 0.134  0.212  0.127  \np-value          0.2 0.042  0.225  Temperatur\ne F1 Corr.          1 0.213  0.803  \np-value           0.039  <0.001  \nF2 Corr.           1 0.487  \np-value            <0.001  \nF3 Corr.            1 \np-value              \nFigure  9. Box plots of 95% confidence intervals in values of each pre -crafted metric across (a) each session (R 1: Rest 1, Se: \nStroop easy, Sh: Stroop hard, R 2: Rest 2, Me: Math easy, Mh: Math hard) and (b) label produced by our labelling technique. \nThe three features (having best correlations with self -reports) are PRV F5: RMSSD , root mean square of the successive \ndifferences of P -P intervals , Thermal F1: TD, temperature difference between from the start and the end (a red line is drawn \nto show negative or positive thermal direction), F2: SDTV , standard deviation of the successive differences of thermal \nvariability sequ ence.  \n \n \n \nInstant Stress Inference Results  \nTo evaluate the performance  of instant stress recognition , we used a 17 -fold leave -one-subject  (participant) -out (LOSO) cross -\nvalidation . LOSO was chosen to  test the ability to generalize to unseen participants (one size fits all) [36,70] . Figure 1 0 \nsummarizes the accuracy results of the three classifiers (NN1, NN2, kNN) using  LOSO (N=17) for three different cases: a) \nmultimodal -approach by simply combining features from both sensing channels ( PRV , Thermal), b) unimodal approach using \nthermal features, and c) unimodal approach using PRV  features. Both neural networks NN1 and NN2 used  our proposed low-\nlevel features  only  (i.e. P-P intervals and thermal variability sequence s). Overall, the NN2 -based multimodal approach \nproduced the highest mean accuracy of 78.33% (SD=15.43) (mean F1 score=77.92%) in discriminating between no -stress and \nperceived stress (see confusion matrix in Figure 10b for details). The NN1 (whose hidden layer  is smaller than that for NN2 ) \nproduced a lower accuracy (M=66.76%, SD=21.75). From all cases of modality, the kNN with the high -level features (i.e. using \nthe hand -engineered 6 PRV and 3 thermal metrics ) performed worst.  A similar pattern can be seen for  the PRV unimodal \nchannel (NN1: M=65.78%, SD=20.55; NN2: M=68.53%, SD=18.89; kNN : M=50.20%, SD=19.63). For the thermal channel,  the \nNN1 appears to perform marginally better (M=58.82%, SD=21.11) than the NN2 (M=56.67%, SD=18.79), but again both NNs \nperform better than  the kNN (M=48.14%, SD=16.52).  \n \nHowever, it should be noted  that, for all the models, the confusion matrices for the thermal case (Figure 10b - Thermal) show a \nclear bias towards the no -stress class. Given this bias and the fact that thermal da ta from the Rest 1 sessions appeared to be \naffected by the large variation in temperature between the waiting space and the experiment room (in addition, some \nparticipants had just arrived from the outside  while others had been already indoor for sometimes ), we re -ran the models \ndiscarding the data from the Rest 1 sessions. Whilst the overall performance  over this modality did not change largely (NN1: \nM=58.14%, SD=23.33; NN2: M=58.14%, SD=21.59; kNN: M=55.88%, SD=22.38) and the NN1 and NN2 still perform better than  \nthe kNN with hand -engineered features , all the confusion matrices (Figure 10c) show more balanced results and a better \nprediction of the stress class  overall .  \n \n \n  \nFigure  10. Summary of (a) mean inference accuracy results across 17 folds, (b) accumulated (from 17 LOSO folds) confusion \nmatrices for the three classifiers NN1, NN2 and kNN along with each set of modalities (Multimodal: PRV+Thermal, Unimodal: \nThermal, PRV), (c)  confusion matrices for the temperature -based unimodal approach built without the Rest 1 data. Each \nnumber in the confusion matrices refers to the number of instances.  \n \n \nA repeated measures ANOVA analysis was carried out on results from the 17 folds  (inclu ding the Rest 1 data)  to compare the \ntwo NN modeling approaches ("}
{"date": "2024-01-04-22-29", "error": false, "url": "PDF", "text_blocks": "arXiv:1901.00516v1  [cs.LG]  28 Dec 2018Honey Authentication with Machine Learning\nAugmented Bright-Field Microscopy\nChloe He\nDepartment of Computing\nImperial College London\nLondon, United KingdomAlexis Gkantiragas\nDepartment of Molecular Biology\nUniversity College London\nLondon, United Kingdom\nalexis.gkantiragas.17@ucl.ac.uk\nGerard Glowacki\nHampton Court House\nLondon, United Kingdom\ngerag7@hchschool.com\nAbstract\nHoney has been collected and used by humankind as both a food a nd medicine for\nthousands of years. However, in the modern economy, honey ha s become subject\nto mislabelling and adulteration making it the third most fa ked food product in\nthe world. The international scale of fraudulent honey has h ad both economic\nand environmental ramiﬁcations. In this paper, we propose a novel method of\nidentifying fraudulent honey using machine learning augme nted microscopy.\n1 Introduction\n1.1 Background\nHoney is the natural sweet substance produced by honey bees f rom the nectar of plants or from\nsecretions of living parts of plants or excretions of plant s ucking insects on the living parts of plants\nwhich bees collect and transform by combining with speciﬁc s ubstances of their own deposit, dehy-\ndrate, store and leave in the honey comb to ripen and mature [1 ]. It consists of various sugars as well\nas organic acids, enzymes and solid particles (such as polle n) derived from honey collection. The\nﬂavour and aroma of honey varies, but is derived from the hone y’s plant origin. [1] For millennia,\nhumankind has collected and used honey for both culinary and medicinal purposes [2]. In modern\ntimes, honey production is a global industry and its bees are essential for pollination and agriculture\nin the developed world [3]. Furthermore initiatives such as Bees for Development have sprung up\naiming to use beekeeping as a means to alleviate poverty in th e developing world [4].\nHoney, however, is also the third most faked food product glo bally and is often subject to misla-\nbelling (selling one honey as another) and adulteration (di lution of honey using sugar syrup, for\ninstance) [5, 6]. This is especially prevalent with more exp ensive regional honeys such as acacia\nand manuka honey, for which global consumption is allegedly greater than global production [7].\nThe truly global nature of this food fraud was most notably il luminated by the so-called ’Honeygate’\nscandal in which it was discovered that Chinese honey was bei ng transshipped through Germany\n(and thereby labelled as German honey) and imported to the US A by a number of food suppliers\n[8, 9, 10].\nSuch fraudulent practices have a negative impact on produce rs of genuine honey products as produc-\ntion costs for the fake products are signiﬁcantly lower. Thi s leads to lower proﬁt margins for genuine\n32nd Conference on Neural Information Processing Systems ( NIPS 2018), Montréal, Canada.producers as the market price for their produce falls someti mes forcing them to leave the market and\ndiscouraging new players from entering. It also means that p oorer regions producing valuable re-\ngional honeys lose out on potential revenue. Furthermore, b eekeeping practices in the production of\nfraudulent honey products are often very much sub-par when c ompared to those producing genuine\nhoney. These can include the over-harvesting of honey which can adversely affect the bee colonies\ninvolved and malnutrition of the colony [11].\nA robust and scalable method of honey authentication would t hus economically incentivise the pro-\nduction of genuine honey products, bring forth many interna tional development opportunities and\npotentially spark a rise in amateur beekeeping in urban area s (which would indeed aid urban bee\npopulations).\n1.2 Existing Methods of Honey Authentication\nDue to pervasiveness of fraudulent honey products, the auth entication of honey has become an active\narea of research with nations such as New Zealand, seeking to protect their valuable Manuka honey\nexports and the European Union trying to protect domestic co nsumer and producer interests [12, 13].\nCurrent honey authentication procedures include quantita tive polymerase chain reaction (qPCR)\n[12], nuclear magnetic resonance spectroscopy (NMR) [14], liquid chromatography mass spectrom-\netry (LC-MS) [12], near-infrared spectroscopy (NIR) [6], a nd microscopy (as different honeys con-\ntain visually distinct pollen from different ﬂoral sources ) [12, 15]. Other tests exist for the iden-\ntiﬁcation of speciﬁc honeys such as testing for methylglyox al and leptosperin in manuka honey\n[16, 17] though these have proven insufﬁcient due to the fact that methylglyoxal is unstable and\nits levels change over time [12]. All such procedures are con ducted in laboratories by specialists\nand the analytical tests (qPCR, NIR, NMR and LC-MS) require s pecialised equipment which can\nprove expensive. The authentication of honey through micro scopy proves difﬁcult too due to the\npollen-identifying expertise required of the operator [12 , 18].\nThe current state-of-the-art in manuka honey authenticati on makes use of four chemical markers\n(2’-methoxyacetophenone, 2-methoxybenzoic acid, 4-hydr oxyphenyllactic acid and 3-phenyllactic\nacid) and a test for the DNA of manuka pollen (qPCR) [12]. The m ethod is, however, only applicable\nto authenticating manuka honey.\n2 Method and Experiments\n2.1 Overview\nWe propose a method of honey authentication which utilises m icroscopy while at the same time\neliminating the need for an expert operator. This is achieve d through the automation of pollen\nclassiﬁcation using machine learning techniques. In this w ay, honey authentication via pollen can be\ncarried out by non-specialists and at scale (in contrast to c entralised testing facilities). Furthermore,\nour method lays the groundwork for accelerating more advanc ed quantitative approaches to honey\nauthentication using pollen.\nOur proposed pipeline comprises of two separate parts: the p ollen identiﬁcation network and the au-\nthentication network. Given an image obtained from a micros cope, the pollen identiﬁcation network\nsegments and identiﬁes the botanical origin, density and di stribution of the extracted pollen grains.\nThe outputs from the pollen identiﬁcation network are then p assed (alongside any other test results\nboth physical and chemical) into the authentication networ k which outputs a decision as to whether\nor not the honey is genuine. This modular pipeline allows the authentication network to be retrained\nfor any purpose while the pollen identiﬁcation network rema ins static. Furthermore, it allows the\nauthentication network to be replaced entirely with any oth er classiﬁer (such as a decision tree, for\nadded interpretability).\n2.2 Data Collection\nSamples of different honeys (manuka, acacia, ’Lithuanian’ , ’Black Forest’, eucalyptus melliodora\nand thyme) of equal volume were collected and spread thinly a cross glass slides. The slides were\ncovered with cover slips and put into a camera-mounted Solom ark compound bright-ﬁeld micro-\nscope for analysis at 320x zoom. The microscope was able to be controlled both manually as well\n2Figure 1: Bright-ﬁeld images of pollen from Eucalyptus mell iodora honey. The leftmost image is\ncomprised exclusively of \"round\" pollen while an example of \"triangular\" pollen can be seen towards\nthe top of the middle image.\nFigure 2: Bounding boxes over detected pollen. Air bubbles m ake up the majority of false positives\n(see the rightmost image) though this can be easily overcome through further training.\nas with stepper motors. Images were captured at 1080x1080 pi xel resolution (see Figure 1) and, for\nthe purposes of a proof-of-concept, the pollen were annotat ed and labelled into three distinct overar-\nching classes (\"round\", \"triangular\" and \"spiky\") with rec tangular bounding boxes. Approximately\n2500 pollen were imaged overall.\n2.3 Segmentation Network\nWe trained a three-class YOLOv2 network [19] to detect and se gment pollen. We used the standard\nYOLO loss function [19] with the architecture displayed in T able 1. Results are displayed in Table\n2 and Figure 2.\n2.4 Authentication Network\nWe trained a feed-forward neural network with a single hidde n layer. The network inputs were pollen\ncounts and overall pollen density (average number of pollen given an arbitrary area). The network\nwas tasked with differentiating ﬁve samples of eucalyptus m elliodora honey from ﬁve samples of\nmanuka honey. All ten samples were classiﬁed correctly.\n3 Discussion and Further Work\nIt seems, given these preliminary results, that bright-ﬁel d microscopy would prove a robust and\npowerful tool for honey authentication when augmented with our machine learning pipeline. Honey\nsamples diluted with sugar syrup can be detected from pollen density analysis and honey samples\ndiluted with cheaper honeys can be detected from pollen dist ribution comparison. Mislabelled honey\nsamples can be identiﬁed through the botanical sources of th eir pollen.\nThe proposed system, however, is unable to identify contami nation with heavy metals, pesticides\nor antibiotics and would thus need to be used in tandem with ot her chemical tests (which could be\nintegrated into the authentication network). Furthermore , the system would be unable to authenticate\n3Table 1: Pollen identiﬁcation network architecture. * deno tes a skip connection which is put through\na 64 ﬁlter 1 x 1 convolutional layer and reshaped to give a tens or of dimension 13 x 13 x 256.\nType Filters Size / Stride Output\nConvolutional 32 3 x 3 / 1 416 x 416 x 32\nMax Pool 208 x 208 x 32\nConvolutional 64 3 x 3 / 1 208 x 208 x 64\nMax Pool 104 x 104 x 64\nConvolutional 128 3 x 3 / 1 104 x 104 x 128\nConvolutional 64 1 x 1 / 1 104 x 104 x 64\nConvolutional 128 3 x 3 / 1 104 x 104 x 128\nMax Pool 52 x 52 x 128\nConvolutional 256 3 x 3 / 1 52 x 52 x 256\nConvolutional 128 1 x 1 / 1 52 x 52 x 128\nConvolutional 256 3 x 3 / 1 52 x 52 x 256\nMax Pool 26 x 26 x 256\nConvolutional 512 3 x 3 / 1 26 x 26 x 512\nConvolutional 256 1 x 1 / 1 26 x 26 x 256\nConvolutional 512 3 x 3 / 1 26 x 26 x 512\nMax Pool* 13 x 13 x 512\nConvolutional 1024 3 x 3 / 1 13 x 13 x 1024\nConvolutional 512 1 x 1 / 1 13 x 13 x 512\nConvolutional 1024 3 x 3 / 1 13 x 13 x 1024\nConvolutional 512 1 x 1 / 1 13 x 13 x 512\nConvolutional 1024 3 x 3 / 1 13 x 13 x 1024\nConvolutional 1024 3 x 3 / 1 13 x 13 x 1024\nConvolutional 1024 3 x 3 / 1 13 x 13 x 1024\nConcatenate 13 x 13 x 1280\nConvolutional 1024 3 x 3 / 1 13 x 13 x 1024\nConvolutional 60 1 x 1 / 1 13 x 13 x 60\nReshape 13 x 13 x 10 x 6\nTable 2: Pollen identiﬁcation network metrics. Results are promising even with limited training\ntime.\nPrecision Sensitivity Speciﬁcity F1\n0.663 0.914 0.761 0.769\nultra-ﬁltered honey samples where pollen is not present tho ugh this is sometimes an indicator of\nadulteration [10].\nIn order to bring the proposed system from infancy to maturit y, a more signiﬁcant pollen dataset\nwould need to be gathered. This would allow the dataset to cap ture the full diversity of pollen in\nhoney [15]. Problems may also arise from different imaging p rotocols and microscope hardware. It\nwould thus be useful to explore possible generalization met hods for robust pollen representations\nbeyond regularisation such as the adverserial training see n in DeepMedic [20].\nThe impacts of the introduction of our system to the honey ind ustry and regulators would likely\ninclude lower capital and labour costs for honey testing and , as a result of this, the development of\nmore decentralised honey authentication. Nevertheless, i n order for any form of honey authentica-\ntion to be effective, robust regulatory frameworks must als o be put in place and this, of course, very\nmuch relies on governments and policy-makers.\n4 Conclusions\nWe have proposed a new spin to an old approach to honey authent ication capable of detecting diluted\nand mislabelled honey through quantitative means and at a lo wer labour and capital cost. We have\npresented a proof-of-concept for the proposed solution wit h promising results forming a strong case\n4for further investigation using more state-of-the-art tec hniques. Our system makes use of a modular\npipeline with a separate ﬁnal authentication network and ca n therefore be integrated with existing\nauthentication processes.\nIf developed further, our system will likely prove a powerfu l tool in the ﬁght against fraudulent\nhoney, an industry which has cost livelihoods, consumer con ﬁdence and the environment.\n5 Acknowledgements\nWe thank Mischa Dohler, Sagar Joglekar, Jung Wing Wan, Dhruv Sengupta and Angus Thompson\nfor proofreading our work at incredibly short notice. We tha nk Elena Sinel for making us aware that\nN(eur)IPS was still open for submissions in September.\nReferences\n[1]Codex alimentarius . Food and Agriculture Organization of the United Nations, 2 001.\n[2] Susan Givens Bell. The therapeutic use of honey. Neonatal Network , 26(4):247–251, 2007.\ndoi: 10.1891/0730-0832 .26.4.247.\n[3]EU Honey Market Situation in 2017 . 2017. URL https://ec .europa.eu/agriculture/\nsites/agriculture/files/honey/market-presentation-h oney_en.pdf.\n[4] Bees for development. URL http://www .beesfordevelopment .org/ .\n[5] Jeffrey C. Moore, John Spink, and Markus Lipp. Developme nt and application of a database\nof food ingredient fraud and economically motivated adulte ration from 1980 to 2010. Journal\nof Food Science , 77(4), 2012. doi: 10 .1111/j.1750-3841 .2012.02657.x.\n[6] Lanzhen Chen, Xiaofeng Xue, Zhihua Ye, Jinghui Zhou, Fan g Chen, and Jing Zhao. Determi-\nnation of chinese honey adulterated with high fructose corn syrup by near infrared spectroscopy.\nFood Chemistry , 128(4):1110–1114, 2011. doi: 10 .1016/j.foodchem .2010.10.027.\n[7] Simon Usborne. The manuka honey scandal, Jul 2014. URL https://www .independent .co.\nuk/life-style/food-and-drink/features/the-manuka-ho ney-scandal-9577344 .\nhtml .\n[8] Jessica Leeder. Honey laundering conspiracy is largest food fraud in u.s. history, May 2011.\nURLhttps://www .huffingtonpost .com/2011/01/07/honey-laundering-conspira_\nn_805707 .html .\n[9] Jon Swaine. ’honeygate’ uncovered in us sting, Feb 2013. URLhttps://\nwww.telegraph .co.uk/news/worldnews/northamerica/usa/9886508/\nHoneygate-uncovered-in-US-sting .html .\n[10] Shivana Inalsingh. The business of honey: Rebuilding t he apiculture industry of trinidad &\ntobago. American College of Healthcare Science , 2014.\n[11] Christine E. Cairns, Rogel Villanueva-Gutierrez, Suz anne Koptur, and David B. Bray. Bee\npopulations, forest disturbance, and africanization in me xico. Biotropica , 37(4):686–692, 2005.\ndoi: 10.1111/j.1744-7429 .2005.00087.x.\n[12] Criteria for Identifying Manuka Honey . New Zealand Ministry for Primary Industries, 2017.\n[13] Coordinated Control Plan to Establish the Prevalence of Fra udulent Practices in the Marketing\nof Honey . European Commission, 2015.\n[14] Giangiacomo Beretta, Enrico Caneva, Luca Regazzoni, N azanin Golbamaki Bakhtyari, and\nRoberto Maffei Facino. A solid-phase extraction procedure coupled to 1h nmr, with chemo-\nmetric analysis, to seek reliable markers of the botanical o rigin of honey. Analytica Chimica\nActa, 620(1-2):176–182, 2008. doi: 10 .1016/j.aca.2008.05.025.\n[15] J. M. Kale Sniderman, Kia A. Matley, Simon G. Haberle, an d David J. Cantrill. Pollen analysis\nof australian honey. Plos One , 13(5), 2018. doi: 10 .1371/journal .pone.0197545.\n[16] Stefanie Oelschlaegel, Margit Gruner, Pang-Ning Wang , Anja Boettcher, Isabelle Koelling-\nSpeer, and Karl Speer. Classiﬁcation and characterization of manuka honeys based on phe-\nnolic compounds and methylglyoxal. Journal of Agricultural and Food Chemistry , 60(29):\n7229–7237, Nov 2012. doi: 10 .1021/jf300888q.\n5[17] Yoji Kato, Rie Fujinaka, Akari Ishisaka, Yoko Nitta, No ritoshi Kitamoto, and Yosuke Takimoto.\nPlausible authentication of manuka honey and related produ cts by measuring leptosperin with\nmethyl syringate. Journal of Agricultural and Food Chemistry , 62(27):6400–6407, 2014. doi:\n10.1021/jf501475h.\n[18] Sónia Soares, Joana S. Amaral, Maria Beatriz P.p. Olive ira, and Isabel Mafra. A compre-\nhensive review on the main honey authentication issues: Pro duction and origin. Comprehen-\nsive Reviews in Food Science and Food Safety , 16(5):1072–1100, 2017. doi: 10 .1111/1541-\n4337.12278.\n[19] Joseph Redmon and Ali Farhadi. Yolo9000: Better, faste r, stronger. 2017 IEEE Conference on\nComputer Vision and Pattern Recognition (CVPR) , 2017. doi: 10 .1109/cvpr .2017.690.\n[20] Konstantinos Kamnitsas, Christian Baumgartner, Chri stian Ledig, Virginia Newcombe, Joanna\nSimpson, Andrew Kane, David Menon, Aditya Nori, Antonio Cri minisi, Daniel Rueckert, and\net al. Unsupervised domain adaptation in brain lesion segme ntation with adversarial networks.\nLecture Notes in Computer Science Information Processing i n Medical Imaging , page 597–609,\n2017. doi: 10 .1007/978-3-319-59050-9_47.\n6"}
{"date": "2024-01-04-22-29", "error": false, "url": "PDF", "text_blocks": "Victor Davis  \nTypes, T okens, and Hapax es: A New He ap's Law  \nAbstrac t  \nHeap 's Law1 states that in a large enough te xt corpus, the n umber of types as\na func tion of tok ens gro ws as  for some free parameters .\nMuch has been writ ten23456 about ho w this result and various\ngeneralizations can be deriv ed from Zipf 's Law7. Here w e deriv e from ﬁrst\nprinciples a c ompletely no vel expression of the t ype- token curve an d prove\nits superior ac curacy on real te xt. This e xpres sion natural ly gen eralizes to\nequally ac curate estimates f or counting hapa xes an d higher -legomena.\nIntroduc tion  \nZipf 's Law is usually f ormulated7 as Freq  1/Rank, generaliz ed b y raising\nRank to an e xponent . This is benchmark ed against real te xt and sh own to\nbe curiously ac curate f or corpora of var ying si zes but exhibiting a f at tai l.\nTheref ore it perf orms most poorly on rare w ords, which contribute the m ost\nto the t ype-tok en cur ve. The c ommon interpretati on is that an y inaccurac y\nin modeling a t ype-tok en gro wth cur ve can b e explained away by thi s fat tai l\nin which the unpredic tabilit y of the frequenc y of rare w ords introduces noise\ninto an o ther wise c orrec t signal. This paradig m is completely false. We sho w\nthat Zipf 's Law can be ref ormulated to model the f requencies of rare w ords\nas ac curately as c ommon ones and that this ref ormulation leads to a simple,\nintuitiv e derivation of a logarithmic ( not exponential) t ype-tok en gro wth\ncurve.Keywords  \nTokens: Instanc es of w ords in a te xt, elements of the  corpus i n which words\nare c onsidered an ordered list. (Using \"w ords \" and \"tokens\" interchangeab ly.)\nTypes : Distinc t words of a te xt, elements of the le xicon/vocabulary or the\nsize of the set of tok ens. (Using \"distinc t words\" and \"t ypes \"\ninterchangeably .)\nHapax es: Types that oc cur e xactly onc e in a c orpus.\nDis, T ris, T etrakis, P entakis, -Legomena : Types that oc cur e xactly \ntimes in a c orpus.\n-corpus : A te xt corpus c onsisting of  tokens and  types.\nOptimum Sample : A te xt corpus e xhibiting a perf ect Zipf distrib ution.\nPerfect Zipf Distribution : A w ord frequency distribution f ollowing Zipf 's\nlaw literally and perf ectly, reformulated to di rectly esti mate the n umber of\nrare w ords. (Deﬁned in more detail later .)\nHypo thesis  \nFor a te xt corpus c onsisting of  tokens and  types, randomly sampling \ntokens of that c orpus yields  types, and the e xpec ted value of  is\ngiven b y , parametriz ed b y , the siz e of an op timum sample.The proc edure f or ob taining the parameters  is described in the\n\"Results\" sec tion later , equations  and , respec tively.\nMethods  \nFor some small , construc t a -corpus b y collec ting e very word that\noccurs exactly   times. This mini-c orpus, a sub-selec tion of t he w hole, has a\nperfectly unif orm w ord frequency distributio n, a te xt consisting of  total\nwords (tok ens):  distinc t words (t ypes) each repeating e xactly  times. What\nis , the e xpec ted number of t ypes in a random s election of  words\nout of this mini-c orpus? If sampling sequent ially without repl acement, the\nexpec ted value is the partial sum of the probab ility at eac h step o f drawing a\nnew type.\nSuppose  tokens are drawn at random without replac ement, resul ting in \ntypes. There are then  tokens lef t to draw ,  of which are of a\ntype no t yet drawn. Thus,\nSubstituting the actual  number of t ypes drawn, , for the expected  number of\ntypes drawn, , we hav e a recursiv e expression f or the gro wth of the\ncurve  starting at .\nThis recursion perf orms quite w ell with real d ata. Consider a shuf ﬂed deck of\ncards, analogous to either a - or -corpus, depending whether\nsuits or valors are c onsidered \"t ypes. \"We can use calculus to deriv e a non-recursiv e version of this function. Since\nthe derivativ e is appro ximately equal to the v ertical distan ce between\nsuccessiv e elements in the series, w e can re write  and integrate.\nUsing  as a boundar y condition, w e ﬁnd , giving:\nAgain, w e ﬁnd a near -perf ect match betw een the d iscrete val ues c alculated\nby recursing and the c ontinuous values giv en b y . Near  perf ect because\nthe discrete case (ac tual realit y) eff ectively st opped  the i ntegral  limit\napproaching z ero onc e . Thus,  is an analy tical estimate of \nsmoo thing out the disc ontinuities f ound in a  real  deck of cards.Text Corpora  \nA -corpus can be partitioned into a number of -mini-c orpuses,\nand the e xpec ted t ype-tok en cur ve of the who le can be gotten by sum ming\nover the individual parts. Start b y partitioning the c orpus i nto decks: al l\nhapax es into the ﬁrst deck, all dis legomena in to the sec ond deck, tris into\nthe third deck, etc. The th deck shall be a -mini-c orpus, the whole\ncorpus enc oded b y some v ector . (Call the \" zeroth\ndeck\" the null set f or no w, for  number of t ypes oc curring e xactly z ero\ntimes in the whole c orpus, which will c ome in han dy sho rtly.)\nThe whole c orpus c onsists of all these decks ran domly shuf ﬂed together .\nSampling  tokens should yield on av erage  tokens from the th deck.\nThe number of t ypes yielded from each deck i s theref ore .\nSubstitute this into  and sum o ver all decks.\nAs for the bounds on the summation, w e can  consider  a ﬁnite v ector in\ninﬁnite-dimensional spac e with z eroes imputed  into missing indexes\n(numbers  for which no w ords oc cur exactly   times). This e xpression , as\nwe'll see later in the \"R esults\" sec tion, perf orms nearly perf ectly on real  data.\nWe can also re write it as an inﬁnite series o ver the i nterval  by\nsubstituting  the proportion of the c orpus sampled rather  than  the\nraw tok en count.What does  really mean ? What happens when w e sample  tokens at\nrandom, or some proportion  of the c orpus? Choosing a sample siz e of \n gives a permutation of the original c orpus, a nd it's easy to  see f rom \n that  as e xpec ted, i.e. all t ypes are drawn. Sampling so me\nproportion  of the c orpus, w e expec t  types to be drawn, and \ntypes not to be drawn. What is the e xpec ted value of the l atter? For the\nhapax es, the probabilit y of not drawing each tok en is , so the e xpec ted\nnumber of hapax es not drawn is . The probabilit y of not drawing\nboth  instanc es of each dis legomenon is  so the e xpec ted number of\ndis legomena not drawn is . Continuing this argument, w e deﬁne \n, the e xpec ted number of t ypes not drawn when sampling proportion \nof the c orpus:\nIt can be seen that  is just a way of re writing  given this ne w intuition.\nBut let 's go further . How many hapax es can be e xpec ted when sampling\nproportion  of the c orpus? The e xpec ted number of e xisting hapax es drawn\nis . But a hapax will be created  in the sample if one instanc e of a dis\nlegomenon is drawn but no t the o ther. We should expec t  to be\ncreated this way . Lik ewise, w e expec t to create a hapax i n our sam ple by\ndrawing only one of the three instanc es of each tris legomenon , resul ting in \n created this way . In general, using the shorthan d ,\nThere is a beautiful way of visualizing this as a matrix transf ormation acting\non  involving P ascal' s Triangle. Sinc e each of the c olumns sum  to , it's easy\nto pro ve that bo th the input v ector  and the resultant v ector  sum to .\nThe equation  abo ve expresses the ro w sums.(If the idea of inﬁnite matric es doesn't sit w ell, rem ember  is always ﬁnite\nin prac tice.) No tice  can be e xpressed in terms of the th derivativ es of \nfor :\nBy no w we've achie ved three results, having no t yet m ade a si ngle em pirical\nassump tion about the w ord frequency distrib ution of a corpus.  Any type-\ntoken system describable in terms of the e volution of some  follows these\nrules.\n1. Equation  gives an algorithmic approach to predic ting -\nlegomena c ounts when sampling a c orpus. U sing the o bserved \ncounts from the whole  corpus as input, the w ord frequency  \ndistribution of any sample can be simulated b y construc ting  \nand transf orming .\n2. Any func tion such as Heap 's Law which appro ximates the t ype-\ntoken gro wth cur ve can be generaliz ed via  to mak e testable  \npredic tions f or -legomena c ounts as w ell.\n3. If  can be appro ximated b y a series and  converges on some  \nanaly tic func tion, then  gives analy tic func tions f or -\nlegomena as w ell.\nCan  be appro ximated b y a series? In real te xt, do the tab ulations of -\nlegomena ac tually f ollow some regular , enum erati ve pat tern ?\nZipf 's Law  \nSuppose that f or a giv en -corpus there e xists a c orresponding\noptimum sample -corpus f ollowing a perfect Zipf distribution . If the\noriginal c orpus is \"too big\" then some numbe r of randomly sel ected tokens \n will produc e a sub-selec tion of te xt exhibiting Z ipf's Law. If the\noriginal c orpus is \"too small\" then it can be t hought o f as a sub -selection of\nsome larger c orpus c onsisting of  tokens e xhibiting Zipf 's Law . (Of\ncourse, some c orpora may be \"just right \" and  .)Deﬁne a perfect Zipf distribution  as follows: For some -corpus with a\nrank ed w ord frequency distribution , the e xpec ted number of\ntypes repeating  or more times  is roughly equal to .\nAlternativ ely, there e xists about  types repeating  or more times.\n\"Roughly\" and \" about \" to allo w for normal sta tistical noise in the sti ll\n\"perfect\" sample.\nCorollaries:\n the e xpec ted number of t ypes repeating betw een  and  \ntimes is \nThe e xpec ted number of t ypes repeating f ewer than   times is \nNo t ypes oc cur e xactly z ero times: \n the e xpec ted number of t ypes repeating exactly   times, or the  \nexpec ted number of -legomena (f or ) equals \nThe e xpec ted proportions  of -legomena are \nThis distribution is already normaliz ed: \nThe e xpec ted frequency of the most c ommon  word is \nThe e xpec ted frequency of the th most c ommon w ord is \nFreq  1/RankThis ref ormulation of Zipf 's Law is prac tically eq uivalent to the o riginal,\nwith the cav eats that (a) f or high ranks (rare w ords) we round down  to the\nnearest integer to ob tain the e xpec ted freque ncy, and (b) the to tal number of\ntypes is equal to the frequency of the c ommon est w ord. (So, curiously, there\nis one \"the \" for each v ocabular y word in the le xicon.) This leaves us w ith a\nspeciﬁc predic tion f or the c ounts of rare w ords ( -legomena f or lo w ). The\nexpec ted number of hapax es, dis, tris, and hi gher -legomena, f or  is\ngiven b y:\nSubstituting  into  abo ve, and taking ,\nIt can be sho wn that  converges on . Taking suc cessiv e derivativ es,\nper , we no w hav e expressions no t just f or the nu mber of types w ith\nrespec t to tok ens, but also hapax es and highe r -legomena:\nResults  \nThe King James Bible is a -corpus. The most c ommon w ord\n\"the\" appears  times (no t ), and % of the t ypes are\nhapax es (no t %). It is no where near an op timum sample, s o how do we ﬁnd\na suitable ? The proportion of hapax es is a decreasing f unction,\nstarting at , falling to , and c ontinuing to fall as  goes toTOKENS TYPES HAP AX TYPES PRED HAP AX PRED\n4,042 993 632 734 535\n105,092 5,766 2,482 5,525 2,726\n206,142 7,781 3,124 7,561 3,310\n307,192 9,075 3,531 8,946 3,633\n408,242 10,087 3,750 10,010 3,846\n509,292 10,898 3,881 10,878 4,001\n610,342 11,664 4,050 11,613 4,120\n711,392 12,303 4,213 12,252 4,215\n812,442 12,855 4,283 12,817 4,294\n913,492 13,314 4,353 13,324 4,359\n1,010,654 13,769 4,414 13,767 4,413inﬁnit y. We can model this b y expressing  as a proportion of  to\nobtain:\nIn the limit,  as e xpec ted, e ven though the func tion is\nundeﬁned at those points. Using a binar y sea rch algorithm, we ﬁnd that \n. Could this mean the Bible is ten times \"too l arge \" to\nexhibit Zipf 's Law? T aking  and scaling  such that \n, we ﬁt  to our sample c orpus using op timum sample\nparameters . Calculating , we hav e:\nObser ved vs P redic ted: King James Bible  TOKENS TYPES HAP AX TYPES PRED HAP AX PRED\n33 25 23 33 27\n858 439 324 424 304\n1,683 704 491 678 457\n2,508 909 587 882 571\n3,333 1,066 653 1,057 662\n4,158 1,211 740 1,212 739\n4,983 1,366 809 1,352 805\n5,808 1,495 878 1,480 864\n6,633 1,604 931 1,598 916\n7,458 1,707 953 1,708 963\n8,283 1,812 1,010 1,811 1,005\nWilliam Blak e's Poems  is a -corpus. The most c ommon w ord\n\"the\" appears  times (no t ) and % of its t ypes are\nhapax es. Using a binar y search, w e ﬁnd that , making\nPoems  \"too small\" b y half . Using the same proc edur e as ab ove, we ﬁnd \n.\nObser ved vs P redic ted: William Blak e's Poem s  TITLE HEAPS SERIES MODEL\nMob y Dick b y Herman  \nMelville 1851173,272 15,854 2.66% 0.23% 0.23%\nLeav es of Grass b y Walt \nWhitman 1855144,542 13,845 2.50% 0.29% 0.35%\nThe Ball and The Cross b y G .  \nK . Chesterton 190991,990 8,714 2.27% 0.36% 0.39%\nThe Wisdom of Father Bro wn \nby G . K . Chesterton 191479,540 7,980 2.44% 0.41% 0.43%\nParadise Lost b y John Milton  \n1667113,779 11,666 2.23% 0.31% 0.47%\nThe Man Who W as Thursday  \nby G . K . Chesterton 190869,764 6,807 2.17% 0.40% 0.59%\nStories to T ell to Children b y \nSara C one Br yant 191826,223 3,108 2.56% 0.51% 0.68%\nRepeating the proc edure, w e ob tain values f or  that estimate t ypes,\nhapax es, and higher -legomena f or a number of diff erent books. W e'll\nevaluate the model ﬁt using roo t mean square erro r as a perc ent of observed\ntypes. Belo w are the ﬁt ting errors f or real data.  The ﬁ t for  using ac tual -\nlegomena c ounts as the c oefﬁcients giv es a go od baseline for measuri ng the\nmodel, sinc e it doesn't assume Zipf 's Law . Maki ng the l eap f rom  to \nrequires the assump tion of the e xistenc e of a n optimum sam ple following a\nperfect Zipf distribution, an assump tion that  appears to  be more ac curate i n\nsome cases, lik e Melville 's Moby D ick, and less ac curate in o thers, lik e\nShak espeare 's Julius C aesar . Still, Heap 's Law is c onsistently ac curate on ly to\nwithin %, while the logarithmic func tion deriv ed abo ve is nearly always\naccurate to within %.\nRMSE % C omparison f or Various Books  TITLE HEAPS SERIES MODEL\nPoems b y William Blak e 1789 16,121 2,574 2.69% 0.72% 0.74%\nSense and Sensibilit y by Jane  \nAusten 181138,414 3,817 2.63% 0.38% 0.78%\nAlice ' s Adv entures in  \nWonderland b y Lewis Carroll  \n186518,864 2,275 2.44% 0.60% 0.79%\nThe P arent ' s Assistant , b y \nMaria Edge worth67,166 5,716 2.43% 0.34% 0.80%\nThe T ragedie of Hamlet b y \nWilliam Shak espeare 1599182,050 13,320 1.07% 0.42% 0.97%\nThe Adv entures of Buster  \nBear b y Thornton W . Burgess  \n19207,158 1,127 2.75% 0.71% 0.99%\nPersuasion b y Jane Austen  \n181848,342 4,393 2.23% 0.40% 1.00%\nThe T ragedie of Macbeth b y \nWilliam Shak espeare 1603106,245 9,465 1.50% 0.52% 1.02%\nEmma b y Jane Austen 1816 57,337 4,528 2.30% 0.36% 1.07%\nThe T ragedie of Julius Caesar  \nby William Shak espeare 159964,786 5,838 1.51% 0.54% 1.09%\nThe King James Bible 97,084 5,312 2.25% 0.28% 1.13%\nDiscussion  \nIt's worth reinf orcing that Zipf 's Law is only ac curate w hen appl ied to a\ncertain op timum sample siz e of a giv en corpus.  Smaller sam ples won't follow\nZipf 's Law , but as te xt ac cumulates, the samp le will reac h a phase at w hich it\nexhibits Zipf 's Law peculiarly w ell. As te xt continues to  accumulate, the\npattern deteriorates in the opposite direc tion. The logarithmic functions \n accurately model this behavior e ven if the y can't explain the m otivation\nfor it. But it has to be stressed that Zipf 's Law i s not a pat tern ac curately\ndescribing all te xts; it is bet ter thought of as describing a phase te xt passes\nthrough as it ac cumulates.\nThis phase is the point at which (a) there are appro ximately as m any\ninstanc es of the most c ommon w ord (usually \"the \") as there are d istinct\nwords in the v ocabular y, and (b) the proporti ons of hapax es, dis, tris, etc\nlegomena with respec t to the number of t ypes is roughl y \n. It should no t be e xpec ted that (a) and (b) always\nhold, and that some te xts f ollow this more ac curatel y than  others.  Our\nhypo thesis is that it seems to be the case that all texts f ollow (a) and (b)\npeculiarly w ell at some op timum sample siz e, and that b y discovering thi s\noptimum, ac curate predic tions can be made f or how these pro portions\nevolve as the sample siz e is varied.\nConclusion  \nMost inv estigations of Zipf 's and Heap 's resp ective Laws and thei r inter-\nrelationship tolerate a c onspicuous degree of  erro r when appl ied to real  text.\nThis may reﬂec t an implicit bias that these \"l aws\" are m ere c uriosities of\nnature, that no model should  be able to ﬁt c ogent, rational human language\nto a tidy physics equation. Shockingly , the disc overy of the f ormulas ab ove\nand their ac curate ﬁt to real data imply that, f ar from being mere c uriosities,\nZipf 's Law and its c orresponding derivations f or esti mating types,  hapax es, \n1. https://dl.acm.org/citation.cfm?id=539986  Heaps, H S 1978 Information R etrie val: C omputational and  \nTheoretic al Aspects  (Academic P ress) ↩ ↩\n \n2. http://iopscienc e.iop.org/article/10.1088/1367 -2630/15/9/093033  Font -Clos, Franc esc 2013 A scaling law  \nbeyond Zipf 's law and its relation to Heaps' law  (New Journal of Physics 15 093033) ↩ ↩\n \n3. http://iopscienc e.iop.org/article/10.1088/1367 -2630/11/12/12301 5 Bernhardsson S, da R ocha L E C and  \nMinnhagen P 2009 The meta book and size-dependent properties of written language  (New Journal of Physics 11  \n123015) ↩ ↩\n \n4. http://iopscienc e.iop.org/article/10.1088/1742-5468/2011/07/P07013  Bernhardsson S, Ki Baek and  \nMinnhagen 2011 A parado xical propert y of the monk ey book  (Journal of Statistical Mechanics: Theor y and  \nExperiment, V olume 2011) ↩ ↩\n \n5. http://milicka.c z/kestaz eni/t ype-tok en_relation.pdf  Milička, Jiřı́  2009 Type-tok en & Hapax -token R elation: A  \nCombinatorial Model  (Glo ttotheor y. International Journal of Theoretical Linguistics 2 ( 1), 99–110) ↩ ↩\n \n6. https://w ww.nature.c om/articles/srep00943  Petersen, Ale xander 2012 Languages c ool as the y expand:  \nAllometric sc aling and the decreasing need for ne w words  (Scientiﬁc R eports v olume 2, Article number: 943) ↩ ↩\n \n7. http://dx.doi.org/10.1037/h0052442  Zipf , George 1949 Human behavior and the principle of least effort  \n(Reading: Addison- Wesley) ↩ ↩ ↩\n \n8. www.hup.har vard.edu/catalog.php?isbn=9780674434929  Zipf , George 1932 Selectiv e studies and the principle  \nof relativ e frequenc y in language  (Cambridge: Har vard Univ ersit y Press) ↩\n \n9. https://catalog.hathitrust.org/R ecord/000359461  Zipf , George 1935 The psy cho-biology of language: A n \nintroduction to dynamic philology  (Boston: Mifﬂin C ompany) ↩and higher -legomena must be more fundamental to the nature of language\nthan w e giv e it credit. It 's still an open questi on why Zipf 's Law seems to\nhold. T aking it in a v ery literal f ormulation as an  axiom, accurate pred ictions\ncan be made about real te xt, bolstering the id ea that something  fundamental\nmust be going on, and Zipf 's original obser vation must b e the i nevitable\ncumulativ e eff ect of some deeper , underlying  information-theo retic propert y\nof human language.\nCorrespondenc e Address  \nVictor Davis victor.davis.us@member .mensa.org\nReferenc es  \n| 1|2|3|4|5|6|7|8|9|10|11|12|13|14| \n10. https://w ww.journals.uchicago.edu/doi/abs/10.1086/364570  Herdan, Gustav 1960 Type-tok en mathematics  \n(The Hague: Mouton) ↩\n \n11. https://dl.acm.org/citation.cfm?id=325476  Bae za-Yates, Ricardo 1997 Block A ddressing Indic es for  \nAppro ximate T ext R etrie val (Journal of the American Societ y for Inf ormation Scienc e, v.51 n.1,  p.69-82, Jan. \n2000) ↩\n \n12. http://dx.doi.org/10.1155/2012/480196  Chen, Y anguang 2012 Zipf ’s law , Hierarchic al Structure, and  \nShufﬂing-C ards Model for Urban De velopment  (Discrete Dynamics in Nature and Societ y, Volume 2012) ↩\n \n13. http://iopscienc e.iop.org/article/10.1088/1367 -2630/13/4/043004  Seung, Ki Baek 2011 Zipf's law unzipped  \n(New Journal of Physics 13 043004) ↩\n \n14. https://doi.org/10.1016/j.physa.2011.05.003  Eliazar , Iddo 2011 The grow th statistics of Zipﬁan ensembles:  \nBeyond Heaps’ law  (Physica A, V olume 390, Issue 20) ↩"}
{"date": "2024-01-04-22-29", "error": false, "url": "PDF", "text_blocks": "Jerdack et al.  Understanding What Drives  Bitcoin  Trading  Activities  \n \n \n \n DECISION SCIENCES INSTITUTE  \nUnderstanding What Drive s Bitcoin  Trading  Activities  \n \nNatalia Jerdack  \nFarmer School of Business, Miami University  \nEmail: jerdacn2@miamioh.edu   \n \nAkmaral Dauletbek  \nFarmer School of Business, Miami University  \nEmail: dauleta@miamioh.edu   \n \nMeredith Divine  \nFarmer School of Business, Miami University  \nEmail: divinemn@miamioh.edu   \n \nMichael Hult  \nFarmer School of Business, Miami University  \nEmail: hultm@miamioh.edu   \n \nArthur Carvalho  \nFarmer School of Business, Miami University  \nEmail: arthur.carvalho@miamioh.edu   \n \nABSTRACT  \n \nCryptocurrencies  have  gained  tremendous popularity  over the past few years. The purpose of this \nstudy  is to try to understand the factors  that are driving cryptocurrency -related trading activit ies. \nFocusing on the well -established cryptocurrency called Bitcoin, we find that online search \npopularity  and th e volume of trade  in unrelated stock markets positively and negatively , \nrespectively,  influence Bitcoin trading volume . We also find no statistical evidence that the \nunderlying sentiment behind relevant financial news influence Bitcoin trading volume . We believe \nthese results might be of great value to investors interested in cryptocurrencies and might \ninstigate further research on this topic.  \n \nKEYWORDS : Bitcoin, Crypt ocurrency, Regression  \n \nINTRODUCTION  \n \nThe year of 2009 saw the birth of a revolutionary concept, namely the online, fully decentralized \ncurrency called Bitcoin  (Nakamo to, 2008) . As a payment system, the transactions involving \nbitcoins are recorded in a public, distributed ledger that requires no intermediaries such as a \ncentral bank.  That distributed ledger, called Blockchain , is heavily dependent on concepts and \nideas from the cryptography field, which makes it a member of a new family of information \ntechnologies called cryptotechnologies.  Due to a similar reason , Bitcoin is  now considered  a \nmember  of a family of currencies called cryptocurrenc ies. \n \nSince its first release, Bitcoin has gained tremendous popularity over the years and exploded in \nits valuation . For example,  Figure 1 shows the value of one Bitcoin in US dollar  from July 18th, \n2010 to May 15th, 2018. One can immediately see that there was a huge spike in prices in 2017 . \nIn particular, Bitcoin price peaked at $ 19 ,343.04 on December 16th, 2017.  Jerdack et al.  Understanding What Drives  Bitcoin  Trading  Activities  \n \n \n \n Figure 1. Bitcoin Prices  in US Dollar  from July 18th, 2010 to May 15th, 2018.  \n \nFollowing the success of Bitcoin, several other cryptocurrencies raised money through initial coin \nofferings (also known as ICOs) and are now  publicly available for trading. As of May 18th, 2018, \nthe website coinmarketcap.com  listed a total of 1,593 cryptocurrencies having a combined market \ncap of $369,691,771,684. In all fairness, after the current hype around cryptocurrencies dies down, \nit is unlikely that all those cryptocurrencies wil l stand the test of time. The question that arises is \nthen: which cryptocurrencies will survive? Answering this question is crucial for low -risk-tolerance \ninvestors and/or investors considering long -term cryptocurrency investment strategies.  \n \nOne way of de termining  whether a certain cryptocurrency will stand the test of time  is by looking \nat trading volume. In particular, one can  take inexistent or very low trading activ ities as a proxy \nfor the lack of interest in the underlying cryptocurrency . In this paper, we try to understand some \nof the factor s that might influence  trading activities associated with cryptocurrencies. Specifically, \nwe focus on the potential factors that drive Bitcoin trading volume  due to the same being currently \nthe most wel l-established cryptocurrency.  \n \nSince cryptocurrencies are  online coins , it might be  just natural that trading volume is partially \ndriven by  the online popularity  of a cryptocurrency . Our proxy for online popularity is the frequency \nwith which online searches include the name of a  cryptocurrency. As we elaborate on later, we \nuse data from Google Trends t o measure search frequency.  That said , our first hypothesis is:   \n \nHypothesis #1 : online search frequency  positively correlates with  Bitcoin  trading volume. \n \nWe next hypothesize that other trading activities might influence the volume  of cryptocurrency -\nrelated  trade . For example, one can argue that when a certain market (e.g., a stock market) is \nattractive, then less resources might be allocated to other trading activities. To test this idea, we \nmeasure how  the trading volume associated with the stock market index known as the Dow Jones \nIndustrial Average ( DJIA ) influences Bitcoin trading volume . Our second hypothesis is then:  \n \nHypothesis #2 : the trading v olume in non -cryptocurrency financial markets negatively correlates \nwith Bitcoin  trading volume . \n 02000400060008000100001200014000160001800020000US DollarJerdack et al.  Understanding What Drives  Bitcoin  Trading  Activities  \n \n \n \n Our last hypothesis  relates to the influence of financial news on the trading volume concerning  \ncryptocurrencies.  It comes as no surprise that financial news  heavily influence investors ( Barber \n& Odean,  2007 ; Fang & Peress, 2009 ; Engelberg & Parsons, 2011 ). Recent financial news have \nmixed feelings when it comes to cryptocurrencies. On the one hand, there are  positive news \naround the acceptance of cryptocurrencies and their valuation gains . On the other hand , there \nare also several reports on how the anonymity aspect of some  cryptocurrencies are making them \nvery suitable to  be used for the payments of  illegal actives. Since the sentiment behind the \nunderlying  news is mixed  and, generally speaking , cryptocurrencies are growing  in value, we then  \nhypothesize that financial news have no influence on the trading volume of cryptocurrencies . To \ntest this hypothesis, we analyze how t he sent iment behind the news published on the Facebook \npage called Bitcoin  Chart  affects Bitcoin  trading volume.  Our formal  hypothesis is then:   \n \nHypothesis #3 : the sentiment behind cryptocurrency -related news does not  significantly  affect \nBitcoin  trading volume . \n \nIn the following section, w e explain  how we collect  the data relevant to  the testing of the above \nhypotheses . This is followed by an explanation of how we analyze the collected data. We finally \nconclude by elaborating on the  implications of the obtained results  and how they relate to the \nrelevant literature .  \n \nDATA COLLECTION AND PREPARATION  \n \nThe central  variable in our study , henceforth called Bitcoin_Volume , measures Bitcoin trading \nvolume. We collected its values  from the website blockchain .info (Blockchain, 2018) . The \ncollected data covers the period of time  between July 24th, 2017 and April 19th, 2018, which \ncaptures the moment in time when Bitcoin exploded in valuation (see Figure 1  and 2 ). The \nresulting 270 observations correspond to the number of daily confirmed Bitcoin transactions.  To \ntest Hypothesis 1, 2, and 3, we also collected data from Google Trends,  DJIA, and Facebook , as \nwe explain next.  \n \nFigure 2. Number of Daily Confirmed Bitcoin Transactions.  \n \n \n 050000100000150000200000250000300000350000400000450000500000Jerdack et al.  Understanding What Drives  Bitcoin  Trading  Activities  \n \n \n \n  \nGoogle Trends  \n \nThe next source of data is Google Trends ( trends.google.com ). The purpose of the collected \nvariable, henceforth called Gtrend , is to determine the online popularity of the term “Bitcoin” over \ntime. Specifically, Google Trends determines the “interest over time” for a specific search term by \ndividing the number of searches of that term by the total number of all searches do ne on Google \nat a given point  in time . The resulting numbers are then scaled on a range of 0 to 100 based on \nthe term’s proportion to all searches on all topics. In our work, we consider daily searches done  \nby users in the United States of America. That sa id, we obtained 270 values between 0 and 100 \nthat correspond to how popular the term ‘Bitcoin’ was during the period of time between July 24th, \n2017 and April 19th, 2018. Figure 3 illustrates the obtained data.  \n \nDow Jones Industrial Average  \n \nThe next variab le we collected , henceforth  called DJIA_Volume , is about  values representing \ndaily trading volume s associated with the Dow Jones Industrial Average (DJIA) index. This data \nset was collected from Yahoo Finance (Yahoo, 2018) . DJIA determines  how 30 major  American \ncompanies have traded on the NASDAQ and NYSE stock markets. Such an index includes ve ry \ndiverse companies, e.g., Apple, Boeing, Caterpillar, Goldman Sachs, IBM, Nike, Walmart, among \nothers. Since the underlying stock markets are officially closed on the weekends, we were only \nable to collect 187 values during the period of time between July 24th, 2017 and April 19th, 2018.  \n \nFacebook  \n \nWe finally  collected financial news related to Bitcoin published on the Facebook public page  called \nBitcoin Chart  (Facebook 2018) . At the time of writing, that page has the highest  number of \nfollowers among open Bitcoin pages on Facebook with a total of 402,562 followers.  In total, w e \ncollected 694 Bitcoin -related snippets  across 229  different days  between July 24th, 2017 and April \n19th, 2018 . After collecting the snippets , we estimated the sentiment  behind the underlying texts \nby using  a service from the IBM Watson  family (Ferrucci  et al. , 2010; Ferrucci et al. , 2013)  called \nNatural Language Understanding . Each resulting  sentiment  score  ranges from -1 to 1 ( i.e., Figure 3. Google Trends Regarding the Term ‘Bitcoin’.  \n0102030405060708090100Jerdack et al.  Understanding What Drives  Bitcoin  Trading  Activities  \n \n \n \n negative s entiment to positive sentiment). Since m any snippets  were posted on the same day,  \nwe averaged the sentiment scores of all snippets published in a day  so as to have a single score  \nper day.  In our analysis, we denote the resulting variable by Scores . Figure 4 plots a histogram \nof the obtained sentiment scores. One can immediately see that most snippets  associated with \nBitcoin are either negative or neutral.  For the sake of illustration, consider the snippet  “Unpacking \nfive of the biggest cryptocurrency scams to have hit the crypto world. ”, which was posted on April \n2018th, 2018. The resulting sentiment score of -0.74 returned by IBM Watson is very negative due \nprimarily to the role of the word “scams” in that sentence.  \n \nFinal Merged Data  \n \nWe note that the first two collected variables, Bitcoin_Volume and Gtrend , have a total of 270 \nvalues, whereas the last two, namely DJIA_Volume  and Scores , have, respectively, 187 and 229. \nAfter grouping all variables by day and removing the incomplete cases, we ended up with a data \nset containing 160 o bservations and 4 variables. Table 1 illustrates the final data set, which in \nturn is used in our analysis described next.  \n \nDATA ANALYSIS  \n \nAfter collecting and preprocessing the data, we next analyze the final data set so as to understand \nhow different var iables influence Bitcoin trading activities. In our analysis, we start by reporting \nsome descriptive statistics and correlation matrix in, respectively, Table 2 and 3. From Table 2, \none can immediately see that sentiment scores are on average negative, as we already \nmentioned in the previous section, meaning that most of the collected financial news about Bitcoin \nare negative in nature. Moreover, the minimum ( 6) and maximum ( 85) Gtrend  values illustrate \nthat some of the original data points we collected bef ore were lost after merging all the data sets \nand removing missing data. From the variables Bitcoin_Volume  and DJIA_Volume , one can see \nthat the number of daily Bitcoin transactions is rather small when compared to the number of \ntransactions involving stoc ks in the DJIA index.  \n \nTable 1. Sample of the Final Data.  \nBitcoin_Volume  Gtrend  DJIA_Volume  Scores  \n347393  29 341470000  -0.761442  \n337959  33 346830000  0 Figure 4. Histogram of the Sentiment Scores Associated with Bitcoin Snippets.  \nJerdack et al.  Understanding What Drives  Bitcoin  Trading  Activities  \n \n \n \n Table 2. Descriptive Statistics Concerning the Final Data Set. \nVariable  Mean  St. Dev.  Min Max \nBitcoin_Volume  262,529.9  69,505.58  131,875  490,644  \nGtrend  18.881  14.234  6 85 \nDJIA_Volume  370,958,500  106,743,091  118,610,000  823,940,000  \nScores  -0.117  0.235  -0.761  0.665  \n \nTable 3. Correlation Matrix.  \n  Bitcoin_Volume  Gtrend  DJIA_Volume  Scores  \nBitcoin_Volume   -- 0.614*** -0.235** -0.010  \nGtrend  0.614*** -- 0.214** 0.025  \nDJIA_Volume  -0.235** 0.214** -- -0.026  \nScores  -0.010  0.025  -0.026  -- \nNote: ** = p -value  < 0.01; *** = p -value  < 0.001 \n \nFocusing now on Table 3, one can see that Gtrend  and DJIA_Volume  significantly correlates with \nBitcoin_Volume . While the former is a positive association, the latter is a negative correlation. \nThis indicates that online popularity, as measured by Google Trends, and Bitcoin trading activity \ntend to move in the same direction, whereas trading activity  associated wi th the  DJIA index and \nBitcoin trading activity move in opposite directions. Another interesting fact is that the variable \nScores is not correlated with any other variable. We return to this point later in the paper. Finally, \nit is noteworthy that Gtrend  also positively correlates with DJIA_Volume . Recall that the variable \nGtrend  measures the popularity of the term ‘Bitcoin’ over time. That said, we believe that its \npositive correlation with DJIA_Volume  might just be spurious since it seems to contradict the  facts \nthat the variables  DJIA_Volume  and Gtrend are, respectively, negatively and positively correlated \nwith Bitcoin_Volume .  \n \nWe next extend the above univariate and bivariate analyses by developing a multiple linear \nregression model where Bitcoin_Volume  is the dependent variable and all the other variables are \nindependent variables. As one can see from Table 3, the independent variables are not highly \ncorrelated, which means that a regression model is unlikely to  suffer from multicollinearity issues. \nTable 4 shows a summary of the obtained regression model.  The coefficients in Table 4 confirm \nwhat we previously suggested. First, holding everything else constant, Bitcoin trading activities \nare expected to increase when Bitcoin’s online popularity ( Gtrend ) increases. Second, when the \nnumber of transactions involving stocks in the DJIA index ( DJIA_Volume ) goes up, the number of \nBitcoin transactions are expected to go down. Finally, there is no significant relationship between \nsentiment scores related to Bitco in news ( Scores ) and Bitcoin trading activities. The R2 and F -\nstatistic values suggest that our model fits the data well . In particular, it is rather surprising that \nthe three independent variables can explain 51.9% (R2 = 0.519) of the variance in the amou nt of \ndaily trading activities  associated with Bitcoin . \n \nTable 4. Summary of the Multiple Linear Regression Model . \n  Coefficient  Standard Error  P-value  \n(Intercept)  289909.95  14,245.510  < 0.001  \nGtrend  3403.46  277.846  < 0.001  \nDJIA_Volume  -0.000 25 0.0000 37 < 0.001  \nScores  -11132.59  16,445.560  0.499  \nR2 = 0.519  \nF-statistic = 55.997 (df = 3, 156; p -value < 0.001)  Jerdack et al.  Understanding What Drives  Bitcoin  Trading  Activities  \n \n \n \n It is important to highlight that we carefully validated the  assumptions behind the linear regression \nmodel. First, there is  strong evidence that the mean of the residuals is equal to zero (one sample \nt-test; null hypothesis: µ = 0;  p-value > 0.999). Second, the distribution of the residuals resembles \na normal distribution (see the left part of Figure 5). Finally, the assumption of homoscedasticity \nseems to hold true (see  the right part of  Figure 5). Although some observations are flagged as \noutliers  according to traditional guidelines based on Cook’s distance , we nonetheless  obtained  \nqualitatively  the same results when  removing those  outliers . \n \nDISCUSSION  \n \nCryptocurrencies promise to disru pt many traditional industries and the way humans perceive and \nhandle (virtual) money. Given the abundance of cryptocurrencies currently available  to the public , \nit is just natural that only a limited number of virtual coins will eventually prevail. In this paper, we \nstudied some of the factors that might make some coins more popular than others. Specifically, \nwe took the number of daily transactions as a proxy for popularity. This allows one to understand \nand potentiall y predict which coins will stand the test of time. Our initial study was focused on \nBitcoin since  the same is  currently  the most popular and well -established cryptocurrency. We then \ninvestigated how online popularity, trading volume  in an unrelated financi al market, and financial \nnews influence Bitcoin trading activity . \n \nOur first hypothesis was that online popularity positively correlates with Bitcoin trading  volume . \nUsing Google Trends as a proxy for online popularity, we confirm that our first hypothesis  is true. \nAlthough it  was found before that Google Trends values can partially explain Bitcoin prices  \n(Kristoufek, 2013 ; Kristoufek , 2015), to the best of our knowledge this is the first paper to establish \nthat online popularity also drives  Bitcoin  trading volume . \n \nOur second hypothesis was that trading volume in non -cryptocurrency financial markets \nnegatively correlates with Bitcoin  trading volume. We used the trading volume regarding stock s \nin the Dow Jones Industrial Average index as a proxy when  testing  that hypothesis.  Our results \nFigure 5. Validating the Assumptions behind the Linear Regression Model. (LEFT) Distribution of \nthe Residuals. (RIGHT) Validating Homoscedasticity.  Jerdack et al.  Understanding What Drives  Bitcoin  Trading  Activities  \n \n \n \n confirm that the second hypothesis is true in that DJIA trading volume negatively correlates with \nBitcoin trading volume. To the best of our knowledge, this is the first work to establish such a \nrelationship between non-cryptocurrency financial markets and cryptocurrency trading volume.  \n \nOur last hypothesis was that financial news do not significantly affect Bitcoin trading volume. After \ncollecting data from the most popular Bitcoin public page on Facebook and estimat ing the \nsentiment behind the underlying posts using IBM Watson, we confirm  that the third hypothesis is \nalso true, i.e., there is  no significant relationship  between sentiment scores and Bitcoin trading \nvolume . It is fair to acknowledge that the lack of re lationship might be due to the fact that, despite \nhaving hundreds of thousands of followers, the Facebook page  we collected data from might not \nbe influential enough and/or the published news might be somehow biased, e.g., too negative. In \nhindsight, we recognize  that it would be valuable to collect Bitcoin -related  news from more than \none Facebook page  and/or other news source s so as to tackle the above mentioned  issues.  \n \nWe conclude this paper by returning  to the discussion  in the introductory section, namely how can \none know which cryptocurrencies will stand the test of time? Our results suggest very practical \nguidelines  to answer th is question . First, one can use Google Trends to track the online popularity \nof a cryptocurrenc y over time . When this popularity measure starts going down, then our res ults \nimply that trading activities involving the cryptocurrency  is also expected to  go down and, \nconsequently, the public  might be losing interest in the cryptocurrency. Second, one c an track the \ntrading volume in different non-cryptocurrency financial  markets . When th ese numbers start going \ndown, then it is expected that  trading activities involv ing cryptocurrencies will go up, meaning that \nthe public might be more interested in crypt ocurrencies.   \n \nClearly, t he above guidelines rely on the assumption that the results we obtained in this paper are \nvalid for all cryptocurrencies , which is unwise  to claim without extra data analyses. That said, \nbesides replicating this study for cryptocurrencies other than Bitcoin , we believe it would be  of \ngreat value to study how generalizable our results are. For example, would one obtain qualitatively \nthe same results when  using stock market indexes other than DJIA or different sources of \ncryptocurrency -related  news? Is there any other way of measuring the online popularity of \ndifferent cryptocurrencies that perhaps complements Google Trends? We argue that answers to \nthe above questions might be of great value to investors considering to trade  cryptocurrencies.  \n \nREFERENCES  \n \nBarber, B. M., & Odean, T. (2007). All that glitters: The effect of attention and news on the \nbuying behavior of individual and institutional investors. The review of financial studies, 21(2), \n785-818. \n \nBlockchain ( 2018 ). Confirmed transactions per day  - Blockchain . Retrieved from \nhttps:// blockchain.info/charts/n -transactions, April 19 . \n \nEngelberg, J. E., & Parsons, C. A. (2011). The causal impact of media in financial markets.  The \nJournal of Finance , 66(1), 67 -97. \n \nFacebook (2018). Bitcoin Chart . Retrieved from https://www.facebook.com/bitcoinchart/ , April \n19.  \n \nFang, L., & Peress, J. (2009). Media coverage and the cross ‐section of stock returns.  The \nJournal of Finance,  64(5), 2023 -2052.  Jerdack et al.  Understanding What Drives  Bitcoin  Trading  Activities  \n \n \n \n Ferrucci, D., Brown, E., Chu -Carroll, J., Fan, J., Gondek, D., Kalyanpur, A. A., Lally, A., \nMurdock, J. W., Nyberg, E., Prager, J., Schlaefer, N., & Welty, C. (2010). Building Watson: An \noverview of the DeepQA project. AI Magazine , 31(3), 59 –79. \n \nFerrucci, D., Levas, A., Bagchi, S., Gondek, D., & Mueller, E. T. (2013). Watson: Beyond \njeopardy! . Artificial Intelligence  199, 93–105. \n \nKristoufek, L. (2013). BitCoin meets Google Trends and Wikipedia: Quantifying the relationship \nbetween phenomena of the Inte rnet era.  Scientific Reports,  3:3415.  \n \nKristoufek, L. (2015). What are the main drivers of the Bitcoin price? Evidence from wavelet \ncoherence analysis.  PloS one , 10(4): e0123923.  \n \nNakamoto, S. (2008). Bitcoin: A peer -to-peer electronic cash system . Retrieved from \nhttps://bitcoin.org/bitcoin.pdf, April 19 . \n \nYahoo (2018). DJI Real Time Price. Retrieved from https:// finance.yahoo.com/quote/%5EDJI, \nApril 19 . "}
{"date": "2024-01-04-22-29", "error": false, "url": "PDF", "text_blocks": "On-line Remote ekg as a Web Service\nAugusto Ciu\u000boletti\u0003\ne.mail: augusto.ciu\u000boletti@unipi.it\nJanuary 4, 2019\nAbstract\nA 3-leads, non-diagnostic ekghas a role in emergency rescue and homecare. In this paper\nwe introduce the design and a prototype of a service, provided to a doctor and a patient, for\nthe on-line remote visualization of patient's 3-leads ekg. The architecture is based on the\nhttp protocol, using commercial o\u000b-the-shelf devices to implement the sensor on patient's\nside, a browser on a laptop Personal Computer (PC) on the doctor's side as viewer, and a\ncloud container to connect the two using Websockets. A prototype is built to evaluate signal\nlatency, power consumption of the patient side device, and the quality of the rendering. After\nsome experiments, latency is measured below 1 sec, and power consumption is estimated in\nthe 2A*3.3V range; visualization is comparable to commercial, non-diagnostic products. The\nprototype patient device is portable, and can be operated using rechargeable battery packs.\nIts cost is below 100$, and all the required equipment is commercially available. The archi-\ntecture is ready for on \feld evaluation, and we indicate how to improve power consumption\nwhile reducing cost.\nKeywords: Non-diagnostic ekg; Websocket; Cloud PaaS; EKG acquisition; Ar-\nduino; Raspberry Pi\n1 Introduction\nThere are cases where heartbeat monitoring would improve doctor's assistance, but the patient\nand the physician are not in the same room. What we need in that case is to transmit the\nelectrocardiogram (EKG) from patient's heart to doctor's display: this is an on-line remote EKG .\nThe number of use cases for remote EKG is long and includes assistance in rural areas, emergency\nrescue, automated processing and alert, long term recording etc. In most cases a diagnostic 12-\nleads measurement is inappropriate, since it requires time and a speci\fc training to be prepared,\nwhile a 3-leads, non-diagnostic EKG is \ftting. Two stories illustrate its possible utilization.\nOne is that of an ambulance with paramedical personnel rescuing a injured person after a car\naccident. It is likely that the location is covered by a ground or satellite broadband provider, and\nthat an Access Point (AP) is available, e.g. by tethering a smartphone. With an on-line remote\nEKG service the 3-leads trace is delivered to the medical sta\u000b in the hospital, that de\fnes the\nemergency level.\nA di\u000berent homecare story is that of a cardiac patient that is periodically contacted by the\nfamily doctor to check general conditions. In that case the physicist uses a remote EKG service to\nreceive the trace without leaving its desk during a phone call, possibly interacting with the patient\nabout electrodes position or body posture.\nThis paper addresses the long distance delivery of a non-diagnostic EKG, using cloud facilities\nintegrated with personal devices.\n\u0003Dept. of Computer Science, Universit\u0013 a di Pisa L.go B. Pontecorvo - 56122 Pisa ORCID:0000-0002-9734-2044\n1arXiv:1901.00724v1  [cs.CY]  3 Dec 20182 Background and previous works\nThe electrical functionality of the heart is a fundamental diagnostic information for the medical\nsta\u000b. Its recording dates back to the end of the 19th century. From that time, research addressed\n\frst the ampli\fcation of the signal, whose amplitude is in the \u0016Vrange, and next the design\nof \flters that remove unwanted components (like powerline hum, or signals from other muscular\nactivity). The current state of the art on EKG \fltering is in [11].\nComputers come into play in connection with \flters, and today they extract the fundamental\nfeatures of the EKG signal. In [10] the authors introduce an approach and evaluate the computing\nresources needed, with a survey of other research results in the \feld. A recent survey is also in\n[14].\nWith the advent of the Web, storage and transport of EKG data emerge as a practical per-\nspective. In [13] the author investigates its use for human identi\fcation, and incidentally creates\na database of EKGs, that later became a precious resource for many. The availability of historical\ndata is relevant for medical research, daily health-care use, and educational purposes.\nThe primary concern with the transport and storage of an EKG is about its con\fdential\nnature. In [18] the authors survey a number of cryptographic systems that can be used to secure\nthe transport and the storage of biosensor data. The paper assumes the presence of a number of\ndistinct sensing devices aggregated in a Medical Sensor Network (MSN).\nThe ubiquitous presence of wireless networks justi\fes the realization of portable (or even\nwearable [2]) EKG devices that forward the trace to a nearby PC or tablet. When many such\ndevices are aggregated in a network, we speak of a Body (or Personal) Data Network (BAN).\nIn 2001, [12] introduces the basic principles and concepts, and, ten years later, a survey in [3]\nlists nine BAN projects, 5 of which include EKG. Detailed designs of BAN devices are found, for\ninstance, in ([19]), [17], [7]. However they are appropriate for local area networks, con\fned in a\nroom or a building.\nThe availability of cloud servers allows overcoming such limits. In [21] the authors propose a\ncloud-based infrastructure: the physician and the patient are clients of a Web server that processes\nthe EKG, evaluates its quality, and provides parameter extraction and visualization. The server\nis in the Amazon Web Services (AWS) cloud, while the client uses personal devices that interact\nwith the server using Secure Hypertext Transfer Protocol (HTTPS).\nTo facilitate the di\u000busion of the remote EKG service, we need to address the cost of the\nhardware devices, which also meets the needs of developing countries and of rural areas, as in [20]\nand [8].\nIn this paper we show how a cloud infrastructure can be used to relay the EKG from the\npatient's device to the doctor's laptop: in a nutshell, we actualize the ideas in [21], but with\nthe target of [12]. This result is obtained using low cost devices and established protocols and\ninfrastructures, without overlooking security aspects.\n3 An open service for remote ekg\nThe design guidelines authorize several alternatives, and we propose the architecture outlined in\n\fgure 1.\nThe right box represents the devices on patient's side. We observe the analog stage with the\noperational ampli\fer and the \flters, the processor that encodes the analog signal on a serial line,\na Hypertext Transfer Protocol (HTTP) user agent that further processes the signal and manages\nthe Websocket. This stage is connected to the Internet with a wireless link, and reaches the cloud\nserver.\nThe devices on doctor's premises are in the left box: a wireless AP, and the smart device (a\nPC or smartphone) with a HTTP client that manages the Websocket, and displays the EKG in a\nconvenient way.\nFrom the security perspective, we highlight that only the routers inside the APs need to\nexpose a public Internet Protocol (IP) address, therefore both patient's and doctor's devices can\n2Figure 1: Remote ekg service infrastructure layout\nbe protected by a Network Address Translation (NAT) and other security techniques implemented\non the router, according with common practice.\nThe cloud server needs a limited computational capacity, and it may exist just for the time\nneeded by the physicist to examine the EKG: it is the ideal candidate for a microservice instance\n[15]. A Platform as a Service (PaaS) provider can create a new instance of a microservice in a few\nseconds, make it accessible in the Internet with a unique Uniform Resource Locator (URL), and\ndestroy it after use.\nThe cloud provider is responsible for the security of the server, whose URL is known only to\nthe partners. However, server life span is so limited that the potential intruder has little time to\nidentify and attack it, especially if communication is encrypted, for instance with Transport Level\nSecurity (TLS).\nThe adoption of HTTP as the transport protocol is a cornerstone, since cloud services, that\nare reachable only using this protocol, provide a \rexible, reliable and secure infrastructure for\nEKG transmission. Although real time aspects of the remote EKG are incompatible with the\nhttp request/response mechanism, the WebSockets [9] have been recently introduced to allow\nunsolicited communication between client and server. WebSockets have a behavior similar to\nTransport Control Protocol (TCP) channels, but are encapsulated in a HTTP session.\nIn our architecture, the PaaS server acts as a relay point: two separate WebSockets are created\nto this end, one with the patient, another with the doctor, and the data are trasparently transferred\nfrom the former to the latter. This con\fguration turns out to be easily scalable, with costs that\nat the prototype stage can be null, and with excellent security features.\nIn addition, with HTTP the doctor uses the browser of his laptop to view the EKG, without\nthe need to install new software. The architecture is therefore agnostic of the operating system\ninstalled on doctor's premises.\nTo have similar bene\fts also on patient's side, we introduce the following principles, that, in\nthis paper, are synthesized in the Open Source, Low Cost, COTS (OpLoC) acronym:\n\u000fOpen Source : components and protocols are exhaustively documented and freely repro-\nducible;\n\u000fLow Cost : the less expensive option is always preferable. In particular, if a functionality\nis already available, it is not re-implemented;\n3void Timer2OveflowISR( ) {\nint i;\nunsigned long int t;\nif ( full [b] ) {\nSerial.println (fail);\nreturn;\n}\nfor (int Channel = 0 ; Channel < 6 ; Channel++) {\nData [ Channel ] [ b ] = analogRead (Channel );\n}\nfull[b]= true;\nb=b1;\n}\nTable 1: The function triggered every 4 msecs on the mcu\n\u000fCommercial Devices : devices must be available on retail (aka Commercial O\u000b-the-shelf\n(COTS)).\nPut together, the three principles ensure that an implementation is easily reproducible, and\nmakes a solid ground for further investigation. In addition, low cost ensures that its applicability\nis not selective by scale and wealth.\n4 A prototype for a remote EKG service\nThis section describes a concrete implementation of the above abstract design. In \fgure 3 we see\nthe device on patient's side, while in \fgure 4 we see the display in the browser. Together with the\nOpLoC hardware components, the prototype contains also three ad-hoc software products, whose\ncode is publicly available on the Bitbucket and GitHub platforms:\n\u000fthe analog-to-serial encoder in the Micro-Controller Unit (MCU) [6]\n\u000fthehttp patient-side User Agent (UA) [4]\n\u000fthe doctor's page and the Websocket manager in the cloud container [5]\nThe sensor: ampli\fer and \flter\nThe prototype uses the popular Olimex EMG-EKG sensor board [1]: its size is 6 \u00028\u00023cm, and\nthe cost is around 30$. It is usually sold with EKG pads.\nThe board integrates a 3rd order \flter at 40Hz and two high-pass \flters to remove high fre-\nquencies and baseline drift.\nA single board acquires a non-diagnostic 3-lead EKG through a 3-pole jack. The design of the\nboard allows to stack up to 6 boards for a diagnostic 12-lead EKG, but our prototype uses just\none of them.\nThe MCU: Analog Digital Converter (ADC) and serial encoder\nThe MCU is a popular Arduino Uno board, whose cost is around 10$. The connection with the\nArduino-compliant Olimex board described above is obtained by stacking the two boards: the\nresult is mechanically stable and su\u000eciently compact. The analog output of the sensor board is\nconverted into a 10-bits integer by the ADC embedded in the MCU.\nTo have an accurate timing, needed for \fltering and analysis purposes, a hardware interrupt\ntriggers data fetch with a frequency of 250Hz [16]. The code snippet for the interrupt handler is\n4in table 1: note that it is prepared to collect six analog data for a standard 12-lead EKG, but only\none is used in the prototype. The main loop waits for the bu\u000ber to be readable, and encodes a\nspace-separated line:\n<h>:<m>:<s>.<msec> <v1> <v2> <v3> <v4> <v5> <v6>\\n\nThe \frst \feld is a 1 msec resolution timestamp, and the other six \felds, of which only one is\nused in the prototype, are integers in the interval [0 \u00001023] that correspond to a sample. The\nencoding does not introduce any rounding or information loss, and its redundancy is functional\nto data integrity. The timestamp is not as accurate as the sampling period: it is used only for\nrendering.\nTo avoid interference between data fetch and encoding, a two positions bu\u000ber is introduced,\nwith access regulated by a semaphore.\nIt is worth saying that Olimex provides a di\u000berent driver ([1]), but its accuracy is not su\u000ecient\nfor the task.\nMCU to Single Board Computer (SBC) interface\nThe two units communicate using their Universal Asynchronous Receiver-Transmitter (UART)s,\nwith a baudrate of 115200. Since the maximum length of a line is 44 8-bit characters, and 250\nlines are produced each second, the MCU outputs 11000 bytes per second. Since one stop bit per\nbyte is added, this requires a baudrate of 99000, which is consistent with UARTs one.\nPatient side user-agent\nSince the sensor unit has tight timing requirements and limited capabilities, it is more appropriate\nto decouple the HTTP UA on a distinct platform. The Raspberry Pi 3 used in the prototype is\na SBC that uses production-level libraries to implement the patient-side user agent. Its cost is\nabout 25$.\nThe UA is written in Python, and opens a Websocket connection with a container hosted in\nthe Heroku cloud whose URL is:\nhttp://<container fqdn>/in/<id>\nwhere <id> is a unique id for the device. When the Websocket is opened, the UA starts\nsending EKG samples encoded as JavaScript Object Notation (JSON) objects with two \felds: the\ntimestamp, and one value.\n4.1 The server\nThe server is a container in the Heroku cloud: for the sake of simplicity, the prototype envisions\none single container hosting several concurrent EKGs instead of a short lived micro-service for\neach of them.\nThe server is implemented using the Python/Flask micro-framework and the gunicorn Web\nServer Gateway Interface (WSGI) HTTP server. It provides three families of application routes:\n\u000f/which returns a presentation page,\n\u000f/in/<id> used by a patient's UA to open a Websocket, as explained above,\n\u000f/<id> used by doctor's UA to open a Websocket and receive the EKG,\n\u000f/out/<id> used as endpoint for doctor's Websocket\n5The server waits for a patient's UA request on the /in/<id> route, upgrades the session to a\nWebsocket and prepares to receive a request from doctor's side with the same <id> : until then,\nall received data are lost. If doctor's request arrives \frst, the server returns a negative reply.\nWhen the server receives doctor's request on an /<id> path matching patient's UA, it delivers\na page containing the JavaScript code to open the WebSocket on /out/<id> and displays the\nEKG.\nSince each patient UA has a di\u000berent identi\fer, a single server may host several EKG at the\nsame time, each of which is received by only one doctor UA.\nThe security mechanisms announced in the 3 are not fully implemented: namely, in the proto-\ntype the server is persistent and communications use plain HTTP. The implementation of such\nfeatures appears to be quite straightforward, and it is a matter for the improvement of the product.\nThe display UA\nThe UA on doctor's side is a web browser running on a laptop. The doctor opens the HTTP session\nusing a URL with the Fully Quali\fed Domain Name (FQDN) of the server and the /<id> route.\nIf the corresponding patient is already connected, the response contains a resource composed of\nthe familiar EKG canvas and of a JavaScript application that opens a WebSocket on the /in/<id>\nroute. From it the EKG is received and the Chart.js library is used to display it.\nThe JavaScript application \flters out the 50 Hzpowerline noise with a moving average of \fve\nvalues and \fnds R peaks to compute heartbeat frequency. This demonstrates the possibility of\nadditional \fltering and feature extraction on doctor's side, and provides a readable result.\n5 Results and future work\nA relevant parameter is the latency between the production of the signal and its visualization: it\nhas been measured as lower than one second. Autonomy with battery operation has an impact\non practical usability as well: using a 2200 mAh rechargeable power bank an autonomy of 72\nminutes has been measured, and the prototype operates with the 3.3V power supply provided by\nthe Raspberry.\nThe Raspberry Pi 3 over-kills its task, and it is a candidate for replacement with a more\nfocused OpLoC device. Being in charge of implementing the patient's WebSocket, it uses 50% of\nthe space, 90% of the power (nearly 1500 mA), and 30% of the cost.\nThe interface on doctor's side (see \fgure 4) should be extended with a switch to select \fltering,\nfeature extraction and evaluation tools, and the possibility to save, and replay, the trace. A Smart-\nphone interface is close to reach, but the limited size of the display makes the EKG signi\fcantly\nless readable.\n6 Discussion\nAn open-source on-line remote EKG architecture has been introduced. This kind of service is\nalready o\u000bered in return for a payment, as part of health-care packages, and it is usually based\non proprietary hardware/software resources. In contrast, this paper aims at an architecture based\non open source resources, with an attitude that we summarize in the OpLoC acronym: hardware,\nsoftware, and communication protocols are a\u000bordable open source products. A few of them have\nbeen designed for the purpose (namely, the client/server software and the serial protocol), but the\nrule is to use COTS resources. One of the resources is in the cloud, the web-server that transfers\nthe EKG from the patient to the physician: no exception, it is a plain open-source web server. To\ndemonstrate that the architecture is feasible and to evaluate its performance, we implemented a\nprototype that is exhaustively described and reproducible. The OpLoC principles foster a wider\ndi\u000busion of a useful device on a more competitive basis, and make it applicable to disadvantaged\nor marginal regions.\n6Figure 2: Two EKGs: one after exercise, using elastic bands on left and right wrists and right\nankle, another at rest, using adhesive electrodes on chest. They have been captured as screenshots\nform doctor's browser using the prototype described in the paper.\n7 Abbreviations\nOpLoC Open Source, Low Cost, COTS\nCOTS Commercial O\u000b-the-shelf\nEKG electrocardiogram\nUA User Agent\nFQDN Fully Quali\fed Domain Name\nHTTP Hypertext Transfer Protocol\nHTTPS Secure Hypertext Transfer Protocol\nURL Uniform Resource Locator\nJSON JavaScript Object Notation\n7Figure 3: The patient-side prototype device, with three elastic bands, the 2200 mAh battery, the\nArduino/Olimex ekg boards and the Raspberry Pi 3\nWSGI Web Server Gateway Interface\nMCU Micro-Controller Unit\nSBC Single Board Computer\nPaaS Platform as a Service\nAP Access Point\nBAN Body (or Personal) Data Network\nMSN Medical Sensor Network\nPC Personal Computer\nAWS Amazon Web Services\nNAT Network Address Translation\nTLS Transport Level Security\nADC Analog Digital Converter\nUART Universal Asynchronous Receiver-Transmitter\nIPInternet Protocol\nTCP Transport Control Protocol\n8 Bibliography\nReferences\n[1]SHIELD EKG-EMG REV.B .\n8Figure 4: The remote EKG display on doctor's side\n[2] Mirza Mansoor Baig, Hamid GholamHosseini, Aasia A. Moqeem, Farhaan Mirza, and Maria\nLind\u0013 en. A systematic review of wearable patient monitoring systems { current challenges and\nopportunities for clinical adoption. Journal of Medical Systems , 41(7):115, Jun 2017.\n[3] Min Chen, Sergio Gonzalez, Athanasios Vasilakos, Huasong Cao, and Victor C. M. Leung.\nBody area networks: A survey. Mobile Networks and Applications , 16(2):171{193, Apr 2011.\n[4] Augusto Ciu\u000boletti. Ecg over websocket project (client). https://bitbucket.org/labreti/ecg-\nclient, october 2017.\n[5] Augusto Ciu\u000boletti. Ecg over websocket project (server). https://bitbucket.org/labreti/ecg-\nserver, october 2017.\n[6] Augusto Ciu\u000boletti. A linux plotter for the Olimex EKG-EMG shield.\nhttps://github.com/AugustoCiu\u000boletti/Olimex-EKG plotter, september 2017.\n[7] C. Cristea, A. Pasarica, G. Andruseac, B. Dionisie, and C. Rotariu. A wireless ecg acquisition\ndevice for remote monitoring of heart rate and arrhythmia detection. In 2015 E-Health and\nBioengineering Conference (EHB) , pages 1{4, Nov 2015.\n[8] S. Deb, S. M. R. Islam, J. RobaiatMou, and M. T. Islam. Design and implementation of\nlow cost ecg monitoring system for the patient using smart device. In 2017 International\nConference on Electrical, Computer and Communication Engineering (ECCE) , pages 774{\n778, Feb 2017.\n[9] I. Fette and A. Melnikov. The WebSocket Protocol. RFC 6455 (Proposed Standard), dec\n2011.\n[10] R. Gutierrez-Rivas, J. J. Garcia, W. P. Marnane, and A. Hernandez. Novel real-time low-\ncomplexity qrs complex detector based on adaptive thresholding. IEEE Sensors Journal ,\n15(10):6036{6043, Oct 2015.\n[11] C. Haritha, M. Ganesan, and E. P. Sumesh. A survey on modern trends in ecg noise removal\ntechniques. In 2016 International Conference on Circuit, Power and Computing Technologies\n(ICCPCT) , pages 1{7, March 2016.\n9[12] Valerie M. Jones, Richard G.A. Bults, D. Konstantas, and P.A.M. Vierhout. Healthcare\npans: Personal area networks for trauma care and home care. In Proceedings of the Fourth\nInternational Symposium on Wireless Personal Multimedia Communications , volume 3, pages\n1369{1374, 2001. Imported from research group ASNA (ID number 161).\n[13] Tatiana S. Lugovaya. Biometric human identi\fcation based on electrocardiogram. Mas-\nter's thesis, Faculty of Computing Technologies and Informatics, Electrotechnical University\n\"LETI\", Saint-Petersburg, Russian Federation, 2005.\n[14] G. R. Naik and K. A. Reddy. A new model for ecg signal \fltering and feature extraction. In\n2016 2nd IEEE International Conference on Computer and Communications (ICCC) , pages\n765{768, Oct 2016.\n[15] Sam Newman. Building Microservices: designing \fne-grained systems . O'Reilly, 2015.\n[16] G.P. Pizzuti, S. Cifaldi, and G. Nolfe. Digital sampling rate and ECG analysis. Journal of\nBiomedical Engineering , 7(3):247 { 250, 1985.\n[17] E. Plesnik, O. Malgina, J. F. Tasi, and M. Zajc. Ecg signal acquisition and analysis for tele-\nmonitoring. In Melecon 2010 - 2010 15th IEEE Mediterranean Electrotechnical Conference ,\npages 1350{1355, April 2010.\n[18] Duraisamy Sathya and Pugalendhi Ganesh Kumar. Secured remote health monitoring system.\nHealthcare Technology Letters , June 2017.\n[19] Victor Shnayder, Bor-rong Chen, Konrad Lorincz, Thaddeus R. F. Fulford-Jones, and Matt\nWelsh. Sensor networks for medical care. Technical Report TR-08-05, Harvard Computer\nScience Group Technical Report, 2005.\n[20] B. A. Walker, A. H. Khandoker, and J. Black. Low cost ecg monitor for developing countries.\nIn2009 International Conference on Intelligent Sensors, Sensor Networks and Information\nProcessing (ISSNIP) , pages 195{199, Dec 2009.\n[21] Henian Xia, Irfan Asif, and Xiaopeng Zhao. Cloud-ecg for real time ecg monitoring and\nanalysis. Computer Methods and Programs in Biomedicine , 110(3):253 { 259, 2013.\n10"}
