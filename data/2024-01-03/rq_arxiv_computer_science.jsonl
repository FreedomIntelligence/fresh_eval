{"date": "2024-01-03-18-23", "error": false, "url": "PDF", "text_blocks": "Profiling Programming Language Learning\nWILL CRICHTON and SHRIRAM KRISHNAMURTHI, Brown University, USA\nThis paper documents a year-long experiment to ‚Äúprofile‚Äù the process of learning a programming language:\ngathering data to understand what makes a language hard to learn, and using that data to improve the learning\nprocess. We added interactive quizzes to The Rust Programming Language , the official textbook for learning\nRust. Over 13 months, 62,526 readers answered questions 1,140,202 times. First, we analyze the trajectories of\nreaders. We find that many readers drop-out of the book early when faced with difficult language concepts\nlike Rust‚Äôs ownership types. Second, we use classical test theory and item response theory to analyze the\ncharacteristics of quiz questions. We find that better questions are more conceptual in nature, such as asking\nwhy a program does not compile vs. whether a program compiles. Third, we performed 12 interventions into\nthe book to help readers with difficult questions. We find that on average, interventions improved quiz scores\non the targeted questions by +20%. Fourth, we show that our technique can likely generalize to languages\nwith smaller user bases by simulating our statistical inferences on small ùëÅ. These results demonstrate that\nquizzes are a simple and useful technique for understanding language learning at all scales.\nCCS Concepts: ‚Ä¢Applied computing ‚ÜíE-learning ;‚Ä¢Software and its engineering ‚ÜíGeneral pro-\ngramming languages .\nAdditional Key Words and Phrases: rust education, digital textbooks, item response theory\n1 INTRODUCTION\nTeaching prospective users is an inescapable part of programming language adoption. Yet, teaching\nPLs is more art than science. PL learning resources are designed based on the intuitions of their\nauthors. Feedback on these resources only comes at the macro-scale, such as whether programmers\nend up successfully adopting a language. This disconnect is becoming more salient as the learning\ncurves for modern languages grow ever steeper. For instance, user surveys within the communities\nof OCaml [OCaml Software Foundation 2022], Haskell [Fausak 2022], Rust [The Rust Survey Team\n2020], Scala [Scala Center Team 2022], Clojure [Randolph 2022], and even Go [Merrick 2023] all\nreport that the language‚Äôs learning curve is one of the biggest problems in the language‚Äôs ecosystem.\nHeeding the call of Meyerovich and Rabkin [2013] to build a scientific foundation for ‚Äúsocio-PLT, ‚Äù\nwe set out to gather data about how people learn a new programming language, and to develop a\ngeneralizable methodology for improving PL learning resources. This paper reports on a year-long\nexperiment to profile the process of PL learning within an online textbook. We use ‚Äúprofile‚Äù in the\nsame sense as performance profiling for software ‚Äî our goal was to gather fine-grained data to help\nidentify ‚Äúhot-spots‚Äù where learners are struggling. Concretely, we studied The Rust Programming\nLanguage (trpl ) [Klabnik and Nichols 2022], the official textbook for learning Rust. We chose to\nstudy Rust both because the Rust community has been exceptionally open to facilitating educational\nresearch, and because many people were seeking to learn Rust in 2022-23.\nThe central idea of the experiment is to add interactive quizzes to each chapter of trpl , a total of\n221 questions. The quizzes acted as profiling probes that gathered data about individual challenges\nfaced by learners. From September 2022 to October 2023, we gathered 1,140,202 answers from\n62,526+ participants. The contribution of this paper is analyzing this data to answer four questions:\nAuthors‚Äô address: Will Crichton; Shriram Krishnamurthi, Department of Computer Science, Brown University, Providence,\nRhode Island, 02912, USA, wcrichto@brown.edu.\n¬©2024 Copyright held by the owner/author(s).\nThis is the author‚Äôs version of the work. It is posted here for your personal use. Not for redistribution. The definitive Version\nof Record was published in Proceedings of the ACM on Programming Languages .\nProc. ACM Program. Lang., Vol. , No. OOPSLA1, Article . Publication date: January 2024.arXiv:2401.01257v1  [cs.PL]  2 Jan 20242 Will Crichton and Shriram Krishnamurthi\nRQ1. What kinds of trajectories do readers take through the book? (Section 3.1)\nWe find that the vast majority of readers do not reach the end of the book, consistent with data from\nMOOCs. We also find that difficult language concepts in early chapters (specifically, ownership in\nthe case of Rust) serve as a common drop-out point for many readers.\nRQ2. What are the characteristics of a high-quality PL quiz question? (Sections 3.2 and 3.3)\nWe use both classical test theory (Section 3.2) and item response theory (Section 3.3) to model the\ndifficulty and discrimination of each question. We find that the most discriminative questions focus\non conceptual understanding over syntax or rote rules. In particular, questions about discerning\nwell-typed vs. ill-typed programs were often not"}
{"date": "2024-01-03-18-23", "error": false, "url": "PDF", "text_blocks": "Do Concept Bottleneck Models Obey Locality?\nNaveen Raman\nCarnegie Mellon University\nnaveenr@cmu.eduMateo Espinosa Zarlenga\nUniversity of Cambridge\nme466@cam.ac.uk\nJuyeon Heo\nUniversity of Cambridge\njh2324@cam.ac.ukMateja Jamnik\nUniversity of Cambridge\nmateja.jamnik@cl.cam.ac.uk\nAbstract\nConcept-based learning improves a deep learning model‚Äôs interpretability by\nexplaining its predictions via human-understandable concepts. Deep learning\nmodels trained under this paradigm heavily rely on the assumption that neural\nnetworks can learn to predict the presence or absence of a given concept\nindependently of other concepts. Recent work, however, strongly suggests\nthat this assumption may fail to hold in Concept Bottleneck Models (CBMs),\na quintessential family of concept-based interpretable architectures. In this\npaper, we investigate whether CBMs correctly capture the degree of conditional\nindependence across concepts when such concepts are localised both spatially, by\nhavingtheirvaluesentirelydefinedbyafixedsubsetoffeatures, and semantically ,\nby having their values correlated with only a fixed subset of predefined concepts.\nTo understand locality, we analyse how changes to features outside of a concept‚Äôs\nspatial or semantic locality impact concept predictions. Our results suggest that\neven in well-defined scenarios where the presence of a concept is localised to a\nfixed feature subspace, or whose semantics are correlated to a small subset of\nother concepts, CBMs fail to learn this locality. These results cast doubt upon\nthe quality of concept representations learnt by CBMs and strongly suggest that\nconcept-based explanations may be fragile to changes outside their localities.\n1 Introduction\nConcept-based learning is an interpretability paradigm that leverages human-understandable\nconcepts as a way to explain a deep learning model‚Äôs predictions [ 1‚Äì4]. Concept Bottleneck\nModels (CBMs) [ 2] are constructed using this paradigm by first predicting concepts from an\ninput sample and then using these concepts to predict a downstream label of interest. This\ndesign allows CBMs to: (1) provide concept-based explanations for their predictions via their\npredicted sets of concepts, and (2) improve their test performance when deployed in conjunction\nwith experts via concept interventions [5, 6].\nIn this work, we investigate whether CBMs properly capture a task‚Äôs feature-to-concept and\nconcept-to-concept relationships through the lens of what we will refer to as concept locality .\nConcept locality refers to the idea that, for certain tasks, a concept‚Äôs value is a function of a\nsubset of features and concepts; modifications to features or concepts outside this should not\nimpact the concept‚Äôs prediction. For example, the concept of ‚Äúbird beak colour‚Äù should be\npredicted by focusing exclusively on the beak region of the image.\nRecent work by Margeloiu et al. [7]has observed that features deemed important for a CBM‚Äôs\nconcept‚Äôs prediction may not be confined to features known to fully define said concept. Here,\n37th Conference on Neural Information Processing Systems (NeurIPS 2023).arXiv:2401.01259v1  [cs.LG]  2 Jan 2024T riangle SquareLeft Shape Prediction(a) Spatial Locality\nHeart CircleShape Predtion (b) Semantic Locality\nFigure 1: CBMs fail to accurately reflect localities present in tasks. (a) Changing pixels on the\nright side of the image modifies the prediction for the shape on the left side from a triangle to a\nsquare. (b) Rotation and dilation changes shape prediction from heart to circle.\nwe aim to build on this surprising result by analysing the locality of a CBM‚Äôs learnt concept\nrepresentations when the training concepts are: (1) spatially localised , where values can be\nperfectly predicted from a well-defined subset of input features, and (2) semantically localised ,\nwhere a concept‚Äôs value is independent of the value of a well-defined subset of concepts. We\nselect these two modes to reflect varying granularities of features: spatial locality is related to\nchanges in individual features, such as pixels, while semantic locality is related to changes to\nabstract-level groups of features (Figure 1).\nOur contributions are the following: we (1) introduce spatial and semantic locality for concept-\nbased models, (2) assess a CBM‚Äôs ability to capture the spatial locality and show this is inversely\nproportional to the CBM‚Äôs capacity, and (3) analyse a CBM‚Äôs ability to properly capture a task‚Äôs\nsemantic locality and show that this is dependent on the task‚Äôs available concept annotations.\n2 Related Works\nConceptLearning Conceptlearning[ 1,8‚Äì11,3]isasubfieldofeXplainableArtificialIntelligence\n(XAI) where a Deep Neural Network‚Äôs predictions are explained via high-level units of information\n(i.e., ‚Äúconcepts‚Äù). Methods in this field can vary from fully concept-supervised [ 2,12,4,13],\nwhere one assumes access to both task and concept labels during training, to concept-unsupervised\nmethods [ 9,11,14], where only task labels are availa"}
{"date": "2024-01-03-18-23", "error": false, "url": "PDF", "text_blocks": "Fairness Certification for Natural Language\nProcessing and Large Language Models\nVincent Freiberger1and Erik Buchmann2\nDept. of Computer Science, Leipzig University, Germany1,2\nCenter for Scalable Data Analytics and Artificial Intelligence (ScaDS.AI)\nDresden/Leipzig, Germany1,2\nfreiberger@cs.uni-leipzig.de1buchmann@informatik.uni-leipzig.de2\nAbstract. Natural Language Processing (NLP) plays an important role\nin our daily lives, particularly due to the enormous progress of Large Lan-\nguage Models (LLM). However, NLP has many fairness-critical use cases,\ne.g., as an expert system in recruitment or as an LLM-based tutor in ed-\nucation. Since NLP is based on human language, potentially harmful\nbiases can diffuse into NLP systems and produce unfair results, discrim-\ninate against minorities or generate legal issues. Hence, it is important\nto develop a fairness certification for NLP approaches.\nWe follow a qualitative research approach towards a fairness certifica-\ntion for NLP. In particular, we have reviewed a large body of literature\non algorithmic fairness, and we have conducted semi-structured expert\ninterviews with a wide range of experts from that area. We have system-\natically devised six fairness criteria for NLP, which can be further refined\ninto 18 sub-categories. Our criteria offer a foundation for operationaliz-\ning and testing processes to certify fairness, both from the perspective\nof the auditor and the audited organization.\nKeywords: Fairness, Certification, NLP\n1 Introduction\nFairness is important for Natural Language Processing (NLP) approaches: NLP\nis used in high-stakes contexts such as healthcare [1]. It is also integrated into\ndaily-use technologies, e.g., voice assistants like Amazon Alexa [2] or AI-based\nchatbots like ChatGPT [3]. A lack of fairness often materializes as allocative or\nrepresentational harm [4] for marginalized groups [5]. An example of allocative\nharm is a resume filtering system, that prefers male applicants [6]. Representa-\ntional harm would be a translation app that translates to gender stereotypes [7],\ncultural stereotypes or demeaning language [6, 8, 9]. To avoid harm, a fair NLP\napplication must not only resist gender bias [10‚Äì13], but also ableist [14], eth-\nnical [11, 15, 16], age-related [17], religion-related [18] or sexuality bias [11, 19].\nPerformant NLP models tend to be opaque and complex [20, 21]. Interactions\nwith such sociotechnical systems are typically also complex [22]. Hence, it is not\npractically achievable for users or affected individuals to verify fairness. Fairness\ncertification could be embraced to reduce information asymmetries [23].arXiv:2401.01262v1  [cs.CL]  2 Jan 20242 Freiberger et al.\nThe concern of this paper is to develop a broad set of criteria, that can\nbe used by an auditor to assess and certify the fairness of an approach that\nmakes use of NLP, be it a large language model, a recruiting-tool or an AI-\nchatbot for teaching. This is challenging: First, many different definitions of\nfairness exist [24, 25], and some of them are contradictory [26, 27]. Second, it\nis still unclear yet, which fairness criteria are important for NLP approaches\nand how they impact each other. For instance, residual unfairness may remain\nafter bias mitigation has been resolved [28]. Third, efforts towards fair NLP and\ncertifying fairness of related AI approaches exist [29‚Äì34]. But there is neither\nan established nor a holistic framework on how fairness could be certified and\nwhat could be audited [35, 36]. To approach certification criteria that can be\napplied in practice, we need to consider the challenges of professionals tasked\nwith auditing the fairness of a system, as well as the challenges of developers\nthat encounter fairness issues when creating NLP systems. Thus, our research\nquestion is as follows:\nWhat criteria are relevant to consider for fairness certification for NLP ap-\nproaches from a practitioner‚Äôs point of view?\nTo approach our research question, we strive for broad, qualitative research.\nWe have decided to derive a basic set of auditable fairness criteria from litera-\nture on NLP, AI fairness and AI certification. Based on this set of criteria, we\nhave developed a concept for a semi-structured interview with stakeholders from\nbusiness and research. We have analyzed the interview transcripts in order to\nfind out (a) which measures for ensuring fairness need to be considered for NLP\napproaches, and (b) how they influence each other. We make four contributions:\n‚ÄìWe outline and structure an extensive, up-to-date body of research literature\non NLP fairness, AI fairness and fairness auditing from the last years.\n‚ÄìWe describe our qualitative research approach, which is based on a series\nof semi-structured interviews with 14 experts from various areas related to\nNLP and algorithmic fairness.\n‚ÄìWe devise a hierarchical coding scheme for the certification of fairness for\nNLP approaches.\n‚ÄìWe provide an overview of the six main criteria, with 18 sub-cr"}
{"date": "2024-01-03-18-23", "error": false, "url": "PDF", "text_blocks": " \n  \n1 Optimal Synthesis of Finite State Machines with Universal Gates using \nEvolutionary Algorithm  \n1Noor Ullah , 2 Khawaja  M. Yahya, 3 Irfan Ahmed  \n1,2,3 Department of Electrical Engineering  \nUniversity of Engineering and Technology, Peshawar, Pakistan.  \nE-mail:  1noorullah51@gmail.com , 2yahyakm@yahoo.com , 3irfanahmed@nwfpuet.edu.pk  \n \nABSTRACT  \n \nThis work presents an optimization method for the synthesis of finite state machines. The focus is on the reduction in the on -\nchip area and the cost of the circuit. A list of finite state machines from MCNC91 benchmark circuits have been evolved using  \nCartesian Genetic Programming. On the average, almost 30% of reduction in the total number of gates has been achieved. The \neffects of some parameters on the evolutionary process have also been discussed in the paper . \n \nKeywords:  Cartesian Genetic Programming, Finite State Machines, Genetic Algorithms.  \n \n \n1.  INTRODUCTION  \n \n Circuit size and cost are among the main issues in \ndigital circuit design these days. Finite State Machines (FSMs) \nare considered as the heart of sequential systems. FSMs are \ngenerally referred to the two models of sequential digital \ncircuits namely Mealy and Moore models. Mealy model \ndescribes the output of a system as a function of both the input \nand current state.  Moore model expresses it in terms of the \ncurrent state only. These sequential systems consist of \ncombinational logic circuits, which are connected to the \nstorage elements making feedback path. Designing of FSMs \ninvolves seven crucial steps [1]. One of the most vital steps is \nto obtain optimal state equations, which include input and \noutput variables. This is an indispensable step towards an \nefficient, small and cost effective hardware design.  \n \nThis paper focuses on the objective to obtain an optimal \ncombinational logic circuit for the FSM. The primary goal is \nto reduce the number of gates as much as possible. This leads \nto a reduction in total number of MOSFETs, which saves the \non-chip area of FSMs and reduces the cost of circuit as well.  \n \nMany researchers have worked on the optimization of \nFSMs using different techniques. A symbolic description of \nFSMs has been considered for logic minimization in PLA \nbased machines [2]. S. Devadas  introduced algorithms using \nmigration and utilization of don‚Äôt -care sequences [3]. Cellular \nautomata based synthesis scheme for sequential circuits has \nbeen described [4]. Different genetic algorithms have been \nproposed in the area [5 -9]. Heuristic algorithms for two level \nlogic and two -hot encoding have been introduced [10] ,[11]. R. \nS. Shelar  et. al.,  have decomposed FSMs into two interactive \nmachines [12]. Mean Field Annealing based solution of graph -\nembedding problem has been given [13]. L. Yuan et. al.,  have \ndevised a state splitting technique for FSMs [14]. The \naforementioned research work is mainly aimed at one of the \ntwo goals or both: First to reduce the number of states that \ndescribe the behavior of FSMs. Secondly, to encode the states \nwith such binary sequences that the switching between the \nstates is minimized. In any case the purpose is a reduction in \ntotal area either as a primary objective or secondary. Three \nMCNC benchmark FSMs have also been evolved using a \nGenetic Programming (GP) [15]. However the above research evolves FSMs using many types of logic gates. Shanti et. al.,  \nhave presented the evolution of asynchronous sequential \ncircuits using developmental Cartesian Genetic Programming \n[16]. The research was carried out to evolve the combinational \npart for each memory element individually.  \nIn this paper, the evolution of combinational logic part of \nFSMs has been proposed using Cartesian Genetic \nProgramming (CGP). The circuits are evolved with universal \ngates (NAND and NOR) only. The evolution encompasses all \nthe state elements and the outputs of the system together in the \nsame program. The benefit of the combined evolution is that \nmany redundant nodes are removed. This results in very \ncompact circuit architecture. The rest of the paper is organized \nin the following manner. Section 2 gives an overview of CGP. \nSection 3 describes the detailed experimental setup. Section 4 \nis about the simulation process and results of the experiments. \nSection 5 concludes the paper.  \n \n2.  CARTESIAN GENETIC PROGRAMMING  \n \nCGP is a variant of GP, which was invented for the \nevolution of digital circuits by Miller  and Thompson  [17]. In \nCGP programs are represented as directed acyclic graphs in \ncontrast to the conventional tree -based GP. This allows the \nindirect reuse of the nodes. In start the CGP graphs were \nrepresented by two -dimensional grid of nodes. Any number of \nrows, columns and level backs could be chosen by the user, \ncreating a number of different topologies. Later work showed \nthat a special case, having a single row with level backs equal \nto the number of columns was more effective [18].  \n \n"}
{"date": "2024-01-03-18-23", "error": false, "url": "PDF", "text_blocks": "1\nf-Divergence Based Classification: Beyond the Use\nof Cross-Entropy\nNicola Novello and Andrea M. Tonello\nAbstract ‚ÄîIn deep learning, classification tasks are formalized\nas optimization problems solved via the minimization of the\ncross-entropy. However, recent advancements in the design of\nobjective functions allow the f-divergence measure to generalize\nthe formulation of the optimization problem for classification.\nWith this goal in mind, we adopt a Bayesian perspective and\nformulate the classification task as a maximum a posteriori\nprobability problem. We propose a class of objective functions\nbased on the variational representation of the f-divergence, from\nwhich we extract a list of five posterior probability estimators\nleveraging well-known f-divergences. In addition, driven by\nthe challenge of improving the state-of-the-art approach, we\npropose a bottom-up method that leads us to the formulation\nof a new objective function (and posterior probability estimator)\ncorresponding to a novel f-divergence referred to as shifted log\n(SL). First, we theoretically prove the convergence property of the\nposterior probability estimators. Then, we numerically test the\nset of proposed objective functions in three application scenarios:\ntoy examples, image data sets, and signal detection/decoding\nproblems. The analyzed tasks demonstrate the effectiveness of\nthe proposed estimators and that the SL divergence achieves the\nhighest classification accuracy in almost all the scenarios.\nIndex Terms ‚ÄîClassification, decoding, estimation, KL diver-\ngence, f-divergence, MAP, neural networks, cross-entropy, deep\nlearning, ML, discriminative AI.\nI. I NTRODUCTION\nClassification problems are relevant for a multitude of do-\nmains, such as computer vision, biomedical, and telecommu-\nnications engineering [1]‚Äì[3]. In general, classification refers\nto the estimation of a discrete vector x(i.e., the class) given\nan observation vector y. In the Bayesian framework, the\noptimal method to solve classification problems is derived\nfrom the maximum a posteriori probability (MAP) principle\n[4]. Classical estimation theory uses a model-based approach\nto formulate such an estimation algorithm. Then, the MAP\ntask is well-defined and solvable when the posterior density\nis known. If the posterior probability is unknown, the first\nfundamental task towards solving a MAP problem consists of\nlearning the posterior density from the data. In this direction,\ndeep learning (DL) approaches have been developed in the\nabsence of a model, i.e., they learn the model and solve\nthe estimation task directly via data observation. The use\nof artificial neural networks is motivated by their sufficient\nexpressiveness in modeling probability density functions as\nshown in [5]‚Äì[8]. DL models require the design of two main\nelements: the network architecture, which defines the class of\nfunctions the network can estimate, and the objective function\nthat is exploited during the training phase to learn the optimal\nThe authors are with the Institute of Networked and Embedded\nSystems, University of Klagenfurt, 9020 Klagenfurt, Austria. (emails:\nnicola.novello@aau.at, andrea.tonello@aau.at)parameters of the network. In reference to neural network-\nbased classification techniques, most of the previous work\nfocused on the conceievement of the network architecture [9]‚Äì\n[13]. Contrarily, a smaller part of classification literature is\ndedicated to the objective function design. In most cases, clas-\nsification is achieved through the minimization of the cross-\nentropy loss function between the data empirical probability\ndistribution pdata and the distribution output of the neural\nnetwork pmodel [14], [15]. The minimization of the cross-\nentropy corresponds to the minimization of the Kullback-\nLeibler (KL) divergence between the same two probability\ndistributions, defined as\nDKL(pdata||pmodel ) =Epdata\u0014\nlog\u0012pdata\npmodel\u0013\u0015\n,(1)\nsince the term Epdata[log (pdata)]does not depend on the\nmodel parameters.\nThe intuitive idea to generalize (1) through the use of the\nf-divergence is not realizable, as shown in [16] (see Appendix\nB). Thus, the authors in [16] propose a min-max game for\nthe objective function design of deep energy-based models,\nwhere they substitute the minimization of the KL with\nanyf-divergence. In [17], the authors propose a max-max\noptimization problem to tackle classification with noisy labels.\nThey maximize the f-mutual information (a generalization\nof mutual information) between the classifier‚Äôs output and\nthe true label distribution. In [18], the f-divergence is used\nas a regularization term in a min-max optimization problem,\nfor the design of fair classifiers (i.e., minimize the classifier\ndiscrepancy over sub-groups of the population).\nDifferently, in this paper, we propose to estimate the con-\nditional posterior probability (needed in the MAP classifier)\nby expressing it as a density ratio (see (9)) and by using a\ndiscriminative learning approach [19]. Density ratio es"}
{"date": "2024-01-03-18-23", "error": false, "url": "PDF", "text_blocks": "LLbezpeky: Leveraging Large Language Models for\nVulnerability Detection\nNoble Saji Mathews\nUniversity of Waterloo, Canada\nnoblesaji.mathews@uwaterloo.caYelizaveta Brus\nUniversity of Waterloo, Canada\nybrus@uwaterloo.caYousra Aafer\nUniversity of Waterloo, Canada\nyousra.aafer@uwaterloo.ca\nMei Nagappan\nUniversity of Waterloo, Canada\nmei.nagappan@uwaterloo.caShane McIntosh\nUniversity of Waterloo, Canada\nshane.mcintosh@uwaterloo.ca\nAbstract\nDespite the continued research and progress in building se-\ncure systems, Android applications continue to be ridden\nwith vulnerabilities, necessitating effective detection meth-\nods. Current strategies involving static and dynamic analysis\ntools come with limitations like overwhelming number of\nfalse positives and limited scope of analysis which make\neither difficult to adopt. Over the past years, machine learn-\ning based approaches have been extensively explored for\nvulnerability detection, but its real-world applicability is\nconstrained by data requirements and feature engineering\nchallenges. Large Language Models (LLMs), with their vast\nparameters, have shown tremendous potential in understand-\ning semnatics in human as well as programming languages.\nWe dive into the efficacy of LLMs for detecting vulnerabili-\nties in the context of Android security. We focus on building\nan AI-driven workflow to assist developers in identifying\nand rectifying vulnerabilities. Our experiments show that\nLLMs outperform our expectations in finding issues within\napplications correctly flagging insecure apps in 91.67% of\ncases in the Ghera benchmark. We use inferences from our\nexperiments towards building a robust and actionable vul-\nnerability detection system and demonstrate its effectiveness.\nOur experiments also shed light on how different various\nsimple configurations can affect the True Positive (TP) and\nFalse Positive (FP) rates.\n1 INTRODUCTION\nDespite advancements in building secure systems and exten-\nsive research in the area, Android applications remain prone\nto a range of vulnerabilities and even vulnerability reintro-\nduction for fixed issues [ 1,5], creating a pressing demand\nfor effective vulnerability detection methodologies. Current\napproaches to tackle this primarily revolve around static\nand dynamic analysis tools [ 10]. However, they have their\ndistinct limitations, such as vast false positives in the case\nof static analysis tools [ 3] and an overwhelming amount of\neffort that goes into building these frameworks and adapting\nthem to newer vulnerability types.\nIn the past few years, there have also been numerous\nexplorations into the use of machine learning to uncovervulnerabilities [ 10], however, the applicability of these re-\nmains limited in real-world settings due to the vast amount\nof training data required and an explicit focus on feature\nengineering to approximate the complexity of the systems\nbeing analyzed. With the advent of LLMs, huge billion pa-\nrameter models have pushed the boundaries of what was\nthought achievable through an Artificially Intelligent sys-\ntem. These are believed to acquire ‚Äúembodied knowledge\nabout syntax, semantics, and ontology inherent in human\nlanguage‚Äù [ 8] and have also shown significant power when\ndealing with programming languages due to their relatively\nsimpler underlying Grammar and Semantics [ 6]. This brings\na question to mind, How good are these Language Models\nat detecting vulnerabilities?. There have been several recent\nexplorations into the use of these large language models\nand improving their efficacy for vulnerability detection in\ngeneral, and these have shown promising results [9].\nCurrent work in the literature has looked at the perfor-\nmance of GPT-based models for the task of vulnerability\ndetection in code [ 4], Cheskov et al. report it to be not very\neffective but they employ a very simplistic approach. Other\nrecent work has shown that extended prompting and LLM-\ndriven methods complemented by other techniques have\nyielded more accurate results than simple prompting for de-\ntecting CWEs present in code [ 2,11]. There has also been\na much more detailed exploration that looks into various\naspects of using LLMs for software security with promising\nresults [14].\nWe explore this area further in the context of Android\nSecurity, attempting to build an AI-enabled workflow that\nwould enable developers to detect and aide in remediating\nvulnerabilities or even aid developers in writing secure code\nby acting as a pair programmer. Do note that fine-tuning\nmodels or training our own LLM is out of scope of this\nresearch, we primarily seek to explore if and how the latent\nknowledge present in these LLMs can be used for Android\nanalysis.\nFor this exploration into the use of new and emerging tech-\nnologies it is critical we lay out a few fundamental questions,\nto begin with, and direct our efforts. We attempt to answer asarXiv:2401.01269v1  [cs.CR]  2 Jan 2024CS858, Project Proposal, LLbezpeky Noble Saji Mathews, Yelizaveta Brus, Yousra A"}
{"date": "2024-01-03-18-23", "error": false, "url": "PDF", "text_blocks": "Optimal Rates of Kernel Ridge Regression under Source Condition in Large Dimensions\nOptimal Rates of Kernel Ridge Regression under Source\nCondition in Large Dimensions\nHaobo Zhang zhang-hb21@mails.tsinghua.edu.cn\nYicheng Li liyc22@mails.tsinghua.edu.cn\nWeihao Lu luwh19@mails.tsinghua.edu.cn\nQian Lin‚àóqianlin@tsinghua.edu.cn\nCenter for Statistical Science, Department of Industrial Engineering\nTsinghua University\nAbstract\nMotivated by the studies of neural networks (e.g.,the neural tangent kernel theory),\nwe perform a study on the large-dimensional behavior of kernel ridge regression (KRR)\nwhere the sample size n‚âçdŒ≥for some Œ≥ > 0. Given an RKHS Hassociated with an\ninner product kernel defined on the sphere Sd, we suppose that the true function f‚àó\nœÅ‚àà[H]s,\nthe interpolation space of Hwith source condition s >0. We first determined the exact\norder (both upper and lower bound) of the generalization error of kernel ridge regression\nfor the optimally chosen regularization parameter Œª. We then further showed that when\n0< s‚â§1, KRR is minimax optimal; and when s >1, KRR is not minimax optimal (a.k.a.\nthe saturation effect ). Our results illustrate that the curves of rate varying along Œ≥exhibit\ntheperiodic plateau behavior and the multiple descent behavior and show how the curves\nevolve with s >0. Interestingly, our work provides a unified viewpoint of several recent\nworks on kernel regression in the large-dimensional setting, which correspond to s= 0 and\ns= 1 respectively.\nKeywords: kernel methods, high-dimensional statistics, reproducing kernel Hilbert space,\nminimax optimality, saturation effect\n1. Introduction\nThe recent studies of neural network theory have brought the renaissance of kernel methods,\nsince the neural tangent kernel (Jacot et al., 2018) provides a natural surrogate to understand\nthe wide neural network (Arora et al., 2019; Lee et al., 2019; Lai et al., 2023). When the\ndimension of data is fixed, there has been extensive literature studying the generalization\nbehavior of kernel ridge regression (KRR), one of the most popular kernel methods, e.g.,\nCaponnetto and de Vito (2007); Fischer and Steinwart (2020); Cui et al. (2021), etc..\nResearchers usually use two crucial factors to characterize KRR‚Äôs generalization behavior:\ncapacity condition andsource condition . Supposing eigenvalues associated with the RKHS\nHare{Œªi}‚àû\ni=1, the capacity condition (also known as effective dimension) assumes N1(Œª) :=P‚àû\ni=1Œªi/(Œªi+Œª)‚âçŒª‚àí1\nŒ≤for some Œ≤ >1, where Œªwill represent the regularization parameter\n‚àó. Corresponding author\n1arXiv:2401.01270v1  [cs.LG]  2 Jan 2024Zhang, Li, Lu and Lin\n(a)\n (b)\nFigure 1: Left: The curve of generalization error for estimating f‚àó\nœÅ‚ààL2(Figure 5 in\nGhorbani et al. (2021)). Right: The curve of the minimax rates for estimating\nf‚àó\nœÅ‚àà H(Figure 2(b) in Lu et al. (2023)).\nin KRR. The capacity condition characterizes the size of Hand is frequently stated as\nan equivalent eigenvalue decay condition: Œªi‚âçi‚àíŒ≤, Œ≤ > 1. The source condition assumes\nthat the true function f‚àó\nœÅfalls into [ H]s, an interpolation space of Hfor some s >0. It\ncharacterizes the relative smoothness of f‚àó\nœÅwith respect to H: the larger sis, the ‚Äúsmoother‚Äù\nf‚àó\nœÅis and the easier it can be estimated. Under this framework, many interesting topics\nabout KRR‚Äôs generalization behavior were studied. For instance, the minimax optimality of\nKRR (Fischer and Steinwart, 2020; Zhang et al., 2023b) when 0 < s‚â§2, the saturation\neffect of KRR (Bauer et al., 2007; Li et al., 2023b) when s >2, the generalization ability\nof kernel interpolation (Beaglehole et al., 2023; Li et al., 2023a) and the learning curve of\nKRR (Cui et al., 2021; Li et al., 2023c), etc. We refer to Section 1.1 for more related work\nabout these topics. These results help us clarify several puzzle points. For example, Li\net al. (2023b) implies that when the true function is smooth enough (e.g., s >2), the early\nstopping kernel gradient flow is often better than the kernel ridge regression and Li et al.\n(2023a) asserts that if a wide neural network overfits the data, it generalizes poorly.\nSince neural networks often perform well on data with large dimensionality where n‚âçdŒ≥\nfor some Œ≥ >0, we expect that the studies of kernel regression in large-dimensional data\ncan provide us more guidance about the generalization behavior of neural network for\nlarge-dimensional data. However, in contrast to the rich theoretical results about kernel\nregression in the fixed-dimensional setting, much less is known about the aforementioned\ntopics in the large-dimensional setting. Since Karoui (2010) provided an approximation of\nthe kernel random matrix when n‚âçd, few works have been done for kernel regression in\nlarge-dimensional or high-dimensional settings until recently. The first obstacle is that if d\nis large, the eigenvalues of the RKHS usually depend on din an unpleasant way. Therefore,\nthe polynomial eigenvalue decay rate assumption Œªi‚âçi‚àíŒ≤must not be true (e.g., the inner\nproduct kernel on the "}
{"date": "2024-01-03-18-23", "error": false, "url": "PDF", "text_blocks": "MOC-RVQ: Multilevel Codebook-assisted Digital Generative\nSemantic Communication\nYingbin Zhou1Yaping Sun2,1Guanying Chen1Xiaodong Xu3,2\nHao Chen2Binhong Huang2Shuguang Cui1,2Ping Zhang3,2\n1FNii and SSE, The Chinese University of Hong Kong, Shenzhen, China\n2Peng Cheng Laboratory, Shenzhen, China\n3Beijing University of Posts and Telecommunications, Beijing, China\nAbstract ‚ÄîVector quantization-based image semantic commu-\nnication systems have successfully boosted transmission efficiency,\nbut face a challenge with conflicting requirements between\ncodebook design and digital constellation modulation. Traditional\ncodebooks need a wide index range, while modulation favors few\ndiscrete states. To address this, we propose a multilevel generative\nsemantic communication system with a two-stage training frame-\nwork. In the first stage, we train a high-quality codebook, using\na multi-head octonary codebook (MOC) to compress the index\nrange. We also integrate a residual vector quantization (RVQ)\nmechanism for effective multilevel communication. In the second\nstage, a noise reduction block (NRB) based on Swin Transformer\nis introduced, coupled with the multilevel codebook from the first\nstage, serving as a high-quality semantic knowledge base (SKB)\nfor generative feature restoration. Experimental results highlight\nMOC-RVQ‚Äôs superior performance over methods like BPG or\nJPEG, even without channel error correction coding.\nIndex Terms ‚Äîvector quantization, generative semantic com-\nmunication, two-stage training, semantic knowledge base\nI. I NTRODUCTION\nTraditional communication systems focus on the bit/symbol-\nlevel transmission, where the receiver seeks to minimize\nbit/symbol transmission errors to recover digital media [1].\nThis allows the design of communication system architecture\nto be separated from the vast and complex content of media.\nAs a result, bit/symbol-based transmission has long been the\nprevailing paradigm in traditional communication systems.\nRecently, propelled by the rapid development of deep learn-\ning technology, a new intelligent transmission paradigm known\nas semantic communication is gradually gaining prominence.\nIn contrast to traditional transmission, semantic communica-\ntion aims for the transmission of semantic fidelity [2]. For\nexample, Dai et al . [3] integrate the nonlinear transform as\na robust prior to efficiently extract source semantic features.\nYang et al . [4] introduce a deep joint source-channel coding\n(JSCC) strategy designed for the transmission of images in\nwireless communication. Sun et al . [5] design a multi-level\nsemantic coding and feature transmission mechanism powered\nby semantic knowledge base. However, these works suffer\nfrom efficiency issues, due to the high dimension of latent\nrepresentation of raw data.\nOne solution to achieve a compact representation is vector\nquantization (VQ) technique [6] . Generally, VQ transforms\nsemantic features into a series of indices, providing a more\ncompact format that can be further converted into bits fortransmission, then the receiver utilizes the received indices\nto reconstruct the semantic features through a pre-established\nlearned codebook. Ultimately, the raw data or the task-oriented\ninformation can be decoded from these reconstructed semantic\nfeatures. Nemati et al. [7] delve into the characteristics of VQ-\nV AE and adapt its training process to formulate a robust JSCC\nscheme against noisy wireless channels. Fu et al. [8] design a\nCNN-based transceiver to extract multi-scale semantic features\nand incorporate multi-scale semantic embedding spaces to\nfacilitate feature quantization. To improve semantic represen-\ntation in digital transmission under resource limitations, Guo\net al . [9] introduce a novel non-linear quantization module\nwith trainable levels for efficient feature extraction.\nHowever, methods above suffer the following two issues:\n‚Ä¢Incompatible issue arises from the disparity between\nconventional vector quantization and digital constellation\nmodulation. The former, aimed at achieving optimal\nimage representation, employs a learnable codebook with\na wide range of code indices. In contrast, the latter is more\ninclined to handle fewer states (e.g., 16-QAM, 64-QAM,\netc.). While it is conceivable to regroup bits representing\nindices to align with modulation, such an adjustment\nalso disrupts the explicit relationship between indices and\nconstellation points. Note that this explicit relationship\nis crucial for preserving the local semantic relationship\nof the underlying neighbour code vectors, which directly\naffects the quality of reconstructed image.\n‚Ä¢Mismatch issue occurs in the local relationship between\ncode indices and code vectors, which renders vector\nquantization-based semantic communication systems sus-\nceptible to channel noise. For instance, while the differ-\nence between index \"1\" and index \"2\" is 1, the distance\nbetween the underlying code vectors of index \"1\" and\nindex \"2\" can be substantial. This mismatch may lead"}
{"date": "2024-01-03-18-23", "error": false, "url": "PDF", "text_blocks": "Learning-based agricultural management in partially\nobservable environments subject to climate variability\nZhaoan Wanga, Shaoping Xiaoa, Junchao Lia, Jun Wangb\naDepartment of Mechanical Engineering, Iowa Technology Institute, University of\nIowa, 3131 Seamans Center, Iowa City, 52242, Iowa, USA\nbDepartment of Chemical and Biochemical Engineering, Iowa Technology Institute,\nUniversity of Iowa, 4133 Seamans Center, Iowa City, 52242, Iowa, USA\nAbstract\nAgricultural management, with a particular focus on fertilization strategies,\nholds a central role in shaping crop yield, economic profitability, and environ-\nmental sustainability. While conventional guidelines offer valuable insights,\ntheir efficacy diminishes when confronted with extreme weather conditions,\nsuch as heatwaves and droughts. In this study, we introduce an innovative\nframework that integrates Deep Reinforcement Learning (DRL) with Re-\ncurrent Neural Networks (RNNs). Leveraging the Gym-DSSAT simulator,\nwe train an intelligent agent to master optimal nitrogen fertilization man-\nagement. Through a series of simulation experiments conducted on corn\ncrops in Iowa, we compare Partially Observable Markov Decision Process\n(POMDP) models with Markov Decision Process (MDP) models. Our re-\nsearch underscores the advantages of utilizing sequential observations in de-\nveloping more efficient nitrogen input policies. Additionally, we explore the\nimpact of climate variability, particularly during extreme weather events,\non agricultural outcomes and management. Our findings demonstrate the\nPreprint submitted to Elsevier June 2023arXiv:2401.01273v1  [cs.LG]  2 Jan 2024adaptability of fertilization policies to varying climate conditions. Notably,\na fixed policy exhibits resilience in the face of minor climate fluctuations,\nleading to commendable corn yields, cost-effectiveness, and environmental\nconservation. However, our study illuminates the need for agent retraining\nto acquire new optimal policies under extreme weather events. This research\ncharts a promising course toward adaptable fertilization strategies that can\nseamlessly align with dynamic climate scenarios, ultimately contributing to\nthe optimization of crop management practices.\nKeywords: Fertilization Management, Reinforcement Learning, Recurrent\nNeural Networks, Partially Observable Environments, Decision-making,\nClimate Variability\n1. Introduction\nAccording to a 2022 report from the United States Department of Agri-\nculture (USDA) [1], total farm production nearly tripled from 1948 to 2017.\nHowever, despite the growth, there remains a global food shortage. The Food\nand Agriculture Organization (FAO) estimated that approximately 828 mil-\nlion people were experiencing hunger in 2022. Given this pressing issue, it\nbecomes imperative to leverage new technologies to boost farm production,\nand one such solution is Precision Agriculture (PA) [2]. Precision agricul-\nture, also known as ‚Äúprecision farming‚Äù or ‚Äúprescription farming,‚Äù utilizes\ninformation and technology-based agricultural management systems. These\n2systems enable farmers to precisely tailor their soil and crop management\npractices to various weather/soil conditions on individual farmlands.\nIn a modern community, PA is an emerging field aimed at enhancing the\nefficiency and sustainability of agricultural practices [3]. Precision agricul-\nture often employs advanced technologies such as remote sensing, robotics,\nMachine Learning (ML), and Artificial Intelligence (AI) techniques. Mon-\nitoring plant health and detecting diseases are vital aspects of sustainable\nagriculture. Yet, manual disease detection is labor-intensive, necessitating\nsignificant expertise, effort, and extended processing time. Researchers have\nturned to image recognition algorithms as a solution, achieving promising\nresults in plant disease identification [4]. Additionally, AI‚Äôs potential in fore-\ncasting crop yields has gained significant attention. Some researchers have\nused satellite imagery to develop models that predict yields, often incorpo-\nrating crop identification maps and meteorological data. These models have\nbeen applied to forecast yields for crops such as wheat, rice, cotton, and sug-\narcane, especially in regions like the Indus Basin in Pakistan, demonstrating\nsatisfactory performance [5].\nAs one of the important components in PA, learning-based agricultural\nmanagement represents a substantial departure from traditional farming meth-\nods, which often rely on human intuition and experience. Learning-based\nagricultural management adopts a more data-driven approach [6] with the\noverarching goals of increasing efficiency, reducing waste, protecting the en-\nvironment, and improving the sustainability of farming practices. A notable\n3example is seen in the work of Vij and co-authors [7], who predicted the\nirrigation needs of farmland. They achieved this by using intelligent systems\nto monitor ground parameters, including soil moisture, soil temperature, and\nenvironmenta"}
{"date": "2024-01-03-18-23", "error": false, "url": "PDF", "text_blocks": "CharacterEval : A Chinese Benchmark for Role-Playing\nConversational Agent Evaluation\nQuan Tu‚ô†, Shilong Fan‚ô£, Zihang Tian‚ô†, Rui Yan‚ô†‚àó\n‚ô†Gaoling School of Artificial Intelligence, Renmin University of China\n‚ô£School of Artificial Intelligence, Beijing University of Posts and Telecommunications\n‚ô†{quantu,tzh2003,ruiyan}@ruc.edu.cn\n‚ô£fansl@bupt.edu.cn\nAbstract\nRecently, the advent of large language models\n(LLMs) has revolutionized generative agents.\nAmong them, Role-Playing Conversational\nAgents (RPCAs) attract considerable atten-\ntion due to their ability to emotionally engage\nusers. However, the absence of a compre-\nhensive benchmark impedes progress in this\nfield. To bridge this gap, we introduce Char-\nacterEval , a Chinese benchmark for compre-\nhensive RPCA assessment, complemented by\na tailored high-quality dataset. The dataset\ncomprises 1,785 multi-turn role-playing dia-\nlogues, encompassing 23,020 examples and\nfeaturing 77 characters derived from Chinese\nnovels and scripts. It was carefully constructed,\nbeginning with initial dialogue extraction via\nGPT-4, followed by rigorous human-led quality\ncontrol, and enhanced with in-depth character\nprofiles sourced from Baidu Baike. Charac-\nterEval employs a multifaceted evaluation ap-\nproach, encompassing thirteen targeted metrics\non four dimensions. To facilitate the conve-\nnient evaluation for these subjective metrics in\nCharacterEval , we further developed Charac-\nterRM, a role-playing reward model based on\nhuman annotations, which has a higher cor-\nrelation with human judgment compared to\nGPT-4. Comprehensive experiments on Char-\nacterEval demonstrate that Chinese LLMs ex-\nhibit more promising capabilities than GPT-4\nin Chinese role-playing conversation. Source\ncode, data source and reward model will be pub-\nlicly accessible at https://github.com/\nmorecry/CharacterEval .\n1 Introduction\nThe development of large language models (LLMs)\nhas marked the beginning of a new era in conver-\nsational AI (Zhao et al., 2023; Chang et al., 2023),\nand opened up a wide range of application possibil-\nities, particularly in agent-based interactions (Park\net al., 2023; Wang et al., 2023a; Gao et al., 2023).\n‚àóCorresponding author: Rui Yan (ruiyan@ruc.edu.cn).The automated agents, equipped with the emerg-\ning capabilities of LLMs such as planning (Silver\net al., 2022; Ge et al., 2023; Song et al., 2023), rea-\nsoning (Wei et al., 2022; Wang et al., 2022), and\nin-context learning (Dong et al., 2022; Brown et al.,\n2020), can perform complex tasks for humans with-\nout any supervision. Among the diverse agents,\nthe Role-Playing Conversational Agent (RPCA),\ndesigned to offer emotional value instead of the\nproductivity, attracts amount of interest.\nRPCA represents a unique category within the\nrealm of conversational agents, distinguished by\ntheir capability for immersive interaction (Li et al.,\n2023). Different from traditional dialogue sys-\ntems, which typically focus on chit-chat (Yan et al.,\n2022), knowledge-based (Chen et al., 2020), per-\nsonalized (Zheng et al., 2019) and empathetic di-\nalogue (Ma et al., 2020), RPCAs engage users in\ndynamic scenarios, where LLM agents are assumed\nas specific characters or roles, often derived from\nexisting composition such as novels, films, car-\ntoons, and games. The development of connections\nbetween fictional characters and humans has the\npotential to not only deepen the impact of cultural\nworks but also improve human engagement. Fur-\nthermore, RPCAs hold significant application value\nin their ability to offer emotional value to users,\npositioning fictional characters as virtual friends.\nThe multifaceted nature of RPCAs has sparked\nconsiderable attention, leading to a surge in both\nresearch (Shao et al., 2023; Wang et al., 2023c; Tu\net al., 2023; Zhou et al., 2023) and application de-\nvelopment (e.g., Character AI1, Tongyi Xingchen2\nand Glow3). However, these implementations of\nRPCAs vary significantly in both approach and ob-\njectives, presenting a challenge in systematically\nassessing and comparing their capabilities. There-\nfore, we propose the CharacterEval , a Chinese\n1https://beta.character.ai\n2https://xingchen.aliyun.com/xingchen\n3https://www.glowapp.tech/\n1arXiv:2401.01275v1  [cs.CL]  2 Jan 2024ÁßÄÊâçÔºåÊò®Â§©Êôö‰∏äÂêÉ‰∫ÜÊ≤°ÊúâÔºü\nXiuc√°i, did you have dinner last night?\nÔºàÊó†Á≤æÊâìÈááÔºâÂêÉ‰∏çÂêÉ‰πüÂ∞±ÊòØÈÇ£‰πàÂõû‰∫ãÂÑø„ÄÇ\n(Lethargically) Eating or not, it's all the same anyway.\nÊò®Â§©ÁöÑÂ∏êÈÉΩÊ∏ÖÂπ≤ÂáÄÊ≤°ÊúâÔºü\nDid you settle all the accounts from yesterday?\nÂ∫îËØ•ÊòØÂêß„ÄÇÔºàÂõûÂ§¥ÊãøË¥¶Êú¨ÁúãÔºâÂïäÔºåÊ∏ÖÂπ≤ÂáÄ‰∫Ü„ÄÇ\nI suppose so. (turns back to check the ledger) \nAh, it's all cleared up.\nÂï•Âè´Â∫îËØ•ÊòØÔºüÔºàÊãøËøáË¥¶Êú¨ÁúãÔºåÊãçÂú®ÊüúÂè∞‰∏äÔºåÊåáÁùÄÔºâËøô\nÂè´Ê∏ÖÂπ≤ÂáÄ‰∫ÜÔºüWhat do you mean 'suppose so'?(Grabs the \nledger, slaps it on the counter, and points at it) \nIs this what you call 'cleaned up'?\nÔºàÁúãË¥¶Êú¨ÔºâÂïäÔºü\n(Looking at the ledger) Huh?Âú∫ÊôØÔºö‰ΩüÊπòÁéâÂú®ÊüúÂè∞Â§ÑË¥®ÈóÆÂêïÁßÄÊâçÊò®Â§©ÁöÑË¥¶ÁõÆÊòØÂê¶Ê∏ÖÁêÜÂπ≤ÂáÄÔºå\nÈöèÂêé‰∏§‰∫∫Â∞±Â∑•‰Ωú‰∏≠ÁöÑÈóÆÈ¢òÂèëÁîü‰∫Ü‰∫âÊâß„ÄÇ\nScene: Tong Xiangyu, at the counter, questions Lv Xiucai whether he \nhas cleared yesterday's accounts properly. Subsequently, the two of them \nget into an argument over issues related to their work.        ÂßìÂêç: ‰ΩüÊπòÁéâ   \n        Name: Xian"}
