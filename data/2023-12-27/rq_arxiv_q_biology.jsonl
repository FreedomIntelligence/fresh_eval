{"date": "2023-12-27-22-36", "error": false, "url": "PDF", "text_blocks": "DTIAM: A unified framework for predicting\ndrug-target interactions, binding affinities and\nactivation/inhibition mechanisms\nZhangli Lu1, Chuqi Lei1, Kaili Wang1, Libo Qin1, Jing Tang2\nand Min Li1*\n1*School of Computer Science and Engineering, Central South\nUniversity, Changsha, 410083, China.\n2Research Program in Systems Oncology, Faculty of Medicine,\nUniversity of Helsinki, Helsinki, FI00014, Finland.\n*Corresponding author(s). E-mail(s): limin@mail.csu.edu.cn;\nAbstract\nAccurate and robust prediction of drug-target interactions (DTIs) plays\na vital role in drug discovery. Despite extensive efforts have been invested\nin predicting novel DTIs, existing approaches still suffer from insuffi-\ncient labeled data and cold start problems. More importantly, there is\ncurrently a lack of studies focusing on elucidating the mechanism of\naction (MoA) between drugs and targets. Distinguishing the activation\nand inhibition mechanisms is critical and challenging in drug develop-\nment. Here, we introduce a unified framework called DTIAM, which\naims to predict interactions, binding affinities, and activation/inhibi-\ntion mechanisms between drugs and targets. DTIAM learns drug and\ntarget representations from large amounts of label-free data through\nself-supervised pre-training, which accurately extracts the substructure\nand contextual information of drugs and targets, and thus benefits the\ndownstream prediction based on these representations. DTIAM achieves\nsubstantial performance improvement over other state-of-the-art meth-\nods in all tasks, particularly in the cold start scenario. Moreover,\nindependent validation demonstrates the strong generalization ability of\nDTIAM. All these results suggested that DTIAM can provide a prac-\ntically useful tool for predicting novel DTIs and further distinguishing\nthe MoA of candidate drugs. DTIAM, for the first time, provides a\nunified framework for accurate and robust prediction of drug-target\ninteractions, binding affinities, and activation/inhibition mechanisms.\n1arXiv:2312.15252v1  [q-bio.BM]  23 Dec 20232 A unified framework for drug-target prediction\n1 Introduction\nAccurately predicting drug-target interactions (DTIs) is an essential step in\ndrug discovery and development [1, 2]. The biochemical experimental method\nfor identifying new DTIs on a large scale is still expensive and time-consuming\n[3–5], despite the wide application of various experimental assays in drug dis-\ncovery. Various computational methods have been applied to drug discovery\nand successfully predict novel DTIs, and they can substantially reduce devel-\nopment time and costs [6–8]. Current computational methods mainly focus\non the binary prediction of DTI or the regression prediction of drug-target\nbinding affinity (DTA).\nIn binary classification-based DTI prediction studies, the goal is to pre-\ndict whether there is an interaction between the drug and the target or not.\nGenerally, the approaches for in silico DTI prediction can be divided into two\nmajor categories: structure-based approaches and structure-free approaches.\nStructure determination of compound-protein complexes can provide insights\ninto the mode of action and thus significantly facilitate lead compound selec-\ntion and optimization in the target-based drug discovery [9, 10]. There are\nmany structure-based approaches, such as molecular docking [11], molecu-\nlar dynamics simulations [12], pharmacophore modeling [13] and GOLD [14],\nwhich are widely applied in virtual screening of drugs binding with proteins.\nHowever, these methods generally fail to predict binding affinities when the\nthree-dimensional (3D) structure of the target protein is unknown, and require\ntremendous computational resources. To overcome the current limitations of\nthe structure-based methods, various structure-free models have been devel-\noped for DTI prediction [15–18]. An example is the network-based inference\n(NBI) methods that construct reliable networks from several data resources\n(e.g., chemical, genomics, proteomics, and pharmacology) and exploit the\ntopological and structural information in the networks for potential associa-\ntion prediction [19–22]. For instance, Luo et al. [23] develop a computational\npipeline, called DTINet, to predict novel DTIs from a heterogeneous network\nconstructed by integrating diverse drug-related information. Another promis-\ning approach for predicting DTIs is the machine learning-based methods that\nmainly consist of two steps: feature extraction and DTI prediction [24–27]. This\ntype of approach fully exploits the latent features from input data of known\ndrug compounds and target proteins to predict their interactions [28, 29].\nWhile these methods can successfully predict the interactions between each\npair of drugs and targets, they fail to infer the strength of the interaction\nbetween the drug–target pairs.\nIn order to further predict the putative strengths of the interactions, vari-\nous regression-based models have been proposed to infer the bi"}
{"date": "2023-12-27-22-36", "error": false, "url": "PDF", "text_blocks": "arXiv:2312.15270v1  [q-bio.PE]  23 Dec 2023Anticipating dengue outbreaks using a novel hybrid\nARIMA-ARNN model with exogenous variables\nIndrajit Ghosha, Shashank Guptab, Sourav Rana1c\naDepartment of Mathematics, Indian Institute of Technology , Bombay - 400076, Maharashtra, India\nbIPM (2022-27), Indian Institute of Management, Indore-453 556, Madhya Pradesh, India\ncDepartment of Statistics, Visva Bharati, Shantiniketan - 7 31235, West Bengal, India\nAbstract\nDengue incidence forecasting using hybrid models has been surging in the data rich\nworld. Hybridization of statistical time series forecasting models an d machine learning\nmodels are explored for dengue forecasting with diﬀerent degrees of success. In this\npaper, we propose a multivariate expansion of the hybrid ARIMA-AR NN model. The\nmain motivation is to propose a novel hybridization and apply it to deng ue outbreak\nprediction. The asymptotic stationarity of the proposed model ha s been established.\nWe check the forecasting capability and robustness of the foreca sts through numerical\nexperiments. State-of-the-art forecasting models for multivar iate time series data are\ncompared with the proposed model using accuracy metrics. Dengu e incidence data from\nSan Juan and Iquitos are utilized along with rainfall as an exogenous v ariable. Results\nindicate that the proposed model improves the ARIMAX forecasts in some situations\nand closely follows it otherwise. The theoretical as well as experimen tal results reinforce\nthat the proposed model has the potential to act as a candidate f or early warning of\ndengue outbreaks. The proposed model can be readily generalized to incorporate more\nexogenous variables and also applied to other time series forecastin g problems wherever\nexogenous variable(s) are available.\nKeywords: Time series forecasting, Hybrid models, Auto-regressive integrat ed moving\naverage model, Auto-regressive neural networks, Dengue incide nce data\n1. Introduction\nDengue is the most prevalent and rapidly spreading mosquito-borne viral disease.\nThe incidence of dengue has grown dramatically around the world in re cent decades,\nwith cases reported to WHO increasing from 505,430 cases in 2000 to 5.2 million in 2019\n[1]. The burden of dengue has become heavier from 1990 to 2019, amid st the three\n1Corresponding author. Email: sourav.rana@visva-bharati.ac.in\nPreprint submitted to arXiv December 27, 2023decades of urbanization, warming climates and increased human mob ility in much of the\nworld [ 33]. Dengue fever is mostly observed in tropical and sub-tropical reg ions of the\nglobe. In particular, several pockets in Africa, Southeast Asian c ountries and the western\nPaciﬁc region are prone to a high burden of dengue disease.\nThe virus is transmitted to humans through the bites of infected fe male mosquitoes,\nprimarily the Aedes aegypti mosquito. Other species within the Aede s genus can also act\nas vectors, but their contribution is secondary to Aedes aegypti. While the majority of\ninfections are milder asymptomatic, the more severe forms of deng ue infection - dengue\nshock syndrome (DSS) and dengue hemorrhagic fever (DHF) - can result in organ failure\nor death [ 27]. Developing a dengue vaccine has proven challenging due to various f actors,\nsuch as the requirement for a tetravalent vaccine capable of prov iding protection against\nall four dengue virus (DENV) serotypes, the absence of suitable a nimal models for test-\ning, and concerns surrounding the potential immune enhancement caused by the vaccine,\nsimilar to what occurs during natural infection [ 28]. Despite the substantial global de-\nmand, these obstacles have hindered the progress of dengue vac cine development. There\nis also no ready-to-use medicine for the disease. Therefore, it is of utmost importance to\nget some idea about future trends of dengue cases in the populatio n.\nThe eﬀectiveness of preventive measures against dengue fever is greatly enhanced by\nthe presence of a precise early warning system that can predict up coming epidemics. It\nhas been established that early detection of cases and treating th em can signiﬁcantly\nreduce fatal complications [ 9]. Early warning systems or forecasting models can inform\nthe expected number of dengue cases over the coming months. Th is information can\nthen be utilized to allocate resources to high-risk zones and awaren ess campaigns can be\nperformed to ﬂatten the expected dengue incidence curve [ 23;29]. Thus, public health au-\nthorities rely on model predictions for optimal management of futu re dengue cases. Due\nto the high importance of accurate forecasts of future dengue c ases, many researchers\nhave attempted this problem with diﬀerent levels of success [ 10;3;17]. However, there is\na diverse range of models that are used for dengue prediction prob lems, namely, compart-\nmental SIR-type models [ 26], statistical time series models [ 16], machine learning models\n[11] and ensemble models [ 32;8]. Researchers have seen that statistical and mac"}
{"date": "2023-12-27-22-36", "error": false, "url": "PDF", "text_blocks": " Multimodal Machine Learning Combining Facial Images and Clinical Texts Improves Diagnosis of Rare Genetic Diseases  Da Wu1, Jingye Yang1, Steven Klein2,3, Cong Liu4, Tzung-Chien Hsieh5, Peter Krawitz5, Chunhua Weng4, Gholson J. Lyon6,7, Jennifer M. Kalish2,3,8, Kai Wang1,9*  1 Raymond G. Perelman Center for Cellular and Molecular Therapeutics, Children's Hospital of Philadelphia, Philadelphia, PA 19104, USA 2 Division of Human Genetics, Children's Hospital of Philadelphia, Philadelphia, PA 19104, USA 3 Department of Pediatrics, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, United States 4 Department of Biomedical Informatics, Columbia University Irving Medical Center, New York, NY 10032, USA 5 Institute for Genomic Statistics and Bioinformatics, University Hospital Bonn, Rheinische Friedrich-Wilhelms-Universität Bonn, Bonn, Germany 6 Department of Human Genetics, New York State Institute for Basic Research in Developmental Disabilities, Staten Island, NY, USA 7 Biology PhD Program, The Graduate Center, The City University of New York, New York, United States of America 8 Department of Genetics, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, United States 9 Department of Pathology and Laboratory Medicine, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA 19104, USA   *: correspondence should be addressed to wangk@chop.edu.   ABSTRACT Individuals with suspected rare genetic disorders often undergo multiple clinical evaluations, imaging studies, laboratory tests and genetic tests, to find a possible answer over a prolonged period of multiple years. Addressing this “diagnostic odyssey” thus have substantial clinical, psychosocial, and economic benefits. Many rare genetic diseases have distinctive facial features, which can be used by artificial intelligence algorithms to facilitate clinical diagnosis, in prioritizing candidate diseases to be further examined by lab tests or genetic assays, or in helping the phenotype-driven reinterpretation of genome/exome sequencing data. However, existing methods using frontal facial photo were built on conventional Convolutional Neural Networks (CNNs), rely exclusively on facial images, and cannot capture non-facial phenotypic traits and demographic information essential for guiding accurate diagnoses. Here we introduce GestaltMML, a multimodal machine learning (MML) approach solely based on the Transformer architecture. It integrates the facial images, demographic information (age, sex, ethnicity), and clinical notes (optionally, a list of Human Phenotype Ontology terms) of patients to improve prediction accuracy. Furthermore, we also introduce GestaltGPT, a GPT-based methodology with few-short learning capacities that exclusively harnesses textual inputs using a range of large language models (LLMs) including Llama 2, GPT-J and Falcon. We evaluated these methods on a diverse range of datasets, including 449 diseases from the GestaltMatcher Database, several in-house datasets on Beckwith-Wiedemann syndrome (BWS, over-growth syndrome with distinct facial features), Sotos syndrome (overgrowth syndrome with overlapping features to BWS), NAA10-related syndrome (neurodevelopmental syndrome) and others. Our results suggest that GestaltMML/GestaltGPT effectively incorporate multiple modalities of data, greatly narrow down candidate genetic diagnosis of rare diseases, and may facilitate the reinterpretation of genome/exome sequencing data.   Keywords:  Multimodal Machine Learning, Artificial Intelligence, Large Language Models, Human Phenotype Ontology, Rare Genetic Disorders, Facial phenotyping   INTRODUCTION Currently, a substantial proportion of the global population, more than 6%, is affected by rare genetic disorders1. While collectively common, rare diseases are individually rare2: they are typically defined as affecting fewer than 200,000 people in the USA or less than one in 2,000 of the general population in Europe3. Based on the latest Orphanet4 and OMIM5 database, currently there are at least 7000 rare diseases that are identified. Due to the inherent rarity and extensive phenotypic heterogeneity of rare genetic disorders, accurately pinpointing a genetic diagnosis presents a formidable and time-intensive challenge, often referred to as “diagnostic odyssey”6-8. Patients with suspected genetic syndromes often need to undergo multiple clinical evaluations, imaging studies, and laboratory tests, in addition to different modalities of genetic tests, including gene panel, exome sequencing or whole-genome sequencing, to find a possible answer over a prolonged period of time. Clinicians often encounter difficulties for making decisions on what diagnostic modalities to use for fast and accurate diagnosis, as they must navigate a vast array of clinical conditions. Thus, shortening or ending the odyssey could have significant clinical, psychosocial, and economic benefits8,9.  Many genetic diseases ha"}
{"date": "2023-12-27-22-36", "error": false, "url": "PDF", "text_blocks": "MotifPiece: A Data-Driven Approach for Effective\nMotif Extraction and Molecular Representation\nLearning\nZhaoning Yu1and Hongyang Gao1*\n1*Department of Computer Science, Iowa State University, 2434 Osborn\nDr, Ames, 50011, Iowa, United States.\n*Corresponding author(s). E-mail(s): hygao@iastate.edu;\nContributing authors: znyu@iastate.edu;\nAbstract\nMotif extraction is an important task in motif based molecular representation\nlearning. Previously, machine learning approaches employing either rule-based\nor string-based techniques to extract motifs. Rule-based approaches may extract\nmotifs that aren’t frequent or prevalent within the molecular data, which\ncan lead to an incomplete understanding of essential structural patterns in\nmolecules. String-based methods often lose the topological information inher-\nent in molecules. This can be a significant drawback because topology plays a\nvital role in defining the spatial arrangement and connectivity of atoms within a\nmolecule, which can be critical for understanding its properties and behavior. In\nthis paper, we develop a data-driven motif extraction technique known as Motif-\nPiece, which employs statistical measures to define motifs. To comprehensively\nevaluate the effectiveness of MotifPiece, we introduce a heterogeneous learning\nmodule. Our model shows an improvement compared to previously reported mod-\nels. Additionally, we demonstrate that its performance can be further enhanced\nin two ways: first, by incorporating more data to aid in generating a richer motif\nvocabulary, and second, by merging multiple datasets that share enough motifs,\nallowing for cross-dataset learning.\nKeywords: Motif extraction, Molecular representation learning, Graph Neural\nNetworks, Heterogeneous motif graph\n1arXiv:2312.15387v1  [q-bio.QM]  24 Dec 20231 Introduction\nGraph neural networks (GNNs) have showcased their proficiency in tackling various\nintricate tasks in the field of molecular property prediction. These tasks encom-\npass activities such as classifying nodes within molecular graphs [14], distinguishing\nbetween different molecular structures [16, 23, 27], and predicting intermolecular inter-\nactions [10, 22, 24]. Instead of manually designing specific features, GNNs transform\na molecular graph into a high-dimensional Euclidean space by leveraging the inherent\ntopological relationships among its constituent nodes [21].\nTraditional GNNs models primarily rely on the fundamental topology of molecu-\nlar graphs to extract structural information [9, 14, 17, 25, 30]. This is accomplished\nthrough techniques such as neighborhood feature aggregation and pooling methods.\nWhile these methods are powerful in capturing local structural features within indi-\nvidual molecular graphs, they typically do not explicitly focus on learning recurring\nmotif patterns that span across different molecular graphs.\nIn molecular chemistry, a motif, also termed as a functional group, stands for a\nunique collection of atoms that are chemically bonded together in a consistent and\nrepeating pattern [2, 6, 7, 33, 34]. This pattern can occur across various molecules.\nThe distinguishing properties and chemical behavior of a molecule are significantly\ninfluenced by its motifs [1, 4, 29], as they represent the crucial reactive elements\nwithin the molecule. Over recent years, a growing body of scientific work has been\ndedicated to identify and incorporate the structural motifs in the learning of molecular\nrepresentations [8, 28, 31–33].\nThe process of extracting motifs is an integral component in the motif-related\nstudy. The capability of a model to effectively gather valuable motif information mainly\ndepends on how well this extraction process works. If the extraction isn’t done correctly\nor accurately, a model might have trouble understanding and using the motif data\neffectively. Therefore, the model’s success in handling motif information largely relies\non how well the motif extraction process is executed. Previouos works employ either\nrule-based or string-based techniques to extract motifs. Rule-based approaches are\nbased on domain knowledge and may extract motifs that aren’t frequent or prevalent\nwithin the molecular data. This can lead to an incomplete understanding of essential\nstructural patterns in molecules. String-based methods use a string to represent a\nmolecule and directly apply Natural Language Learning method to extract motifs. It\nmay ignore the topological information inherent in molecules. This can be a significant\ndrawback because topology plays a vital role in defining the spatial arrangement and\nconnectivity of atoms within a molecule, which can be critical for understanding its\nproperties and behavior.\nIn this paper, we introduce a novel method called MotifPiece for extracting motifs\nfrom molecular data. MotifPiece is a data-driven approach that can adapt to the\nunique characteristics and patterns present in a group of molecules. To comprehen-\nsively evaluate existing motif extraction methods and"}
{"date": "2023-12-27-22-36", "error": false, "url": "PDF", "text_blocks": "A Multi-Modal Contrastive Diffusion Model for Therapeutic Peptide Generation\nYongkang Wang1*, Xuan Liu1*, Feng Huang1, Zhankun Xiong1, Wen Zhang1,2 3†\n1College of Informatics, Huazhong Agricultural University, Wuhan 430070, China\n2Hubei Key Laboratory of Agricultural Bioinformatics, Huazhong Agricultural University, Wuhan 430070, China\n3Engineering Research Center of Intelligent Technology for Agriculture, Ministry of Education, Wuhan 430070,China\n{wyky481, lx666, fhuang233, xiongzk }@webmail.hzau.edu.cn, zhangwen@mail.hzau.edu.cn\nAbstract\nTherapeutic peptides represent a unique class of pharmaceu-\ntical agents crucial for the treatment of human diseases. Re-\ncently, deep generative models have exhibited remarkable\npotential for generating therapeutic peptides, but they only\nutilize sequence or structure information alone, which hin-\nders the performance in generation. In this study, we pro-\npose a Multi-Modal Contrastive Diffusion model (MMCD),\nfusing both sequence and structure modalities in a diffusion\nframework to co-generate novel peptide sequences and struc-\ntures. Specifically, MMCD constructs the sequence-modal\nand structure-modal diffusion models, respectively, and de-\nvises a multi-modal contrastive learning strategy with inter-\ncontrastive and intra-contrastive in each diffusion timestep,\naiming to capture the consistency between two modalities\nand boost model performance. The inter-contrastive aligns se-\nquences and structures of peptides by maximizing the agree-\nment of their embeddings, while the intra-contrastive differ-\nentiates therapeutic and non-therapeutic peptides by max-\nimizing the disagreement of their sequence/structure em-\nbeddings simultaneously. The extensive experiments demon-\nstrate that MMCD performs better than other state-of-the-\nart deep generative methods in generating therapeutic pep-\ntides across various metrics, including antimicrobial/anti-\ncancer score, diversity, and peptide-docking.\nIntroduction\nTherapeutic peptides, such as antimicrobial and anticancer\npeptides, are a unique class of pharmaceutical agents that\ncomprise short chains of amino acids, exhibiting significant\npotential in treating complex human diseases (Jakubczyk\net al. 2020). Traditionally, therapeutic peptides are discov-\nered through a comprehensive screening of sequence spaces\nusing phage/yeast display technologies (Muttenthaler et al.\n2021) or computational tools trained for scoring desired\nproperties (Lee et al. 2017; Lee, Wong, and Ferguson 2018).\nHowever, the combinatorial space of possible peptides is\nvast and only a small solution satisfies therapeutic require-\nments; thus, such screening methods based on brute force\ncan be time-consuming and costly.\n*These authors contributed equally.\n†Corresponding authors.\nCopyright © 2024, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.In recent years, deep generative models (DGMs) have\ndemonstrated success in generating images (Liu and Chilton\n2022), texts (Iqbal and Qureshi 2022), proteins (Wu et al.\n2021), and also gained popularity in peptides. DGMs ex-\nplored a more expansive chemical space that affords the\ncreation of structurally novel peptides, by training neu-\nral networks to approximate the underlying distribution of\nobserved or known ones (Wan, Kontogiorgos, and Fuente\n2022). For example, autoregression-based methods depicted\npeptide sequences as sentences composed of residue tokens,\nso that the problem can be solved by predicting residue ar-\nrangement via recurrent neural networks (RNN) (M ¨uller,\nHiss, and Schneider 2018; Capecchi et al. 2021). Variational\nautoencoder (V AE)-based methods generated new peptide\nsequences by sampling from the latent space learned through\nan encoder-decoder architecture, with or without therapeu-\ntic properties as conditional constraints (Ghorbani et al.\n2022; Szymczak et al. 2023b). Generative adversarial net-\nwork (GAN)-based methods trained the generator and dis-\ncriminator using known data, which compete against each\nother to generate new peptides (Tucs et al. 2020; Oort et al.\n2021; Lin, Lin, and Lane 2022). Nowadays, diffusion mod-\nels (Yang et al. 2023) are prevalent in the generation of pro-\ntein sequences and structures, owing to their superior capa-\nbility in fitting distributions compared to prior techniques\n(Shi et al. 2023; Wu et al. 2022). Likewise, these advanced\ndiffusion models can be extended to peptide generation and\nare expected to deliver favorable outcomes.\nDespite the commendable progress of efforts above, they\nfocused on generating either sequences (i.e., residue ar-\nrangements) or structures (i.e., spatial coordinates of back-\nbone atoms), ignoring that models fusing information from\nboth modalities may outperform their uni-modal counter-\nparts (Huang et al. 2021). However, how to effectively in-\ntegrate the multi-modal information and capture their con-\nsistency in peptide generation is a major challenge. Addi-\ntionally, compared with gener"}
{"date": "2023-12-27-22-36", "error": false, "url": "PDF", "text_blocks": "Exploring the Relationship between Fractional Hill Coefficient,\nIntermediate Processes and Mesoscopic Fluctuations\nManuel Eduardo Hern´ andez-Garc´ ıa, Jorge Vel´ azquez-Castro\nFacultad de Ciencias F´ ısico Matem´ aticas\nBenem´ erita Universidad Aut´ onoma de Puebla\nDecember 27, 2023\nContents\n1 Introduction 2\n2 Deterministic approximation 2\n3 Hill function with decimal coefficient 3\n4 Enzymatic reactions with intermediate processes 4\n4.1 Sequential case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n4.2 Independent case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n5 Intrinsic Fluctuations in Enzymatic Reactions 6\n5.1 Sequential case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n5.2 Independent case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n6 Relationship between the Hill functions 9\n7 Results and conclusions 11\n8 Acknowledgments 11\nReferences 11\nAbstract\nThe Hill function is relevant for describing enzyme binding and other processes in gene regulatory\nnetworks. Despite its theoretical foundation, it is often used empirically as a useful fitting function.\nTheoretical predictions suggest that the Hill coefficient should be an integer; however, it is often assigned\na fractional value. This study aims to show that the use of fractional Hill coefficients actually indi-\ncates the presence of intermediate processes or, in some cases, the effect of noise on these systems. The\ndeterministic approximation of enzymatic processes leads to the derivation of the Hill function, which\ncan be expanded around the noise magnitude to derive mesoscopic corrections. This study establishes\nrelationships between the intermediate processes and the decimal Hill coefficient, both with and without\nfluctuations. This outcome contributes to a deeper understanding of the underlying processes associ-\nated with the fractional Hill coefficient, while also enabling the prediction of an effective value of the\nHill coefficient from the underlying mechanism, allowing us to have a simplified description of complex\nsystems.\nKeywords: Hill function, intermediate processes, deterministic approximation, Hill coefficient, stochas-\ntic corrections.\n1arXiv:2312.15789v1  [q-bio.MN]  25 Dec 20231 Introduction\nHill function plays an important role in describing enzyme binding or promoter activity in gene regulation\nnetworks [1, 2]. However, even if an underlying theory exists for its derivation, it is sometimes used as\nan empirical description of the biochemical processes. As is the case with the Hill coefficient [3], which\nis commonly represented as n, this coefficient describes the cooperativity in the binding of ligands to a\nreceptor molecule, such as enzymes, to a protein. In kinetic experiments, data are commonly fitted to a Hill\nfunction and a decimal value is assigned to the Hill coefficient, even though theoretical predictions suggest\nonly integer values. For example, in a study on the interaction between hemoglobin and oxygen [12], the\nHill coefficient was found to be n= 1.8−3.4. However, theoretical calculations suggest that the value of\nnshould be equal to four because hemoglobin has the capacity to bind up to four oxygen molecules [4]. It\nis evident that this process is more intricate than the enzymatic reaction described by the Hill function.\nConsequently, it was employed merely as a convenient function for fitting. In [5], intermediate processes\nwere used to provide a more realistic representation of enzyme-protein binding given that enzymes do not\nalways bind simultaneously to a protein. This study illustrates how various system parameters can produce\ndifferent curves with varying degrees of cooperation. However, there is no direct correspondence between\nthe parameters of a Hill function with intermediate processes and those with a decimal Hill coefficient.\nThis study seeks to show that the use of a Hill function with decimal coefficients actually entails the\npresence of intermediate processes and that the Hill coefficient corresponds to the coefficients of the detailed\ndescription that includes the intermediate processes.\nThis problem is underexplored in terms of the influence of noise on this type of system. It is widely\nacknowledged that noise can have consequences in the dynamics of genetic regulatory networks, as demon-\nstrated in references [6, 7]. Although deterministic models can effectively capture most system dynamics\n[1, 6], they are insufficient for explaining all the observed behaviors [8]. In this study, we also investigated\nthe influence of intrinsic fluctuations in enzymatic binding on intermediate processes. To achieve this, we\nemployed a systematic expansion around the deterministic behavior to derive mesoscopic corrections [9, 10].\nSubsequently, we established relationships between the intermediate processes and the decimal Hill coeffi-\ncient, both "}
{"date": "2023-12-27-22-36", "error": false, "url": "PDF", "text_blocks": "Fidelity and Consistency in\nIterative Probabilistic Set Replication:\nComparing Bi-Parental and Mono-Parental Methods\nAssaf Marron1, Smadar Szekely1, Irun R. Cohen2, and David Harel1\n1Department of Computer Science and Applied Mathematics,\n2Department of Immunology and Regenerative Biology,\nWeizmann Institute of Science, Rehovot, 76100, Israel\nEmail:<firstname>.<lastname>@weizmann.ac.il\nKeywords:\nProbabilistic Sampling, Statistics, Autoencoding, Sexual reproduction, Asexual reproduction,\nbiparental, uniparental, monoparental\nAbstract:\nWe report results of a restricted mathematical computation that may be relevant in various con-\ntexts, including the evolution of sexual reproduction. The computation is an iterative probabilistic\nreplication of sets of real numbers. Given a set of random values sampled from a certain inter-\nval, we replicate it probabilistically by encoding it as its arithmetic mean and then sampling a\nrandom same-size set of real numbers using uniform distribution over the same interval length\naround that mean. The encoded set and its code are considered the parent of the sampled one.\nWe first sample a cohort of several such sets around an initial code, and probabilistically replicate\neach set once, creating a new same-size cohort, which we then subject to the same process. In a\nbi-parental variant of the above mono-parental process, we use a pair of codes rather than a single\none for sampling a new set: each parent contributes half of the elements of the child set. Neither\nvariant depends on judging properties as harmful, or on selection: all individuals are paired and\nreproduced. Comparing the two variants over many iterations, bi-parental processing shows en-\nhanced fidelity and consistency, where fidelity is defined as the mean of the distances between a\ncohort’s codes and the initial code, and consistency is the standard deviation of code values within\na cohort. We do not attempt here to directly mimic natural reproduction, which includes copying\nand recombination of DNA codes subject to mutations. Still, the result intuitively aligns with the\nidea that sexual reproduction in nature helps preserve, and perhaps even define, core traits of each\nspecies. The cause for the prevalence, in eukaryotic species, of sexual reproduction over asexual,\ndespite increased complexity and unpredictability, is subject to debate and diverse theories. The\nmathematical phenomenon reported here might be part of the answer.\n1 Introduction\nInspired by research on biological evolution, in-\ncluding the evolution of sexual reproduction,\nwe report on an interim observation regarding\na purely synthetic mathematical computation.\nWhile the results may indeed be relevant to our\noriginal motivation, we defer that aspect of the\ndiscussion, and focus on reporting the observed\nnumerical phenomenon.\nWe term the process at hand iterative proba-\nbilistic replication . In each step one encodes a set\nof real numbers to a single code value, and thenformsanewsetbyprobabilisticsampling(alsore-\nferred to here as probabilistic decoding), around\nthat code. In Section 2, we present this process\nin detail, but in two variants. In the first variant,\nwe carry out the probabilistic sampling of each\nnew set using a single parent code, and in the\nsecond we use two parent codes. The variants are\nthus termed here mono-parental andbi-parental ,\nrespectively ( uniparental is a common synonym\nfor mono-parental).\nThe motivation for studying this particular\ncomputation is discussed in Section 2.4. In Sec-\ntion 3, we summarize our observation that (i)arXiv:2312.15795v1  [q-bio.PE]  25 Dec 2023bi-parental replication preserves at least one set\nproperty more faithfully than the mono-parental\nvariant, and (ii) the output of bi-parental sam-\npling is more internally consistent; namely, the\nstandard deviation across a cohort of multi-\nple replicated sets is smaller than under mono-\nparental processing. In Section 4 we discuss the\npossible relevance of the present restricted results\nto future biological research and the emerging in-\ntuition around the mechanisms by which sexual\nreproduction may have evolved in nature. We\nconclude by outlining steps for continuing this\nanalysis, and list a few relevant areas that em-\nploy similar computational building blocks.\nThe program source code for our ex-\nperiments is available online at https:\n//colab.research.google.com/drive/1DG1tCM3_\nAMAouNxQBEIKTz3rnoxFe1Ye?usp=sharing.\n2 Iterative Probabilistic\nReplication by Encoding and\nProbabilistic Sampling\nAs stated above, the mathematical process we\nstudy here is minimalistic, and does not attempt\nto simulate key aspects of natural reproduction\nlike the copying or recombination of genetic ma-\nterial, or known formulas for the rates of inter-\ngeneration errors or mutations. Specifically, we\nare interested in the replication of sets of real\nnumbers, which can also be visualized as sets of\npoints on the x-axis.\n2.1 Mono-parental iterative\nprobabilistic replication\nWe first"}
{"date": "2023-12-27-22-36", "error": false, "url": "PDF", "text_blocks": "Unsupervised Learning of Phylogenetic Trees via\nSplit-Weight Embedding\nYibo Kong\nDepartment of Computer Science\nUniversity of Wisconsin-Madison\nMadison, WI 53706George P. Tiley\nKew Royal Botanic Gardens\nKew, Richmond, TW9 3AE,\nLondon, UK\nClaudia Sol´ ıs-Lemus∗\nWisconsin Institute for Discovery\nDepartment of Plant Pathology\nUniversity of Wisconsin-Madison\nMadison, WI 53706\nJanuary 2023\nAbstract\nUnsupervised learning has become a staple in classical machine learning, successfully identi-\nfying clustering patterns in data across a broad range of domain applications. Surprisingly,\ndespite its accuracy and elegant simplicity, unsupervised learning has not been sufficiently\nexploited in the realm of phylogenetic tree inference. The main reason for the delay in adop-\ntion of unsupervised learning in phylogenetics is the lack of a meaningful, yet simple, way of\nembedding phylogenetic trees into a vector space. Here, we propose the simple yet power-\nful split-weight embedding which allows us to fit standard clustering algorithms to the space\nof phylogenetic trees. We show that our split-weight embedded clustering is able to recover\nmeaningful evolutionary relationships in simulated and real ( Adansonia baobabs) data.\n1 Introduction\nThe Tree of Life is a massive graphical structure which represents the evolutionary process from single\ncell organisms into the immense biodiversity of living species in present time. Estimating the Tree of Life\nwould not only represent the greatest accomplishment in evolutionary biology and systematics, but it would\nalso allow us to fully understand the development and evolution of important biological traits in nature, in\nparticular, those related to resilience to extinction when exposed to environmental threats such as climate\nchange. Therefore, the development of statistical and machine-learning theory to reconstruct the Tree of Life,\nespecially those scalable to big data, are paramount in evolutionary biology, systematics, and conservation\nefforts against mass extinctions.\nGraphical structures that represent evolutionary processes are denoted phylogenetic trees . A phylogenetic\ntree is a binary tree whose internal nodes represent ancestral species that over time differentiate into two\nseparate species giving rise to its two children nodes (see Figure 1 left). The evolutionary process is then\ndepicted by this bifurcating tree from the root (the origin of life) to the external nodes of the tree (also\ndenoted leaves) which represent the living organisms today. Mathematically, a rooted phylogenetic tree Ton\ntaxon set Xis a connected directed acyclic graph with vertices V={r} ∪VL∪VT, edges Eand a bijective\nleaf-labeling function f:VL→Xsuch that the root rhas indegree 0 and outdegree 2; any leaf v∈VLhas\nindegree 1 and outdegree 0, and any internal node v∈VThas indegree 1 and outdegree 2. An unrooted tree\n∗Corresponding author: solislemus@wisc.edu\n1arXiv:2312.16074v1  [q-bio.PE]  26 Dec 2023results from the removal of the root node rand the merging of the two edges leading to the outgroup (taxon\n4 in Figure 1 left). Traditionally, phylogenetic trees are drawn without nodes (Figure 1 center) given that\nonly the bifurcating pattern is necessary to understand the evolutionary process. The specific bifurcating\npattern (without edge weights) is denoted the tree topology. Edges in the tree have weight we∈(0,∞) that\ncan represent different units, evolutionary time or expected substitutions per site being the most common.\nFigure 1: Left: Phylogenetic tree in 4 taxa. Internal (gray) nodes represent speciation events in which an\nancestral species differentiates into two. External (blue) nodes, also denoted leaves, represent living species\n(here denoted 1,2,3,4). Edge weights (in gray) also denoted branch lengths can represent evolutionary time\nor expected substitutions per site. Center: Different phylogenetic tree on the same 4 taxa in which taxon\n2 is grouped with taxon 3 rather than with taxon 1. Nodes are no longer drawn as is the most common\nrepresentation of phylogenetic trees. Right: Phylogenetic tree with gene flow event depicted as a green\narrow. This biological scenario represents the possibility that some genes have the evolutionary history of\nthe phylogenetic tree on the left (with clade (1 ,2)) and some genes, the evolutionary history of the center\ntree (with clade (2 ,3)).\nOne of the main challenges when inferring phylogenetic trees is the fact that different genes in the data\ncan have different evolutionary histories due to biological processes such as introgression, hybridization or\nhorizontal gene transfer [33, 12, 28]. An example is depicted in Figure 1 (right) which has one gene flow\nevent drawn as a green arrow. This gene flow event represents the biological scenario in which some genes in\ntaxon 2 get transferred from the lineage of taxon 3, and thus, when reconstructing the evolutionary history\nof this group of four taxa, some genes will depict the phylogenetic tree that clusters "}
{"date": "2023-12-27-22-36", "error": false, "url": "PDF", "text_blocks": "arXiv:2312.16086v1  [q-bio.NC]  26 Dec 2023NOTES ON RETROACTIVE INTERFERENCE MODEL OF\nFORGETTING\nMikhail Katkov\nDepartment of Brain Sciences\nWeizmann Institute of Science\nRehovot, 76100 Israel\nSchool of Natural Sciences\nInstitute for Advanced Study\nPrinceton, NJ\nmikhail.katkov@gmail.com\nABSTRACT\nWe present analytical derivation of the minimal and maximal number of items retained in recently\nintroduced Retroactive Interference Model of Forgetting. Also we computed the probability that two\nitems presented at different times are retained in the memor y at a later time analytically.\nKeywords retrograde interference ·Markov process ·retention curve\nIntroduction\nStudying human memory is a complex task, since there are pres umably many interacting processes that are hard to\nisolate. Traditionally models in psychology of memory are a ttempting to describe many processes at once by creating\na very complicated mathematical model that have a lot of para meters, hard to analyse, and usually require a separate\nﬁtting of parameters for each experiment. Therefore, since parameters have to adjusted for each measurement, it is\nnot clear how good these models would describe memory proces ses outside of laboratory settings. We have recently\nproposed a different type of models to describe human memory that are based on few assumptions and have zero or\nfew parameters that describe the class of stimuli, but indep endent of experimental settings. These types of models,\nif validated, have a much broader applicability in everyday life settings. We have recently presented mathematical\nmodels for memory forgetting and retrieval [1]. In this publ ication we have asked about mathematical properties of\nforgetting model that may help design experiments to valida te the underlying mathematical construction. In this note\nwe provide answers to 2 questions raised in that publication regarding the forgetting model.\nExperimentally, forgetting is traditionally measured in t he form of retention function ( RC(t)) - the probability that\nmemory is retained for time tsince acquisition[2]. People observe that retention funct ion monotonically decreasing\nwith time and although there are debates on the form of retent ion function one of the best candidate is power function\nof time. One of the popular explanation of memory forgetting in humans is retrograde interference [3]. It assumes\nthat new incoming memories are interacting with stored memo ries and cause some past memories disappear. There\nare different approaches to model forgetting (see for examp le [4]), but here we are concentrating on consequences of\nour mathematical model [5] for possible experimental valid ating of underlying assumptions behind our model. The\nmodel assumes that each incoming memory (one memory at one di screte time step) has ndimensional valence vector,\nwith components being iid random variables. Every incoming memory is added to the memory pool, erasing all\nstored memories that have smaller valences in all dimension s. This model can be solved analytically, and the resulting\nretention curve agree well with experiment. Nevertheless, it is not clear to what extent the underlying principles hold s\nduring retention of memory items. We have posed recently sev eral mathematical questions that may provide additional\nexperimental tests related to this issue[1].Forgetting Calculations\nWe consider the forgetting model III from [1]. It states that there is a retention process, where at each time step a\nnew memory is presented to the process. Memory in the model is characterized by a vector of valences vk∈R,k=\n1..n, wherenis a single integer parameter of the model representing the d imensionality of the model. Valences of\nincoming memory is assumed to be sampled from arbitrary stat ionary distribution (absolutely continuous). Incoming\nmemory erases all currently stored memories that have all va lences smaller that corresponding valencies of incoming\nmemory. Finally, incoming memory is added to stored memorie s. Formally, all incoming memories are described by\ncollection of valences V={vk,t∈R,k= 1..n,t∈N}. For each time Twe can deﬁne a set of stored memories\nM(T;V) ={t1,...t|M(T)|},tk< T which contains presentation times ( t1,...t|M(T)|) of stored memories, where the\ncardinality of M(T;V)(|M(T;V)|) represents a number of stored memories at time T. At time T+1a new memory\nwith valences vk,T+1is presented, and the set of stored memories is updated M(T+ 1;V) ={T+ 1;tm:tm∈\nM(T;V),∃k|vk,tm> vk,T+1}. One can ask what is expected value of |M(T)|that is referred to as retention curve\nRCn(T) =E(|M(T;V)|)with respect to distribution of vk,t. It turns out that retention curve does not depend on the\nparticular distribution of valences, since it depends only on the order statistics of memory items in each dimension[5,\n1].\nMinimal number of retained items\nWe proposed two kind of tests that can potentially check the v alidity of the model [1]. Both are related to partialy\nordered set (poset) nature o"}
{"date": "2023-12-27-22-36", "error": false, "url": "PDF", "text_blocks": "1 \n Expanding to Arbitrary Study Designs: ANOVA to Estimate Limits of \nAgreement for MRMC Studies  \nSi Wena* and Brandon D. Gallasa \naDivision of Imaging, Diagnostics, and Software Reliability, Office of Science and Engineering \nLaboratories, Center for Devices and Radiological Health, U.S. FDA, Silver Spring, USA  \n* Correspondence to: Si Wen. Email: si.wen@fda.hhs.gov \n  2 \n Expanding to Arbitrary Study Designs: ANOVA to Estimate Limits of \nAgreement for MRMC Studies  \nA multi-reader multi -case (MRMC) analysis i s applied to account for both reader and case \nvariability when evaluating the clinical performance of a medical imaging device or reader \nperformance under different reading modalities. For a clinical task that measures a \nquantitative biomarker an agreement  analysis, such as limits of agreement (LOA), can be \nused. In this work, we decompose the total variation in the data using a three -way mixed \neffect ANOVA model to estimate the MRMC variance of individual differences and the \nLOA between different reading m odalities. There are rules for writing down the \nexpectation of the mean squares in terms of the variance components for fully -crossed data, \ni.e. data where all the readers read all the cases in all modalities being studied. Sometimes \nthe annotation task is  labor -intensive and time -consuming or distributed across sites, so that \na fully -crossed study is not practical. In this work, we focus on estimating the MRMC \nvariance in the within - and between -readers and within - and between -modalities LOA for \nan arbitrary study design. Simulation studies were conducted to validate the LOA variance \nestimates. The method was also applied to a dataset to compare pathologist performance for assessing the density of stromal tumor infiltrating lymphocytes on different platform s. \nKeywords: limits of agreement ; MRMC study ; ANOVA for unbalanced data;  variance \ncomponents  \n1.Introduction  \nA multi -reader multi -case (MRMC)  study is usually appl ied to evaluate whether a medical \nimaging device can improve the clinical performance of the image readers.(Wagner et al. 2007; \nGallas et al. 2012; Obuc howski and Bullen 2022)  In the study, qualitative or quantitative \nassessment s are collected and compared from multiple readers  (radiologists/ pathologists) \nreviewing multiple  cases  (images)  under different reading modalities . For example,  suppose that \nthere is an AI/ML algorithm enabled medical device supporting the pathologist s to evaluate the \ndensity of stromal tumor infiltrating lymphocytes  (sTIL s) on digital slides . The density of sTILs  3 \n is prognostic for survival in breast cancers and  is visual ly assessed  on routine hematoxylin and \neosin (H&E)- stained slides.(Kos et al. 2020)  To validate the performance of the device  in the \nhands of the reader s we collect estimates of the density of sTILs from  pathologists with and \nwithout the assistance of the de vice. Then  we compare the closeness or agreement between  the \nquantitative  measurements , sTIL scores, from different modalities  or readers . We refer to such \nstudies as agreement studies.  \nOur p revious work(Wen and Gallas 2022)  generalized the limits of agreement (LOA) \nmethod (Bland and Altman 1986, 1999) , a widely used agreement analysis, to MRMC analysis \nthat account s for reader and case variability for fully -crossed study designs . In a fully -crossed \nstudy, all the readers provide  measurements for  all the cases for both modalities  as shown in  \nFigure 1.e . In some studies,  the annotation tasks  are labor -intensive and time -consuming or \ndistributed across sites, so that a fully -crossed study is not practical. In this work, we focus on \nMRMC stu dies that are not fully crossed , and we generalize the MRMC analysis to treat  \narbitrary study designs . Some examples are described  in Figure 1.a -Figure 1.d.  \nAn ANOVA model is commonly used to analyze MRMC data,(Beiden et al. 2000; \nDorfman et al. 1992; Gallas et al. 2009; Obuchowski 1995)  as the data are likely correlated when \nthe readers evaluat e the same set of cases and each case is reviewed by multiple readers. A  three -\nway mixed effect ANOVA is  used to estimate different types of LOA for a fully -crossed MRMC \nstudy.(Wen and Gallas 2022)  In ANOVA, th e data generated from a fully -crossed MRMC study \nare called balanced data , as each reader or case has the same number of readings . There are rul es \nfor calculating the sum of squares (SS ) and expected mean squares (MS)  when the data are \nbalanced .(Montgomery 2012)  The expected mean squares link the variance components for the \nrandom effects in the ANOVA model to the SS computed from the data . Then, the variance 4 \n components can be estimated from the data and used to estimate the MRMC variance in  LOA.  \nHowever, in an arbitrary MRMC study, t he data are unbalanced. To determine the relationship \nbetween expected MS  and the variance components in the ANOVA model, we fi"}
